# Data processing

In this section I'll process the raw data so that I can use them for analysis in the next section.
Note that the data were slightly preprocessed: I only selected variables that we use for processing and analysis here.
Other than that, the data were untouched.

The data are on the OSF.
You can download them if you set the code chunk below to `eval=TRUE`.
Downloading only works when the OSF project is public.
If it isn't during peer review, you'll need to paste the data files from the OSF to the `data/` folder manually.
```{r download-data, eval=TRUE}
# create directory
dir.create("data/", FALSE, TRUE)

# download models
osf_retrieve_node("https://osf.io/yn7sx/") %>%
  osf_ls_nodes() %>%
  filter(name == "data") %>%
  osf_ls_files(
    .,
    n_max = Inf
  ) %>%
  osf_download(
    .,
    path = here("data"),
    progress = FALSE
  )
```

## Read waves 2-6

We'll start with loading the data for waves 2 to 6.
We start here instead of wave 1 because participant identification isn't super straightforward.
A participant doesn't get a single unique identifier that's stable across all waves.
Instead, participants start with an ID in wave 1 (called `transaction_idOld` in the wave 2 to 6 data) and get a new unique ID for wave 2 and so on.

I believe originally the researchers wanted to go with a single ID, but changed their mind.
Look at the data table below (\@ref(tab:example-ids)), where I made up two participants to recreate the data structure.
We see that the first participant has an transaction ID (`transaction_idOld`) for the first wave.
The same participant then has that same old transaction ID for wave two, plus a new transaction ID for wave 2 (`transaction_id`).

Here's where it gets a bit complicated: That transaction ID for wave 2 is repeated on wave 3, but with a different name (`transaction_idW2`).
Next to that new variable, is the unique ID for that wave (`transaction_idW3`).
After that, each new wave has the ID of the previous wave plus a new ID for the current wave.
```{r example-ids, echo=FALSE}
example_ids <- 
  read_csv(here("data", "example_id.csv"))

knitr::kable(
  example_ids,
  caption = "Example of how ID variables look like",
  full_width = TRUE
) %>% 
  kable_styling(font_size = 8)
```

Unfortunately, the `id` column from the example isn't included in the raw data, so we'll have to recreate participant IDs that are constant across waves.
I solved this problem with a loop, which is definitely not the most elegant way to go about this, but I think it gets the job done.
First, lets load the data.
```{r load-waves-2-to-6}
waves_2_to_6 <- 
  read_csv(
    here("data", "waves_2_to_6.csv"),
    guess_max = 2e4
  ) %>% 
  select(-X1) # remove rownumber
```

Next, the logic behind assigning the constant IDs.
We'll start at the ID of wave 2, find the ID of wave 3 that's on the same line as the ID of wave 2 and store the ID for wave 3.
We repeat this procedure for all waves and in the end assign an ID to those rows that have the IDs we extracted on any of the ID variables.

The steps, concretely:

1. We store all IDs (so that's the IDs of wave 2) in a vector (excluding `NA`s).
2. Initiate an ID counter (i.e., the participant number we assign later).
3. We iterate over each wave 2 ID.
4. If participants did participate in a wave, we find the wave 3 ID that is on the same row as the wave 2 that we're currently looking for.
5. We now look for the wave 3 ID and store the wave 4 ID that's on the same line.
6. We repeat that until we're at the last ID and have all IDs for that participant stored in a vector.
7. Then a row gets assigned the participant ID (to the existing, but empty `id` variable) if any of the wave ID variables have a match in the extracted IDs.

On my machine, the below code takes about three minutes.
```{r assign-pp-id, cache=TRUE}
# the unique wave 2 IDs
ids <- waves_2_to_6 %>% 
  pull(transaction_id) %>% 
  na.omit

# the participant number we assign later
id_counter <- 1

# assign the correct variable type to the empty ID variable that's already in the data where we'll assign participant numbers at the end of the loop
waves_2_to_6$id <- NA_real_

for (an_id in ids) {
  
  # transaction ids that belong to that one participant
  id_to_match <- c()
  
  # add the initial id
  id_to_match <- c(id_to_match, an_id)
  
  # assign that id as temporary ID for which we should match (id_to_match only has one entry so far)
  temp_id <- id_to_match
  
  # at this point, participants might have not participated in the next wave, so they might have an empty cell in
  # transaction_id2. so we'll embed everything that follows in their separate if statement
  if (!is_empty(temp_id)) {
    
    # find the transcation_id3 that's on the same line as transaction_id2 and store it
    temp_id <- 
      waves_2_to_6 %>% 
      filter(transaction_idW2 == an_id) %>% 
      pull(transaction_idW3)
    
    id_to_match <- na.omit(c(id_to_match, temp_id)) # so that NA doesn't become one of the IDs
  }
  
  if (!is_empty(temp_id)){
    # then the same for transaction_id4, but this time we compare to the temporary id we extracted above
    # also, we only select those rows where the next ID isn't NA (because there're two matches for the temp_id)
    temp_id <- 
      waves_2_to_6 %>% 
      filter((transaction_idW3 == temp_id) & !is.na(transaction_idW4)) %>% 
      pull(transaction_idW4)
    
    id_to_match <- c(id_to_match, temp_id)
  }
  
  if (!is_empty(temp_id)){
    # then the same as above for transaction_id5
    temp_id <- 
      waves_2_to_6 %>% 
      filter((transaction_idW4 == temp_id) & !is.na(transaction_idW5)) %>% 
      pull(transaction_idW5)
    
    id_to_match <- c(id_to_match, temp_id)
  }
  
  if (!is_empty(temp_id)){
    # and last for transaction_id6
    temp_id <- 
      waves_2_to_6 %>% 
      filter((transaction_idW5 == temp_id) & !is.na(transaction_idW6)) %>% 
      pull(transaction_idW6)
    
    id_to_match <- c(id_to_match, temp_id)
  }
  
  # then we assign a participant number, such that a participant gets the number for each row where any of their transaction_ids are part of the temporary ids
  waves_2_to_6 <- 
    waves_2_to_6 %>% 
    mutate(
      id = case_when(
        transaction_id %in% id_to_match ~ id_counter,
        transaction_idW2 %in% id_to_match ~ id_counter,
        transaction_idW3 %in% id_to_match ~ id_counter,
        transaction_idW4 %in% id_to_match ~ id_counter,
        transaction_idW5 %in% id_to_match ~ id_counter,
        transaction_idW6 %in% id_to_match ~ id_counter,
        TRUE ~ id
      )
    )

  # increase the participant number
  id_counter <- id_counter + 1
} 
```

Before we we assign correct variable types, name factor levels etc. we'll load wave 1.
This way, we can merge the two files first before doing all of the data cleaning, variable selection, and variable renaming.

## Read wave 1

Let's load the file for wave 1.
`transcaction_id` is the unique identifier for each participant.
However, that variables is called `transaction_idOld` in waves 2 to 6, which is why we name it the same here (see above).
Also, `dWeekMerged` is the wave identifier that's used in waves 2 to 6, so we'll include that manually here.
```{r load-wave-1}
wave1 <- 
  read_csv(
    here("data", "wave1.csv"),
    guess_max = 2e4
  ) %>% 
  select(-X1) %>% # remove row number
  rename(transaction_idOld = transaction_id) %>% 
  mutate(dWeekMerged = 1)
```

There are many variables we don't care about, but before we make the variable selection, I'll first merge the two files.
Here's another complication: If we look at the surveys and how variables are named there, it looks like there are different labels for the same variables in wave 1 and waves 2 to 6.
For example, in wave 1, variables providing the estimated time with a medium had the appendix `ai` and those asking about self-estimated increases or decreases in frequency had the appendix `aii`.
For waves 2 to 6, the surveys say that this is reversed, such that estimated time with a medium has the appendix `aii` and self-estimated increase or decrease has the appendix `ai`.

The same goes for variable names: For example, the audiobooks section in wave 1 begins with `C7c`, but with `C6c` in waves 2 to 6.
In the actual data, however, variable names are constant (see the codebook).
For example, audiobooks are `C7c` in both data sets despite what the survey files say.
The variable labels are the same across all waves (I manually checked), which makes merging easier.

My merging strategy is as follows:

1. I assign the `id` we created above to the `wave1` data file by merging by `transaction_idOld` which is available in both data sets.
However, that means that those who didn't participate in wave 2 won't have an `id`.
So we manually fill those empty cells up - although we'll probably exclude those who only participant in wave 1 later anyways.
2. I then add the rows of `waves_2_to_6` to `waves1`. I use the `bind_rows` command, which maintains all variables for which there's no match and sets them to `NA` - exactly what we want, because full demographics are only in wave 1 and newer questions only in later waves.

Note that from now on I leave the raw wave data untouched and make all changes in a working file.
```{r merge-waves}
# add the id variable to wave1 by merging by transaction_idOld that's in both data sets
working_file <- 
  left_join(
    wave1,
    waves_2_to_6 %>% select(transaction_idOld, id),
    by = "transaction_idOld"
  )

# assign an id to those in wave 1 who have an NA in the id column because they didn't participate in later waves
# we can do this easily with coalesce, for which we create a vector that continues from the current max ID until each participant with missing ID has one
working_file <- 
  working_file %>% 
  mutate(
    id = coalesce(
      id,
      max(working_file$id, na.rm = T)+1:nrow(working_file)
    )
  )

# then add the rows of waves 2 to 6 to wave 1
working_file <- 
  bind_rows(
    working_file,
    waves_2_to_6
  )
```

## Data cleaning

Now that each participant has a constant identifier and all waves are merged, we can select those variables we actually need.
For our purposes, we'll retain:

* demographic information
* variables indicating what media people used in the past week
* time estimates of those uses
* self-estimated importance of the medium
* self-estimated frequency
* the estimated effects on well-being in wave 6

Note that there are quite a lot of filtering variables.
We can't collapse these to one variable because these questions were multiple choice.

Also, variables `C1x1aii` to `C7cx1aii` ask about estimates of change of media use.
However, the first wave has a different time frame ("Since the COVID-19 pandemic") than the following waves ("Compared to the week before"), but assess the same concept: estimates of change.
We don't formally analyze these variables, but use their data in all waves a) to impute missing values later in data processing, b) in visualizations to help readers understand the data structure.
```{r select-and-rename}
working_file <-
  working_file %>% 
  select(
    # meta information
    id,
    wave = dWeekMerged,
    
    # demographics
    gender = A4,
    age = A5,
    
    # filter questions: downloaded
    downloaded_music = B1r1,
    downloaded_music_videos = B1r2,
    downloaded_video_games = B1r3,
    downloaded_software = B1r4,
    downloaded_films = B1r5,
    downloaded_tv = B1r6,
    downloaded_sports = B1r7,
    downloaded_video_clips = B1r8,
    downloaded_ebooks = B1r9,
    downloaded_magazines = B1r10,
    downloaded_audiobooks = B1r11,
    downloaded_images = B1r12,
    downloaded_none = B1r13,
    
    # filter questions: streamed
    streamed_music = B2r1,
    streamed_music_videos = B2r2,
    streamed_video_games = B2r3,
    streamed_software = B2r4,
    streamed_films = B2r5,
    streamed_tv = B2r6,
    streamed_sports = B2r7,
    streamed_video_clips = B2r8,
    streamed_ebooks = B2r9,
    streamed_magazines = B2r10,
    streamed_audiobooks = B2r11,
    streamed_images = B2r12,
    streamed_none = B2r13,
    
    # filter questions: shared
    shared_music = B3r1,
    shared_music_videos = B3r2,
    shared_video_games = B3r3,
    shared_software = B3r4,
    shared_films = B3r5,
    shared_tv = B3r6,
    shared_sports = B3r7,
    shared_video_clips = B3r8,
    shared_ebooks = B3r9,
    shared_magazines = B3r10,
    shared_audiobooks = B3r11,
    shared_images = B3r12,
    shared_none = B3r13,
    
    # filter questions: bought
    bought_music = B4r1,
    bought_video_games = B4r2,
    bought_software = B4r3,
    bought_films = B4r4,
    bought_tv = B4r5,
    bought_books = B4r6,
    bought_magazines = B4r7,
    bought_audiobooks = B4r8,
    bought_none = B4r9,
    
    # music
    music_identity_ = C1x1r1:C1x1r7,
    music_hours = C1x1aiHoursc1,
    music_minutes = C1x1aiMinutesc2,
    music_estimate = C1x1aii,
    
    # films
    films_identity_ = C2x1r1:C2x1r7,
    films_hours = C2x1aiHoursc1,
    films_minutes = C2x1aiMinutesc2,
    films_estimate = C2x1aii,
    
    # tv
    tv_identity_ = C3x1r1:C3x1r7,
    tv_hours = C3x1aiHoursc1,
    tv_minutes = C3x1aiMinutesc2,
    tv_estimate = C3x1aii,
    
    # video games
    games_identity_ = C5x1r1:C5x1r7,
    games_hours = C5x1aiHoursc1,
    games_minutes = C5x1aiMinutesc2,
    games_estimate = C5x1aii,
    
    # e-publishing
    e_publishing_identity_ = C7x1r1:C7x1r7,
    
    # (e-)books
    books_hours = C7ax1aiHoursc1,
    books_minutes = C7ax1aiMinutesc2,
    books_estimate = C7ax1aii,
    
    # magazines
    magazines_hours = C7bx1aiHoursc1,
    magazines_minutes = C7bx1aiMinutesc2,
    magazines_estimate = C7bx1aii,
    
    # audiobooks
    audiobooks_hours = C7cx1aiHoursc1,
    audiobooks_minutes = C7cx1aiMinutesc2,
    audiobooks_estimate = C7cx1aii,
    
    # well-being
    life_satisfaction_ = QD2r1:QD2r2,
    well_being_ = QD2r3:QD2r4
  )
```

Alright, now to transforming all variables to the correct type and assigning informative factor level labels.
Note that `id` now is numeric which can be misleading, which is why I add `pp_` (for participant) before the ID number.
```{r assign-types-and-labels}
working_file <- 
  working_file %>% 
  
  # turn non-numeric variables into factors
  mutate(
    across(
      c(
        id,
        gender
      ),
      as.factor
    )
  ) %>% 
  
  # purely cosmetic: arrange by id
  arrange(id) %>% 
  
  # give proper labels to demographics
  mutate(
    gender = fct_recode(
      gender,
      "Male" = "1",
      "Female" = "2",
      "Other" = "3"
    ),
    # add "pp_" prefix to id variable
    id = as.factor(
      paste0("pp_", id)
    )
  )
```

For the first wave, participants only responded to questions about how much they used a medium if they indicated that they had used it in the three months before wave 1.
Those variables (e.g. `bought_books`) are only present in wave 1, but `NA` in the other waves.
Therefore, we create new variables that show whether a person was asked to indicate their use of a medium, so if they answered yes to any of the filter variables at the beginning of the wave 1 survey.
At this point, those filter variables are still numeric, so we'll add them up.
If they're above 0, participants were asked about that medium.
If they're 0, participants hadn't used any of the media in the three months before wave 1 and weren't asked questions about them.
Note that I keep those filter variables as numeric for processing later.
After we're done with the filter variables, we can also delete the individual ones.

Note that I first check whether any of those filter variables have missing values, but it seems the survey had forced responses here, so we don't have missings.
```{r check-missings-filter}
# check whether any of the filter variables (at wave 1, when they were asked) have missing values
working_file %>% 
  filter(wave == 1) %>% 
  summarise(
    across(
      c(
       starts_with("downloaded"),
       starts_with("streamed"),
       starts_with("shared"),
       starts_with("bought")
      ),
      ~ unique(is.na(.x))
    )
  ) %>%
  pivot_longer(
    everything(),
    values_to = "missing"
  ) %>% 
  summarise(
    "Number of missings: " = sum(missing)
  )
```

While we're at it: All constant wave 1 variables now have `NA` in the subsequent wave.
I'll set those `NA`s to the wave 1 value because those are stable demographics that apply to each wave.
Note that three demographic questions were asked at each wave, employment status, living siutation, and the consequences of COVID-19.
```{r create-use-filter}
# get filter variables (only present at wave 1)
filters <- 
  working_file %>% 
  filter(wave == 1) %>%
  
  # the filter per category
  mutate(
    filter_music = rowSums(
      select(
        .,
        starts_with("downloaded_music"),
        starts_with("streamed_music"),
        starts_with("shared_music"),
        bought_music
      )
    ),
    
    filter_films = rowSums(
      select(
        .,
        downloaded_films,
        streamed_films,
        shared_films,
        bought_films
      )
    ),
    
    filter_tv = rowSums(
      select(
        .,
        downloaded_tv,
        streamed_tv,
        shared_tv,
        bought_tv
      )
    ),
    
    filter_video_games = rowSums(
      select(
        .,
        downloaded_video_games,
        streamed_video_games,
        shared_video_games,
        bought_video_games
      )
    ),
    
    filter_ebooks = rowSums(
      select(
        .,
        downloaded_ebooks,
        streamed_ebooks,
        shared_ebooks,
        bought_books
      )
    ),
    
    filter_magazines = rowSums(
      select(
        .,
        downloaded_magazines,
        streamed_magazines,
        shared_magazines,
        bought_magazines
      )
    ),
    
    filter_audiobooks = rowSums(
      select(
        .,
        downloaded_audiobooks,
        streamed_audiobooks,
        shared_audiobooks,
        bought_audiobooks
      )
    )
  ) %>% 
  
  # recode depending on whether the sum is zero or not
  mutate(
    across(
      starts_with("filter"),
      ~ if_else(.x > 0, 1, 0)
    )
  ) %>% 
  
  # select variables that are constant across all waves
  select(
    id,
    gender,
    contains("identity"),
    starts_with("filter")
  )

# add those filters and constant variables so that they become a constant for each pp, deleting old filter variables
working_file <- 
  left_join(
    working_file %>% 
      select(
        -(gender),
        -contains("identity")
      ),
    filters,
    by = "id"
  ) %>% 
  select(
    -starts_with("downloaded"),
    -starts_with("streamed"),
    -starts_with("shared"),
    -starts_with("bought"),
  ) %>% 
  
  # some reordering for purely cosmetic purposes
  select(
    id:age,
    starts_with("filter"),
    everything()
  )

# remove the temp filters file
rm(filters)
```

## Response rates and missing values

In this section, I check response rates, response patterns, and missing values.
The data set is quite complicated because of the many filter variables.
The survey had forced responses, so there aren't any missings if someone finished the survey.
However, because of the many filters, there'll still be a large amount of missing values that we need to inspect or recode.

I think the following information is most relevant to understand response and missingness patterns:

1. How many participants have completed each wave.
2. How many responses we have per medium per wave.

### Participants per wave

First, let's see how many people completed each wave, what percentage of people have completed that exact number of wave, how many participants that have exactly this number of waves, and what percentage of participants have completed *at least* this wave (Table \@ref(tab:check-wave-completes)).
```{r check-wave-completes, echo=FALSE}
completion_table <- 
  working_file %>% 
  count(id) %>% 
  count(n) %>% 
  rename(
    "Waves" = n,
    "Participants (only that number of waves)" = nn
  ) %>% 
  mutate(
    "Frequency" = round(`Participants (only that number of waves)` / sum(`Participants (only that number of waves)`), digits = 3) * 100,
    "Participants per wave" = rev(cumsum(rev(`Participants (only that number of waves)`))),
    "Frequency per wave" = round(`Participants per wave` / sum(`Participants (only that number of waves)`), digits = 3) * 100
  ) %>% 
  as_tibble()

knitr::kable(
  completion_table,
  caption = "Response rates"
) %>% 
  kable_styling(font_size = 15)
```

### Responses per wave and medium

Okay, next we inspect how many responses we have per medium per wave.
The data set gets complicated here.
This is where the filtering requires quite some wrangling: Someone who hasn't listened to music in the three months before wave 1 will have missing values on all items about music - but only at wave 1.

However, at each subsequent wave, participants were asked one of the `estimate` questions.
If they said that they had used a medium less, about the same, or more compared to the previous week, they were then also prompted to provide their use estimates.

For example, someone might've had a 0 on the filter questions for audio books because they hadn't listened to audio books the three months before wave 1.
For wave 1, then, they didn't provide the minutes and hours they spent on audio books.
In wave 2, they were then asked how their audio book use had changed since the last survey.
If they answered anything but the sixth answer option (i.e., they still hadn't listened to audio books), they were asked to report how many minutes and hours they had used audio books.

Here's why that can be problematic: The participant below (\@ref(tab:example-filter-change)) hadn't listened to audio books in the first three months and reports that at wave 1, then says at wave 2 that their audio book use hadn't changed (i.e., selected `3` on the `audiobooks_estimate` question).
But the participant was still asked about their minutes and hours - which is why they filled in bogus numbers.
Minutes and hours were forced response as far as I can tell.
I wouldn't take those estimates seriously, because the participant was forced to respond to minutes and hours.
We see that in the following waves, they selected the option that they hadn't listened to audiobooks.

Please note: We could not share the full `estimate` questions.
Before uploading the raw data, I did some preprocessing such that only the answer options 3 (nothing changed) and 6 (didn't use a medium) remained.
All other non-missing values are set to 9.
Missing values remain as `NA`.
```{r example-filter-change, echo=FALSE}
working_file %>% 
  filter(id == "pp_7") %>%
  filter(filter_audiobooks == 0) %>%
  select(
    id,
    wave,
    filter_audiobooks,
    audiobooks_estimate,
    audiobooks_minutes,
    audiobooks_hours
  ) %>% 
  knitr::kable(
    .,
    caption = "Example of a participant with no change in use"
  ) %>% 
  kable_styling(font_size = 15)
```

Before we turn to those cases where we can tell a participant didn't want to provide a use estimate, we need to decide what to do with the filter questions in the first wave.
For our research question, we're interested in **how variations in amount of use relate to well-being**, not what that relation is **among users**.
Therefore, if someone says that they didn't use a medium in the three months before the first wave, they are saying that they **spent zero time engaging with that medium**.
The filter questions didn't ask whether a user has a device they can use to engage with those content categories or whether they had any of the media.
So the filter question didn't ask whether participants were **able** to engage with a category.
It asked **whether people used a medium**.
Therefore, it fits our research question to treat those values as zero.

Below, I'll set all time variables at the first wave to `-99` that were skipped in the survey because participants said they didn't use the medium in the filter questions.
I choose `-99` to be able to distingiush "natural" zeros (so zeros participants actually filled in) from our imputed zeros.
I'll turn those `-99` to zeros later when we inspect data quality.

There's probably a sleek way to write a function that pulls variable names and matches those with the conditional commands in the code, but that's above my skill level.
```{r set-nonuse-to-zero}
working_file <- 
  working_file %>% 
  mutate(
    
    # music
    across(
      c(music_hours, music_minutes),
      ~ if_else((wave == 1 & filter_music == 0), -99, .x)
    ),
    
    # films
    across(
      c(films_hours, films_minutes),
      ~ if_else((wave == 1 & filter_films == 0), -99, .x)
    ),
    
    # tv
    across(
      c(tv_hours, tv_minutes),
      ~ if_else((wave == 1 & filter_tv == 0), -99, .x)
    ),
    
    # video games
    across(
      c(games_hours, games_minutes),
      ~ if_else((wave == 1 & filter_video_games == 0), -99, .x)
    ),
    
    # ebooks
    across(
      c(books_hours, books_minutes),
      ~ if_else((wave == 1 & filter_ebooks == 0), -99, .x)
    ),
    
    # magazines
    across(
      c(magazines_hours, magazines_minutes),
      ~ if_else((wave == 1 & filter_magazines == 0), -99, .x)
    ),
    
    # audiobooks
    across(
      c(audiobooks_hours, audiobooks_minutes),
      ~ if_else((wave == 1 & filter_audiobooks == 0), -99, .x)
    )
  )
```

Also, when we look at the codebook, we see that hours and minutes were coded such that 0 = 1, 2 = 1, etc.
This means someone who has 24 hours actually has 23 hours.
Someone who has 60 minutes actually has 59 minutes.
Therefore, I subtract one from each hour and minute variable to get the real estimate.
```{r transform-hours-minutes}
working_file <- 
  working_file %>% 
  mutate(
    across(
      c(
        contains("hours"),
        contains("minutes")
      ),
      ~ if_else(.x != -99, .x - 1, .x) # we maintain the artificial zero
    )
  )
```

Now, when participants said they didn't use a medium for any wave, in the next wave they're still presented the `estimate` question.
When they answered anything but that they didn't use the medium, they were asked to provide minutes and hours estimates (see the example participant above).
In those hours and minutes survey questions, they were shown what they said in the previous wave.
Crucially, they saw their estimate from the previous wave **after they had given their estimate**.

So when I used 0 minutes in the previous week but forget what I said in the previous wave, it's not unrealistic that I select "a lot less" on the `estimate` question.
In my mind, estimating use in relation to previous time points and giving an absolute estimate of minutes and hours are two separate psychological retrieval processes.
Therefore, I don't have a problem with someone who used 0 minutes of audio books in a wave saying that they used audio books a lot less in the next wave and report to have used them for half an hour.
It doesn't make sense from an objective stand point because 30 minutes is more than 0 minutes, but the estimate question is about participants' perceived frequency in relation to the past.
For that reason, I won't directly change the 30 minutes to 0, but leave them as is.

In other words, I won't set values to `NA` by comparing the absolute minutes and hours estimate to the relative frequency estimate.
I'll only make changes in clear cases like the one presented above, where someone clearly didn't use a medium.
I'll do exclusions in the next section when I look at data quality.

For now, let's deal with those few cases that are as clear-cut as the one presented above.
First some house keeping.
If participants indicated on one of the `estimate` questions that they didn't use that medium in the previous week (only applicable in waves 2 to 6), they'll receive a 0 on their time estimates.
So we'll first set time estimates to `-999` if participants say that they didn't use a medium, following the same logic I outlined above.
I use `-999` instead of `-99` like above to be able to distinguish between imputed zeros in the first wave and imputed zeros in later waves.
```{r didnt-use-medium}
working_file <- 
  working_file %>% 
  mutate(
    
    # music
    across(
      c(music_hours, music_minutes),
      ~ if_else((wave != 1 & music_estimate == 6), -999, .x)
    ),
    
    # films
    across(
      c(films_hours, films_minutes),
      ~ if_else((wave != 1 & films_estimate == 6), -999, .x)
    ),
    
    # tv
    across(
      c(tv_hours, tv_minutes),
      ~ if_else((wave != 1 & tv_estimate == 6), -999, .x)
    ),
    
    # video games
    across(
      c(games_hours, games_minutes),
      ~ if_else((wave != 1 & games_estimate == 6), -999, .x)
    ),
    
    # ebooks
    across(
      c(books_hours, books_minutes),
      ~ if_else((wave != 1 & books_estimate == 6), -999, .x)
    ),
    
    # magazines
    across(
      c(magazines_hours, magazines_minutes),
      ~ if_else((wave != 1 & magazines_estimate == 6), -999, .x)
    ),
    
    # audiobooks
    across(
      c(audiobooks_hours, audiobooks_minutes),
      ~ if_else((wave != 1 & audiobooks_estimate == 6), -999, .x)
    )
  )
```

Alright, now let's check, per medium, who only has 6s and 3s on the `estimate` questions (aka didn't use and no change to previous week).
Those minutes and hours we'll set to 0 as well.
This applies only to those who didn't use a medium in the first wave.
If you used a medium in the first wave and said that your time remained the same, you shouldn't get a zero.

Setting instances of time with a medium within a participant but across waves to 0 requires some serious data wrangling (or my coding game isn't strong enough...).
To be able to assess who **only gave 3 or 6** as an estimate for a medium for waves 2 through 6, we first transform the data to long format.
In Table \@ref(tab:media-to-long), I display how the data look like after transformation.
```{r media-to-long, echo=FALSE}
media_long <- 

  # first turn long by filter variables
  pivot_longer(
    working_file %>% 
      select(
        id,
        wave,
        contains("estimate"),
        contains("minutes"),
        contains("hours")
      ),
    c(-id, -wave),
    names_to = c("medium", "time"),
    values_to = "value",
    names_sep = "_"
  ) %>%
  
  # now the medium and time are mixed up in the same column, so we spread them 
  pivot_wider(
    .,
    id:medium,
    names_from = "time",
    values_from = "value"
  )

knitr::kable(
  head(media_long, n= 20),
  caption = "Data in long format"
)
```

Next, I need to select only those media which participants didn't say they used at the first wave.
Below, I select those, add a marker for that id by medium combination, and then add that marker to the long data frame.
```{r mark-media}
# select id by medium combinations that didn't give an estimate in the fist wave (aka the only NA entries)
markers <- 
  media_long %>% 
  filter(is.na(estimate)) %>% 
  select(id, medium) %>% 
  mutate(selected = TRUE)

# add those markers to the long data frame
media_long <- 
  left_join(
    media_long,
    markers,
    by = c("id", "medium")
  )
```

Now we know on which rows to operate.
We then check whether a medium that wasn't used in the first wave only got a 3 or a 6 on the `estimate` in waves 2 to 6 and flag the person by medium combination that indeed doesn't have a change.
Afterwards, we transform those `no_change` indicators to the wide format.
Below shows how these data look like: If it's `NA` the person provided an estimate at the first wave.
If it's `FALSE` the person didn't provide an estimate at wave 1 (so it was 0 minutes and hours), but their estimate increased or decreased over the next waves.
If it's `TRUE` the person didn't provide an estimate at wave 1 and they kept not using or their use didn't change.
```{r count-no-changes}
no_changes <- 
  media_long %>% 
  filter(selected == TRUE) %>% # everyone who had an NA for an estimate in the first wave
  filter(wave > 1) %>% # we don't count the first wave
  group_by(id, medium) %>% 
  mutate(no_change = if_else(estimate %in% c(3,6), 0, 1)) %>% # if it's 3 or 6, we assign zero 
  summarise( # so that the sum is zero
    no_change = sum(no_change)
  ) %>%
  mutate(no_change = if_else(no_change == 0, TRUE, FALSE)) %>% # then anything that isn't zero has at least one 1,2, or 4 in their estimate 
  ungroup() %>% 
  
  # then turn to wide format
  pivot_wider(
    .,
    names_from = "medium",
    values_from = "no_change"
  ) %>% 
  rename_with(
    .,
    .cols = -id,
    ~ paste0(., "_no_change")
  )
```

Table \@ref(tab:table-no-changes) shows how these markers look like.
```{r table-no-changes, echo=FALSE}
knitr::kable(
  head(no_changes, n = 10),
  caption = "Markers for whether someone had no change from wave 1 through wave 6 or not, per medium"
) %>% 
  kable_styling(font_size =  7)
```

Now we can add those markers to the `working_file`.
```{r add-markers}
working_file <- 
  left_join(
    working_file,
    no_changes,
    by = c("id")
  )
```

Last, we transform the minutes and hours for each medium in each wave to 0, depending on whether that medium has one of the above markers telling us that the person didn't use the medium at wave 1 and use didn't change in subsequent waves (i.e., "not changed" or "haven't used" on `estimate` for all subsequent waves).
Like above, we use `-9999` as an indicator for zero, so we know that `-9999` estimates are imputed zeros based on the person not changing their use after having said they don't use a medium in the first wave.
`-999` is just someone saying they didn't use a medium and `-99` is not having used a medium in the first wave.
```{r zero-estimates}
working_file <- 
  working_file %>% 
  mutate(
    
    # music
    across(
      c(music_hours, music_minutes),
      ~ if_else((wave != 1 & music_no_change == TRUE), -9999, .x, missing = .x) # need to set missing explicitly because the no_change variables contain NA if someone didn't have a missing in the first wave
    ),
    
    # films
    across(
      c(films_hours, films_minutes),
      ~ if_else((wave != 1 & films_no_change == TRUE & .x != - 999), -9999, .x, missing = .x) # don't override the -99
    ),
    
    # tv
    across(
      c(tv_hours, tv_minutes),
      ~ if_else((wave != 1 & tv_no_change == TRUE & .x != - 999), -9999, .x, missing = .x)
    ),
    
    # video games
    across(
      c(games_hours, games_minutes),
      ~ if_else((wave != 1 & games_no_change == TRUE & .x != - 999), -9999, .x, missing = .x)
    ),
    
    # ebooks
    across(
      c(books_hours, books_minutes),
      ~ if_else((wave != 1 & books_no_change == TRUE & .x != - 999), -9999, .x, missing = .x)
    ),
    
    # magazines
    across(
      c(magazines_hours, magazines_minutes),
      ~ if_else((wave != 1 & magazines_no_change == TRUE & .x != - 999), -9999, .x, missing = .x)
    ),
    
    # audiobooks
    across(
      c(audiobooks_hours, audiobooks_minutes),
      ~ if_else((wave != 1 & audiobooks_no_change == TRUE & .x != - 999), -9999, .x, missing = .x)
    )
  ) %>% 
  
  # no need anymore for the variables we added
  select(
    -ends_with("no_change")
  )
```

Let's do a sanity check: all `minutes` and `hours` items should now have entries because they were forced response (or because we set them to zero).
That's indeed the case, so all looking good.
```{r check-missings-time}
working_file %>% 
  summarise(
    across(
      c(contains("minutes"), 
        contains("hours")),
      ~ sum(is.na(.x))
      )
    ) %>%
  gather()
```

In contrast, the estimates will still contain `NA`s if people didn't use a medium in the first wave because the survey had them skip those items. 

After all this wrangling we're finally able to look at how many responses we have per medium per wave.
Actually, the answer is straightforward now: everyone who finished a wave either provided minutes and hours estimates for all media, or they didn't which means we set them to 0.
In other words, **the complete responses per wave are also the complete responses per medium**.

## Data quality and exclusions

In this section, we inspect implausible values, strange response patterns, and potential outliers.

### Implausible values

Okay, first let's check that the maximum hour reported is indeed 23 and the maximum minutes 59.
Table \@ref(tab:max-hours-minutes) shows that that's the case.
```{r max-hours-minutes}
working_file %>% 
  summarise(
  across(
    c(contains("hours"), contains("minutes")),
    ~ max(.x, na.rm = T)
  )
  ) %>% 
  gather() %>% 
  knitr::kable(
    .,
    caption = "Maximum values of hours and minutes, per medium"
  )
```

Alright, next we did a lot of work on `working_file`, and `media_long` isn't up to date anymore, which is why I turn the working file into the long format once more because it's easier for some plotting.
```{r media-to-long2}
media_long <- 

  # first turn long by filter variables
  pivot_longer(
    working_file %>% 
      select(
        id,
        wave,
        contains("estimate"),
        contains("minutes"),
        contains("hours")
      ),
    c(-id, -wave),
    names_to = c("medium", "time"),
    values_to = "value",
    names_sep = "_"
  ) %>%
  
  # now the medium and time are mixed up in the same column, so we spread them 
  pivot_wider(
    .,
    id:medium,
    names_from = "time",
    values_from = "value"
  )
```

Now let's see what proportion of minutes and hours we imputed (aka placeholders for zeros).
We turned values into `-99` if they were in the first wave on a medium a user hadn't used; to `-999` if a user said they hadn't used a medium in the waves after that; and `-9999` if a user hadn't used a medium in the first wave and reported no changes in all following waves.
In Table \@ref(tab:table-imputed-zeros-minutes), we see we had to impute the most zeros for audiobooks.
```{r table-imputed-zeros-minutes, echo=FALSE}
media_long %>% 
  count(medium, minutes) %>% 
  pivot_wider(
    names_from = minutes,
    values_from = "n"
  ) %>% 
  mutate(
    Nonzero = rowSums(select(., `1`:`56`), na.rm = TRUE)
  ) %>% 
  rename(
    "Zeros for no change" = `-9999`,
    "Zeros for no use" = `-999`,
    "Zeros for first wave" = `-99`,
    "Natural zeros" = `0`
  ) %>% 
  select(medium, contains("zero"), Nonzero) %>% 
  mutate(
    Total = rowSums(select(., `Zeros for no change`:Nonzero)),
    "Proportion no change" = round(`Zeros for no change` / Total * 100, digits = 2),
    "Proportion no use" = round(`Zeros for no use` / Total * 100, digits = 2),
    "Proportion first wave" = round(`Zeros for first wave` / Total * 100, digits = 2),
    "Porportion natural" = round(`Natural zeros` / Total * 100, digits = 2),
    "Proportion Nonzero" = round(Nonzero / Total * 100, digits = 2)
  ) %>% 
  knitr::kable(
    .,
    caption = "Proportion of imputed and natural zero minutes"
  )
```

Next, we do the same thing for hours.
In Table \@ref(tab:table-imputed-zeros-hours), we see a similar pattern.
```{r table-imputed-zeros-hours, echo=FALSE}
media_long %>% 
  count(medium, hours) %>% 
  pivot_wider(
    names_from = hours,
    values_from = "n"
  ) %>% 
  mutate(
    Nonzero = rowSums(select(., `1`:`22`), na.rm = TRUE)
  ) %>% 
  rename(
    "Zeros for no change" = `-9999`,
    "Zeros for no use" = `-999`,
    "Zeros for first wave" = `-99`,
    "Natural zeros" = `0`
  ) %>% 
  select(medium, contains("zero"), Nonzero) %>% 
  mutate(
    Total = rowSums(select(., `Zeros for no change`:Nonzero)),
    "Proportion no change" = round(`Zeros for no change` / Total * 100, digits = 2),
    "Proportion no use" = round(`Zeros for no use` / Total * 100, digits = 2),
    "Proportion first wave" = round(`Zeros for first wave` / Total * 100, digits = 2),
    "Porportion natural" = round(`Natural zeros` / Total * 100, digits = 2),
    "Proportion Nonzero" = round(Nonzero / Total * 100, digits = 2)
  ) %>% 
  knitr::kable(
    .,
    caption = "Proportion of imputed and natural zero hours"
  )
```

Ultimately, these zero imputations are just a matter of how many nonzero entries a medium had to begin with.
In other words: The more participants used a medium, the lower the proportion of imputed zeros for any reason.
Also, someone putting down one hour and zero minutes will have a zero up here, so these tables aren't terribly informative.

How much total time is zero is much more informative.
Right now, hours and minutes are still separate, so we'll create a `time` variable that maintains the negative placeholders we inserted above.
```{r create-time}
media_long <- 
  media_long %>% 
  mutate(
    # if minutes isn't negative, create time variable to maintain the placeholders
    time = round(if_else(minutes >= 0, hours + (minutes / 60), minutes), digits = 1)
  )
```

In Table \@ref(tab:table-imputed-zeros-times), we see a clearer pattern: The media with the most use (e.g., TV, music, films) have low imputed zeros, whereas those with little use (especially audio books) have a high amount of imputed zeros.
That's in line with the high proportion of imputed values for no use (i.e., selecting not having used in waves 2 to 6) for the little used media.
```{r table-imputed-zeros-times, echo=FALSE}
media_long %>% 
  count(medium, time) %>% 
  pivot_wider(
    names_from = time,
    values_from = "n"
  ) %>%  
  mutate(
    Nonzero = rowSums(select(., `0.1`:`21.7`), na.rm = TRUE)
  ) %>% 
  rename(
    "Zeros for no change" = `-9999`,
    "Zeros for no use" = `-999`,
    "Zeros for first wave" = `-99`,
    "Natural zeros" = `0`
  ) %>% 
  select(medium, contains("zero"), Nonzero) %>% 
  mutate(
    Total = rowSums(select(., `Zeros for no change`:Nonzero)),
    "Proportion no change" = round(`Zeros for no change` / Total * 100, digits = 2),
    "Proportion no use" = round(`Zeros for no use` / Total * 100, digits = 2),
    "Proportion first wave" = round(`Zeros for first wave` / Total * 100, digits = 2),
    "Porportion natural" = round(`Natural zeros` / Total * 100, digits = 2),
    "Proportion Nonzero" = round(Nonzero / Total * 100, digits = 2)
  ) %>% 
  knitr::kable(
    .,
    caption = "Proportion of imputed and natural zero times"
  )
```

Let's turn those negative values (i.e., the placeholders for zeros) into actual zeros and check for the overall occurrence of all zeros in relation to nonzero values.
```{r placeholders-to-zeros}
working_file <- 
  working_file %>% 
  mutate(
    across(
      c(contains("hours"), contains("minutes")),
      ~ if_else(.x < 0, 0, .x) # if negative, turn into zero
    )
  )

media_long <- 
  media_long %>% 
  mutate(
    across(
      c(contains("hours"), contains("minutes")),
      ~ if_else(.x < 0, 0, .x) # same here
    ),
    
    time = round(hours + (minutes / 60), digits = 1)
  )
```

Then we'll show zeros vs. nonzeros in Table \@ref(tab:zero-times-table).
The table basically summarizes all tables so far, showing the popularity of the medium and how much we had to impute.
```{r zero-times-table, echo=FALSE}
media_long %>% 
  group_by(medium) %>% 
  count(time == 0) %>% 
  pivot_wider(
    names_from = `time == 0`,
    values_from = "n"
  ) %>% 
  rename(
    "Above 0h" = `FALSE`,
    "0h" = `TRUE`
  ) %>% 
  mutate(
    Proportion = round(`0h` / sum(c(`Above 0h`, `0h`)) * 100, digits = 2)
  ) %>% 
  knitr::kable(
    .,
    caption = "Proportion of 0 hours, per medium"
  )
```

Alright, next we'll visually inspect the distribution of self-reported use times per medium.
We'll be working with the `working_file` again, for which we need to calculate the time per medium.
Like before, I'll do that manually for all seven media.
```{r get-time-per-medium}
working_file <- 
  working_file %>% 
  mutate(
    
    # music
    music_time = music_hours + (music_minutes / 60),
    
    # films
    films_time = films_hours + (films_minutes / 60),
    
    # tv
    tv_time = tv_hours + (tv_minutes / 60),
    
    # video games
    games_time = games_hours + (games_minutes / 60),
    
    # ebooks
    books_time = books_hours + (books_minutes / 60),
    
    # magazines
    magazines_time = magazines_hours + (magazines_minutes / 60),
    
    # audiobooks
    audiobooks_time = audiobooks_hours + (audiobooks_minutes / 60)
  )
```

In Figure \@ref(fig:plot-minutes-hours-per-medium) we see the distribution of use time per medium.
Those figures aren't super accurate for practical reasons: For some media, there's so many zeros that there isn't enough jitter in the cloud which is why they're all so bunched up together on the left.

There's many entries of more than 18h of **average daily use**, which is close to impossible if someone sleeps at least six hours.
```{r plot-minutes-hours-per-medium, echo = FALSE, warning=FALSE, message=FALSE, fig.cap="Distribution of self-reported time per medium", fig.dim=c(8.5,9)}
plot_grid( # from cowplot
  dens_with_points(working_file, "music_time"), # custom function, see custom functions under setting up
  dens_with_points(working_file, "films_time"),
  dens_with_points(working_file, "tv_time"),
  dens_with_points(working_file, "games_time"),
  dens_with_points(working_file, "books_time"),
  dens_with_points(working_file, "magazines_time"),
  dens_with_points(working_file, "audiobooks_time"),
  labels = c(
    "Music time", 
    "Films time",
    "TV time",
    "Games time",
    "Books time",
    "Magazines time",
    "Audiobooks time"
    ),
  ncol = 2,
  label_size = 8,
  hjust = 0,
  vjust = 0,
  label_x = 0,
  label_y = 0.93
)
```

In Table \@ref(tab:implausible-use-table) we see that very few entries are above 18h, relative to all other values, which is a good sign.
```{r implausible-use-table}
# count proportion per medium
media_long %>% 
  group_by(medium) %>% 
  count(time >= 18) %>% 
  pivot_wider(
    names_from = `time >= 18`,
    values_from = "n"
  ) %>% 
  rename(
    "Below 18h" = `FALSE`,
    "Above 18h" = `TRUE`
  ) %>% 
  mutate(
    Proportion = round(`Above 18h` / sum(c(`Above 18h`, `Below 18h`)) * 100, digits = 2)
  ) %>% 
  knitr::kable(
    .,
    caption = "Proportion of hours above 18"
  )
```

#### Participant-level

Let's follow up on those who reported 18h or more use of a medium and check whether there are any participants whose estimates we cannot really trust.

We need to distinguish between completely excluding a participant (whose answers we don't trust for all waves they provided) and wave-level exclusions (when we trust the data of the participant, except for one or two waves).

As for implausible values on the participant-level, I'd say the following are indicators of poor quality:

1. More than 30% of time estimates participants provided (excluding zeros imputed by us) across all waves are above 18h.
2. More than one instance of a 23h+ estimate across all waves.
3. More than one instance where the sum of nonzero estimates is above 48h in a wave. 

Let's look at the proportion of very high reported use times.
Self-reported use is also about how much people **feel** like they used medium, so I'll be liberal here.
I'd say we can't trust a participant if they estimated 18+ hours in > 30% of all their time estimates, across all waves.
Below, I'll count per participant how many times they estimated 18+ hours of consumption in relation to all time estimates they provided.
I'll not include zero times in that account because we imputed times of zero.
```{r implausible-pp-level-1}
implausible_pp_level_1  <- 
  media_long %>%
  filter(time > 0) %>% # nonzero
  group_by(id, medium) %>% 
  summarise(
    above18 = sum(time >= 18),
    below18 = sum(time < 18),
    waves = n()
  ) %>% 
  ungroup() %>% 
  group_by(id) %>% 
  summarise(
    above18 = sum(above18),
    below18 = sum(below18),
    entries = sum(waves),
    proportion_above18 = round(above18 / entries, digits = 2)
  ) %>% 
  ungroup() %>% 
  arrange(desc(proportion_above18)) %>% 
  filter(proportion_above18 > 0.3)

# store the participants that were above that threshold
exclusions_pp_1 <- 
  implausible_pp_level_1 %>% 
  pull(id) %>% 
  as.character()
```

In Table \@ref(tab:table-implausible-pp-1) we see that there's mostly participants that fulfill these exclusions who completed only a wave or two, so there's most likely a correlation between their motivation to participate and how seriously they took the survey.
**Note: For all tables on exclusions, I show the first 15 rows.**
```{r table-implausible-pp-1, echo=FALSE}
knitr::kable(
  head(implausible_pp_level_1, n = 15),
  caption = "Proportion of respondents who reported use of 18h in more than 30% of their estimates"
)
```

Overall, there were `r length(exclusions_pp_1)` participants who fall into the first exclusion criterion.
Next, participants might feel like they played the whole day, so saying 23 hours of play on average is close to impossible.
I'd say that can happen, but if it happens twice across waves, I wouldn't trust that participant.
```{r implausible-pp-level-2}
implausible_pp_level_2 <- 
  media_long %>% 
  group_by(id) %>% 
  summarise(
    above23 = sum(time >= 23),
    below23 = sum(time < 23)
  ) %>% 
  filter(above23 > 1)

# store the IDs
exclusions_pp_2 <- 
  implausible_pp_level_2 %>% 
  pull(id) %>% 
  as.character()
```

There were `r length(exclusions_pp_2)` participants who fell into the second criterion.
In Table \@ref(tab:table-implausible-pp-2) we see that there's mostly participants that fulfill these exclusions who completed only a wave or two, so there's most likely a correlation between their motivation to participate and how seriously they took the survey.
```{r table-implausible-pp-2, echo=FALSE}
knitr::kable(
  head(implausible_pp_level_2, n = 15),
  caption = "Proportion of respondents who reported more than one instance of 23h use across waves"
)
```

By the same logic, some weeks might feel very intense, and participants surely didn't keep track of what they reported for use throughout all media.
So it's possible if we add up all times, there'll be instances where the sum is above 24h, even around 48h.
After all, participants can multitask, but if they use three media at the same time for 16 hours, that's 48h.
I'd say that can happen theoretically, but not over multiple weeks.
So if there's more than one wave where the total is equal to or above 48h, I don't think the participant read the question correctly.
```{r implausible-pp-level-3}
# get total time
working_file <- 
  working_file %>% 
  mutate(
    total_time = rowSums(select(., contains("time")))
  )

# get counts of more than 48h total time
implausible_pp_level_3 <- 
  working_file %>% 
  group_by(id) %>% 
  summarise(
    above48_count = sum(total_time >= 48)
  ) %>% 
  filter(above48_count > 1)

# store the IDs
exclusions_pp_3 <- 
  implausible_pp_level_3 %>% 
  pull(id) %>% 
  as.character()
```

In Table \@ref(tab:table-implausible-pp-3) we see that there's a bunch of participants who had 48h of total media use more than once (in total `r length(exclusions_pp_3)`).
```{r table-implausible-pp-3, echo=FALSE}
knitr::kable(
  head(implausible_pp_level_3, n = 15),
  caption = "Respondents who reported a total media use time of 48h or more across multiple weeks"
)
``` 

Last, let's check how many unique participants we'd need to exclude if we applied all three of those exclusion criteria (taking into account overalp).
```{r implausible-values-pp-overlap}
exclusions_pp <- 
  c(exclusions_pp_1, exclusions_pp_2, exclusions_pp_3) %>% 
  unique()
```

#### Wave-level

As for implausible values on the wave-level, I'll apply the following criteria:

1. Any wave that has more than two estimates of using a medium for 16h+.
2. Any wave where the sum of use times is above 64h.
3. Any wave where a participant estimated use of 23h or more.

Again, it's probably not uncommon to report a high number if I went on a reading-binge.
But I'd say if you sleep eight hours, reporting the rest of the time twice for a wave is suspicious, so there's probably a typo or someone didn't take the question seriously.
```{r implausible-wave-level-1}
implausible_wave_level_1 <- 
  media_long %>%
  group_by(id, wave) %>% 
  summarise(
    two16s = sum(time >= 16)
  ) %>% 
  filter(two16s > 1)

# store the rows that were above that threshold
exclusions_wave_1 <- 
  implausible_wave_level_1 %>% 
  select(id, wave)
```

Overall, we have `r nrow(exclusions_wave_1)` rows of data we need to exclude from `r length(unique(exclusions_wave_1$id))` participants.
However, of those, `r sum(unique(exclusions_wave_1$id) %in% exclusions_pp)` were already identified as suspicious in the participant-level exclusions.

Next, we inspect waves where even excessive multitasking per day exceeds a reasonable threshold.
If someone multitasked with three media every waking hour, they'd have 16h x 3 = 48h.
Therefore, we exclude waves where the sum of use times is equal or above four times all day multitasking: 16h x 3 = 64.
```{r implausible-wave-level-2}
implausible_wave_level_2 <- 
  working_file %>% 
  mutate(
    total_time = rowSums(select(., contains("time")))
  ) %>% 
  filter(total_time >= 64) %>% 
  select(id, wave, contains("time"))

# store the rows
exclusions_wave_2 <- 
  implausible_wave_level_2 %>% 
  select(id, wave)
```

For this criterion, we have `r nrow(exclusions_wave_2)` rows of data we need to exclude from `r length(unique(exclusions_wave_2$id))` participants.
However, of those, `r sum(unique(exclusions_wave_2$id) %in% exclusions_pp)` were already identified as suspicious in the participant-level exclusions.

Last on the wave-level, we want to exclude any row where participants estimated 23h of daily use of any medium.
Maybe one can multitask with three media for 16h a day, but an average use of 23h **daily** for a week is close to impossible.
On the participant level, we already had an exclusion criterion where all of people's rows were excluded if they had more than one estimate of 23h (across all waves).
```{r implausible-wave-level-3}
implausible_wave_level_3 <- 
  media_long %>%
  group_by(id, wave) %>% 
  summarise(
    max_time = max(time)
  ) %>% 
  filter(max_time >= 23)

# store the rows that were above that threshold
exclusions_wave_3 <- 
  implausible_wave_level_3 %>% 
  select(id, wave)
```

For this criterion, we have `r nrow(exclusions_wave_3)` rows of data we need to exclude from `r length(unique(exclusions_wave_3$id))` participants.
However, of those, `r sum(unique(exclusions_wave_3$id) %in% exclusions_pp)` were already identified as suspicious in the participant-level exclusions.

Before I remove those cases and rows from the data, I'll go to response patterns. 
I'll do the actual exclusions at the end of this section. 

### Response patterns

In surveys, people who didn't take the study seriously often provide implausible values (see section above), rush, or have response patterns.
Out of experience, response patterns are an indicator of poor data quality.
I'll mostly be looking at straightlining, so selecting the same answer option for each item in a scale.
Usually, straightlining isn't uncommon for, say, well-being scales, so I don't want to be too strict here and exclude valid cases.

Also, if participants repeatedly provide the same time estimate **across** different media, I'd be suspicious of their responses.

1. Anyone who straightlined on more than two of the identity scales (minimum of three media).
2. Anyone who has the same total time in each wave (minimum three media and waves).

For the first criterion, we calculate the variance for each identity scale (provided participants provided a response).
If someone straightlined at three (of at least three) scales, I wouldn't trust them to take the survey seriously.
Note that magazines and audio books didn't have identity questions.
```{r pattern-pp-level-1}
exclusions_pp_4 <- 
  working_file %>% 
  
  # create the variance variables per row
  rowwise() %>% 
  mutate(
    
    # music identity variance
    music_identity_sd = sd(
      c_across(starts_with("music_identity")),
      na.rm = TRUE
    ),
    
    # films identity variance
    films_identity_sd = sd(
      c_across(starts_with("films_identity")),
      na.rm = TRUE
    ),
    
    # tv identity variance
    tv_identity_sd = sd(
      c_across(starts_with("tv_identity")),
      na.rm = TRUE
    ),
    
    # games identity variance
    games_identity_sd = sd(
      c_across(starts_with("games_identity")),
      na.rm = TRUE
    ),
    
    # epublishing identity variance
    e_publishing_identity_sd = sd(
      c_across(starts_with("e_publishing_identity")),
      na.rm = TRUE
    )
  ) %>% 
  unnest(cols = c()) %>% 
  
  # we're only looking at the first wave where the identity questions were asked
  group_by(id) %>% 
  filter(wave == 1) %>% 
  ungroup() %>% 
  
  # now we check who answered at least three identity scales by summing the filer questions
  mutate(
    media_number = rowSums(select(., filter_music:filter_ebooks)),
    at_least_three = if_else(media_number >= 3, 1, 0)
  ) %>% 
  filter(at_least_three == 1) %>% 
  
  # create a variable that counts how many of the variances are zero
  mutate(
    multiple_straightlines = rowSums(select(., ends_with("_sd")) == 0)
  ) %>% 
  filter(multiple_straightlines > 2) %>% 
  
  # and select participants
  pull(id) %>% 
  as.character()
```

For this criterion, we have `r length(exclusions_pp_4)` participants.
Of those, `r sum(exclusions_pp_4 %in% exclusions_pp)` were already identified as suspicious in the participant-level exclusions previously.

On to the second criterion: Someone might be very consistent and provide the same use times at each wave (excluding nonzero estimates).
However, if a person provides the same use estimates for each medium across all waves (minimum three waves), I'd say they're just trying to get the survey done and rely on the time that they survey prompted.

So below I'll check who has the same total time (i.e., reporting the same time across all media) in all of their waves.
To avoid excluding people for whom this occurred only once, I'll set a minimum of three media and three waves.
```{r pattern-pp-level-2}
# get participants who have at least three waves and media use estimates
three_media_and_waves <- 
  working_file %>% 
  mutate(
    media_number = rowSums(select(., starts_with("filter"))) # minimum three media
  ) %>% 
  filter(media_number >= 3) %>% 
  count(id) %>% # count waves
  filter(n >= 3) %>% 
  pull(id) %>% 
  as.character()

# then filter by those participants and check how many times their total times are constant
exclusions_pp_5 <- 
  working_file %>% 
  filter(id %in% three_media_and_waves) %>% 
  select(id, wave, total_time) %>% 
  group_by(id) %>%
  summarise(
    distinct_times = n_distinct(total_time)
  ) %>%
  filter(distinct_times == 1) %>% 
  pull(id) %>% 
  as.character()
```

Only `r length(exclusions_pp_5)` participants fulfilled this criterion.
Of those, `r sum(exclusions_pp_5 %in% exclusions_pp)` were already identified as suspicious in the participant-level exclusions previously.

Alright, let's add those participants with response patterns to those with implausible values.
```{r pattern-pp-overlap}
exclusions_pp <- 
  c(exclusions_pp, exclusions_pp_4, exclusions_pp_5) %>% 
  unique()
```

### Applying exclusions

As a last step, we exclude those participants whom we identified as having low data quality.
How many people we exclude will depend on what our starting sample is.
Currently, we still have the whole sample, but for the analysis, we'll restrict valid cases to those who responded to a certain number of waves.

Below in Table \@ref(tab:show-pp-exclusions) I'll show, per wave, how many people we'd exclude for each exclusion criterion plus what proportion of the valid sample (aka how many participants have at least that many waves) we have left.
 
Note that some participants fulfill multiple exclusions, so the last columns shows the cumulative exclusions and proportion of the respective sample. 
For the analysis, mixed-effects models weigh participants with more data more heavily, which means we can use everyone with at least three waves (because we used lagged predictors).
```{r show-pp-exclusions, echo=FALSE}
# a data frame that simply counts the data points per participant
waves_per_id <- 
  working_file %>% 
  count(id)

# we take the completion table from above so we have the wave and cumulative number of participants at that wave
# then I apply the exclusion function (see custom functions in the setting up chapter) to see, per wave, how many exclusions we'd have with each exclusion criterion
completion_table %>% 
  select(Waves, `Participants per wave`) %>% 
  rename(N = `Participants per wave`) %>% 
  rowwise() %>% 
  mutate(
    
    # exclusion 1
    "Exclusion 1" = apply_exclusion(Waves, exclusions_pp_1),
    "Exclusion 1 %" = round(1 - (`Exclusion 1` / N), digits = 4) * 100,
    
    # exclusion 2
    "Exclusion 2" = apply_exclusion(Waves, exclusions_pp_2),
    "Exclusion 2 %" = round(1 - (`Exclusion 2` / N), digits = 4) * 100,
    
    # exclusion 3
    "Exclusion 3" = apply_exclusion(Waves, exclusions_pp_3),
    "Exclusion 3 %" = round(1 - (`Exclusion 3` / N), digits = 4) * 100,
    
    # exclusion 4
    "Exclusion 4" = apply_exclusion(Waves, exclusions_pp_4),
    "Exclusion 4 %" = round(1 - (`Exclusion 4` / N), digits = 4) * 100,
    
    # exclusion 5
    "Exclusion 5" = apply_exclusion(Waves, exclusions_pp_5),
    "Exclusion 5 %" = round(1 - (`Exclusion 5` / N), digits = 4) * 100,
    
    # cumulative
    "Exclusion all" = apply_all_exclusions(Waves),
    "Exclusion all %" = round(1 - (`Exclusion all` / N), digits = 4) * 100
  ) %>% 
  
  # hm, the table is quite wide like this, so I'll turn it into the long format
  pivot_longer(
    N:`Exclusion all %`
  ) %>% 
  pivot_wider(
    names_from = Waves,
    values_from = value,
    names_prefix = "Wave "
  ) %>% 
  rename(
    Participants = name
  ) %>% 
  knitr::kable(
    .,
    caption = "Exclusions depending on how many minimum waves participants must have"
  )
```

Let's also combine all wave-level exclusions.
```{r combine-wave-exclusions}
# first, I'll combine all three wave-level exclusions
exclusions_wave <- 
  full_join(
    exclusions_wave_1,
    exclusions_wave_2
  ) %>% 
  full_join(
    .,
    exclusions_wave_3
  ) %>% 
  ungroup() %>% 
  distinct()
```

Before we apply the exclusions, let's first create a data frame which we can use later to plot exclusions for the paper.
It'll be similar to the one above, but restricted to those with at least three waves, because those are the ones we ultimately use for the analysis.
The code below might duplicate some of the work of previous and later code, but I came back here for creating a plot for the paper, so I didn't want to break anything.
```{r get-exclusion-plot-data}
# vectors holding number of participants and number of observations
PPs <- c()
Observations <- c()

# temp data set of people with at least three waves
dat <- 
  working_file %>% 
  group_by(id) %>% 
  filter(n() >= 3) %>% 
  ungroup()

# the exclusions we iterate over
exclusions <- 
  list(
    exclusions_pp_1,
    exclusions_pp_2,
    exclusions_pp_3,
    exclusions_pp_4,
    exclusions_pp_5,
    exclusions_wave_1,
    exclusions_wave_2,
    exclusions_wave_3
  )

# iterate over each exclusion criterion list/tibble and extract how many are left after excluding those
for (i in exclusions) {
  if(!is_tibble(i)){
    PPs <- c(PPs, dat %>% filter(!id %in% i) %>% summarise(PPs = length(unique(id))) %>% pull(PPs))
    Observations <- c(Observations, dat %>% filter(!id %in% i) %>% summarise(n = n()) %>% pull(n))
  } else{
    PPs <- 
      c(
        PPs,
        anti_join(
          dat,
          i
        ) %>% 
          summarise(PPs = length(unique(id))) %>% 
          pull(PPs)
      )
    Observations <- 
      c(
        Observations,
        anti_join(
          dat,
          i
        ) %>% 
          summarise(n = n()) %>% 
          pull(n)
      )
  }
}

# our data for the plot
exclusion_plot_data <- 
  tibble(
    "Type" = c(rep("Participant-level", 5), rep("Wave-level", 3), "Total", "Total Before"),
    "Exclusion" = c(1:5, 1:3, "Total", "Total Before"),
    "PPs" = c(
      PPs,
      dat %>% 
        filter(!id %in% exclusions_pp) %>% 
        anti_join(
          .,
          exclusions_wave
        ) %>% 
        group_by(id) %>% 
        filter(n() >= 3) %>% 
        ungroup() %>% 
        summarise(
          n = length(unique(id))
        ) %>% 
        pull(n),
      length(unique(dat$id))
    ),
    "Observations" = c(
      Observations,
      dat %>% 
        filter(!id %in% exclusions_pp) %>% 
        anti_join(
          .,
          exclusions_wave
        ) %>% 
        group_by(id) %>% 
        filter(n() >= 3) %>% 
        ungroup() %>% 
        summarise(
          n = n()
        ) %>% 
        pull(n),
      nrow(dat)
    )
  )

# clear workspace
rm(PPs, Observations, exclusions, dat)
```

Let's apply participant-level exclusions.
```{r apply-pp-exclusions}
# exclusions_pp contains all participant-level exclusions
working_file <- 
  working_file %>% 
  filter(!id %in% exclusions_pp)
```

Now that we've applied the participant-level exclusions, we also need to take a look at wave-level exclusions.
It's quite possible that having excluded participants with low-quality data already excluded many of their low-quality rows as well.

I'll check how many rows that we intended to exclude on the wave-level are already not in the data set anymore because the entire participant that row belongs to was excluded during participant-level exclusions.
```{r compare-wave-pp-exclusions}
anti_join(
  exclusions_wave,
  working_file,
  by = c("id", "wave")
) %>% 
  nrow()
```

Let's take the data set after participant exclusions, exclude low-quality rows (i.e., waves) and count the number of waves again.

Table \@ref(tab:show-wave-exclusions) shows the number of participants with at least a number of waves (after participant-level exclusions) next to the same number after excluding on the wave-level.
The sharpest drop is in the number of people who previously had completed six waves.
That's not surprising because each unique participant in `exclusions_wave` (`r length(unique(exclusions_wave$id))` participants) who had previously completed six waves now drops down to five waves.
Probably there's a correlation between sticking around for this long and motivation, such that motivation drops in later waves and there's a higher chance to fulfill one of the exclusion criteria.
**Overall, `r 100 - round(nrow(anti_join(working_file, exclusions_wave)) / nrow(working_file), digits =4) * 100`% of rows are excluded.**
```{r show-wave-exclusions, echo=FALSE}
# let's get the table
working_file %>% 
  count(id) %>% 
  count(n) %>% 
  rename(
    "Waves" = n
  ) %>% 
  mutate(
    "Participants per wave" = rev(cumsum(rev(nn))) # same as above, get number with at least that many rows
  ) %>% 
  select(-nn) %>% 
  left_join( # then add how many are left after doing row-wise exclusions
    .,
  anti_join( # don't keep any rows that are in the exclusions for wave
    working_file,
    exclusions_wave
  ) %>% 
    count(id) %>% 
    count(n) %>% 
    rename( # same as above, getting participants with at least that many rows but after exclusions
      "Waves" = n
    ) %>% 
  mutate(
    "Participants per wave after exclusions" = rev(cumsum(rev(nn)))
  ) %>% 
    select(-nn)
  ) %>% 
  mutate( # get proportion in reduction
    "Reduction proportion %" = round(1 - (`Participants per wave after exclusions` / `Participants per wave`), digits = 4) * 100
  ) %>% 
  knitr::kable(
    .,
    caption = "Participants with at least a number of waves before and after wave-level exclusion"
  )
```

During model fitting, we'll predict the outcome with the lagged value of the predictor.
If we merely exclude the rows participants will have gaps in their waves.
For example, a participant might have entries for waves 1-4, but wave 3 belongs to low-quality data rows.
We'd then be left with rows 1,2, and 4.
During model fitting, just lagging the value would mean the outcome at wave 4 is predicted by the predictor at wave 2 - effectively messing up our one-week lag between waves.

Therefore, it makes sense to maintain those rows whose data we exclude, but set them to `NA`.
This way, we don't have "gaps" between waves.
In addition, if we want to impute missing values during model fitting (via the built-in `brms` imputation), we want to be able to know what value to impute, which is why we need the `NA` signal.

Let's make those rows that have low quality data, then set all wave-level entries to `NA` on those rows.
```{r apply-wave-exclusions}
# add marker to wave-level exclusions
exclusions_wave <- 
  exclusions_wave %>% 
  mutate(set_to_na = 1)

# add that marker to working file
working_file <- 
  left_join(
    working_file,
    exclusions_wave,
    by = c("id", "wave")
  )

# then set all wave-level entries to NA that have a marker
working_file <-
  working_file %>% 
  mutate(
    across(
      c(
        music_hours:well_being_2,
        music_time:total_time
      ),
      ~ replace(.x, set_to_na == 1, NA)
    )
  ) %>% 
  # remove marker
  select(-set_to_na)
```

## Build scales

As a last step, we're creating the mean score scales.

Before we do that, we have to reverse code some items.
`identity` items had strongest agreement as 1.
I find it more intuitive when larger numbers mean more agreement.
The same applies to the well-being item about anxiety, which I will reverse code.
```{r reverse-code}
working_file <- 
  working_file %>% 
  mutate(
    across(
      contains("identity"),
      ~ 5 - .x
    ),
    
    well_being_2 = 10 - well_being_2 # starts at 0
  )
```


Let's start with the identity scales; for each medium (except magazines and audiobooks), participants indicated how much that medium was part of their identity.
```{r build-identity-scales}
working_file <- 
  working_file %>% 
  mutate(
    
    # music
    music_identity = rowMeans(select(., starts_with("music_identity"))),
    
    # films
    films_identity = rowMeans(select(., starts_with("films_identity"))),
    
    # tv
    tv_identity = rowMeans(select(., starts_with("tv_identity"))),
    
    # games
    games_identity = rowMeans(select(., starts_with("games_identity"))),
    
    # epublishing
    e_publishing_identity = rowMeans(select(., starts_with("e_publishing_identity"))),
  )
```

And the well-being scales per wave (aka row).
```{r build-well-being-scales}
working_file <- 
  working_file %>% 
  mutate(
    life_satisfaction = rowMeans(select(., starts_with("life_satisfaction"))),
    affect = rowMeans(select(., starts_with("well_being"))),
    well_being = rowMeans(select(., starts_with("well_being"), starts_with("life_satisfaction"))) # both affect and well-being combined
  )
```

Before we move on to visualizations and descriptive info, I'll do some housekeeping.
I'll reorder some variables for cosmetic purposes, only select those we need, and clean the workspace.
```{r housekeeping-processing}
# select relevant variables
working_file <- 
  working_file %>% 
  select(
    id, 
    gender,
    wave:filter_audiobooks,
    starts_with("music"),
    starts_with("films"),
    starts_with("tv"),
    starts_with("games"),
    starts_with("e_publishing"),
    starts_with("books"),
    starts_with("magazines"),
    starts_with("audiobooks"),
    total_time,
    starts_with("life_satisfaction"),
    starts_with("well_being"),
    affect,
    -ends_with("hours"), # we got the total time from here on
    -ends_with("minutes"),
  )

# clean workspace
rm(
  markers,
  no_changes,
  waves_per_id,
  an_id,
  id_counter,
  id_to_match,
  ids,
  temp_id,
  three_media_and_waves
)
```

And then remove those who don't have at least three waves.
For one model part, we'll used led values, so two waves won't be enough because that means a participant is left with only one wave once we lead a predictor.

Also, some participants now have missing values (because we applied the wave-level exclusions).
Missing values will be removed during model fitting, meaning that if someone has three waves, but two of them are `NA`, they'll be left with one wave of data.
So I'll filter the data set to only keep those with at least three waves with responses.
```{r only-keep-five-waves}
# get ids of participants who have at least three valid waves
at_least_three <- 
  working_file %>% 
  group_by(id) %>% 
  filter(!is.na(music_time)) %>% 
  filter(n() >= 3) %>% 
  ungroup() %>% 
  pull(id)

# then only keep those participants
working_file <- 
  working_file %>% 
  filter(id %in% at_least_three)

# remove from workspace
rm(at_least_three)
```
