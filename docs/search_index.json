[
["index.html", "No effect of different types of media on well-being Preface 0.1 Data and models 0.2 How to reproduce processing and analyses", " No effect of different types of media on well-being Niklas Johannes, Tobias Dienlin, Hasan Bakhshi, and Andrew K. Przybylski 2021-01-13 Preface On this site, I document all steps, from data processing to final analyses, for the project No effect of different types of media on well-being. Link to the preprint: &lt;&gt; 0.1 Data and models The data and models are on the Open Science Framework page of this project at https://osf.io/yn7sx/. You’ll see that there are different components. One component holds the raw data. These data were processed before uploading because they contained other variables that we were not allowed to share. You can see those processing steps in the processing section on the next page. Another component holds model objects. We ran 28 total models, and each one is about one GB large. You’ll see in the analysis section that we downloaded those models and loaded them into R for model inspection and diagnostics. 0.2 How to reproduce processing and analyses All processing, analysis, description, and modelling steps organized into separate R Markdown files. The source code is on GitHub: https://github.com/digital-wellbeing/cultural-consumption. Those source files are organized as an R bookdown project. That project was knitted to an online book, whose results are at https://digital-wellbeing.github.io/cultural-consumption/. The project used a local library to make sure package versions are stable for anyone who wants reproduce the analysis. We used renv for that. If you want to reproduce the entire book, it’s best to download the entire R project from the Github repo: https://github.com/digital-wellbeing/cultural-consumption. As a first step, open the project and make sure you have all packages installed in the right version by calling renv::restore(). That’ll install all packages in the version that are saved in the lockfile of the project (renv.lock). For that, it’s best if you are on R 4.0.1 or higher. Once all packages are installed, you should be able to build the book and reproduce all files that are displayed at https://digital-wellbeing.github.io/cultural-consumption/. To do that, either run bookdown::render_book(\"index.Rmd\") or click the “Build Book” button under the Build tab in RStudio. Each .Rmd source file will be knitted and stored in a docs folder. You can double click on docs/index.html and view the results in a web browser. You’ll see that the source code doesn’t run the models anymore. In total, running each chunk would take the good part of a week on a modern 4-core laptop. I ran them once and them stored them on the OSF. In the source code, you can download those files (note: downloading the models will take some time, they’re 34GB in total). To download the models, make sure the chunk option for chunk download-models in the analysis chapter is set to eval=TRUE. If you want to run the models rather than downloading them and loading them into R, you can either set chunk options to eval=TRUE or run each of the five .Rmd files separately. I set this book up so that it runs in one go, meaning you need to run the source files in their order, and can’t run source files independently. The same goes for the data: You’ll need to set the chunk download-data to eval=TRUE. That only works when the OSF project is public. If it isn’t (because of peer review), you’ll need to manually download the data files from the OSF into a data/ folder in the main directory of the project. "],
["setting-up.html", "1 Setting-up", " 1 Setting-up In this section, I load all libraries and define all custom functions that we need for data processing and analysis. Note I use the pacman package for loading libraries. # pacman makes it easier to load and install packages if (!requireNamespace(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) library(pacman) # load packages p_load( tidyverse, here, ggridges, cowplot, kableExtra, directlabels, GGally, lavaan, brms, ggbeeswarm, osfr ) # set seed set.seed(42) # set theme theme_set(theme_cowplot()) # custom colors that are color blind friendly cb_palette &lt;- c(&quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;) # chunk options knitr::opts_chunk$set( message = FALSE, warning = FALSE ) Below the functions I use throughout the script. They’re usually explained in the section where I use them. dens_with_points &lt;- function( data, variable ) { p &lt;- ggplot(data, aes_string(x = variable, y = 0)) + geom_density_ridges( jittered_points = TRUE, position = &quot;raincloud&quot;, fill = &quot;darkslateblue&quot;, point_color = &quot;darkslateblue&quot;, color = &quot;darkslateblue&quot;, alpha = 0.5 ) + theme_cowplot() + theme( axis.line=element_blank(), axis.text.y=element_blank(), axis.ticks=element_blank(), axis.title.y=element_blank(), axis.title.x=element_blank(), legend.position=&quot;none&quot;, panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank() ) return(p) } # function that applies the exclusion criterion, taking the number of waves as argument plus the list of to be excluded participants apply_exclusion &lt;- function( wave_number, exclusion_criterion ){ N &lt;- working_file %&gt;% filter(id %in% (waves_per_id %&gt;% filter(n &gt;= wave_number) %&gt;% pull(id))) %&gt;% # select only those with at least this many waves group_by(id) %&gt;% slice(1) %&gt;% filter(!id %in% exclusion_criterion) %&gt;% nrow() return(N) } # the same function as above, but this time applying all exclusions at the same time apply_all_exclusions &lt;- function( wave_number ){ N &lt;- working_file %&gt;% filter(id %in% (waves_per_id %&gt;% filter(n &gt;= wave_number) %&gt;% pull(id))) %&gt;% group_by(id) %&gt;% slice(1) %&gt;% filter(!id %in% exclusions_pp) %&gt;% nrow() return(N) } # raincloud plot function from https://github.com/RainCloudPlots/RainCloudPlots/blob/master/tutorial_R/R_rainclouds.R # Defining the geom_flat_violin function ---- # Note: the below code modifies the # existing github page by removing a parenthesis in line 50 &quot;%||%&quot; &lt;- function(a, b) { if (!is.null(a)) a else b } geom_flat_violin &lt;- function(mapping = NULL, data = NULL, stat = &quot;ydensity&quot;, position = &quot;dodge&quot;, trim = TRUE, scale = &quot;area&quot;, show.legend = NA, inherit.aes = TRUE, ...) { layer( data = data, mapping = mapping, stat = stat, geom = GeomFlatViolin, position = position, show.legend = show.legend, inherit.aes = inherit.aes, params = list( trim = trim, scale = scale, ... ) ) } #&#39; @rdname ggplot2-ggproto #&#39; @format NULL #&#39; @usage NULL #&#39; @export GeomFlatViolin &lt;- ggproto(&quot;GeomFlatViolin&quot;, Geom, setup_data = function(data, params) { data$width &lt;- data$width %||% params$width %||% (resolution(data$x, FALSE) * 0.9) # ymin, ymax, xmin, and xmax define the bounding rectangle for each group data %&gt;% group_by(group) %&gt;% mutate( ymin = min(y), ymax = max(y), xmin = x, xmax = x + width / 2 ) }, draw_group = function(data, panel_scales, coord) { # Find the points for the line to go all the way around data &lt;- transform(data, xminv = x, xmaxv = x + violinwidth * (xmax - x) ) # Make sure it&#39;s sorted properly to draw the outline newdata &lt;- rbind( plyr::arrange(transform(data, x = xminv), y), plyr::arrange(transform(data, x = xmaxv), -y) ) # Close the polygon: set first and last point the same # Needed for coord_polar and such newdata &lt;- rbind(newdata, newdata[1, ]) ggplot2:::ggname(&quot;geom_flat_violin&quot;, GeomPolygon$draw_panel(newdata, panel_scales, coord)) }, draw_key = draw_key_polygon, default_aes = aes( weight = 1, colour = &quot;grey20&quot;, fill = &quot;white&quot;, size = 0.5, alpha = NA, linetype = &quot;solid&quot; ), required_aes = c(&quot;x&quot;, &quot;y&quot;) ) # function that returns summary stats describe &lt;- function( dat, variable, trait = FALSE ){ # if variable is not repeated-measures, take only one measure per participant if (trait == TRUE){ dat &lt;- dat %&gt;% group_by(id) %&gt;% slice(1) %&gt;% ungroup() } # then get descriptives descriptives &lt;- dat %&gt;% filter(!is.na(UQ(sym(variable)))) %&gt;% # remove missing values summarise( across( !! variable, list( N = ~ n(), mean = mean, sd = sd, median = median, min = min, max = max, cilow = ~Rmisc::CI(.x)[[3]], # lower CI cihigh = ~Rmisc::CI(.x)[[1]] # upper CI ) ) ) descriptives &lt;- descriptives %&gt;% # only keep measure rename_all( ~ str_remove( ., paste0(variable, &quot;_&quot;) ) ) %&gt;% mutate( variable = variable, range = max - min ) %&gt;% relocate(variable) %&gt;% relocate( range, .after = max ) return(descriptives) } # a single raincloud plot single_cloud &lt;- function( raw_data, summary_data, variable, color, title, trait = FALSE ){ # take only one row per person if it&#39;s a trait variable if (trait == TRUE){ raw_data &lt;- raw_data %&gt;% group_by(id) %&gt;% slice(1) %&gt;% ungroup() } # the plot p &lt;- ggplot( raw_data %&gt;% mutate(Density = 1), aes( x = Density, y = get(variable) ) ) + geom_flat_violin( # the &quot;cloud&quot; position = position_nudge(x = .2, y = 0), adjust = 2, color = NA, fill = color, alpha = 0.5 ) + geom_point( # the &quot;rain&quot; position = position_jitter(width = .15), size = 1, color = color, alpha = 0.5 ) + geom_point( # the mean from the summary stats data = summary_data %&gt;% filter(variable == !! variable) %&gt;% mutate(Density = 1), aes( x = Density + 0.175, y = mean ), color = color, size = 2.5 ) + geom_errorbar( # error bars data = summary_data %&gt;% filter(variable == !! variable) %&gt;% mutate(Density = 1), aes( x = Density + 0.175, y = mean, ymin = cilow, ymax = cihigh ), width = 0, size = 0.8, color = color ) + ylab(title) + theme( axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.ticks.x = element_blank(), axis.title.y = element_blank(), axis.line = element_blank() ) + guides( color = FALSE, fill = FALSE ) + coord_flip() return(p) } lm_function &lt;- function( data, mapping, ... ){ p &lt;- ggplot( data = data, mapping = mapping ) + geom_point( color = &quot;#56B4E9&quot;, alpha = 0.5 ) + geom_smooth( method=lm, fill=&quot;#0072B2&quot;, color=&quot;#0072B2&quot;, ...) p } dens_function &lt;- function( data, mapping, ... ){ p &lt;- ggplot( data = data, mapping = mapping ) + geom_density(fill = &quot;#009E73&quot;, color = NA, alpha = 0.5) } model_diagnostics &lt;- function( model ){ plot_grid( pp_check( model, type = &quot;dens_overlay&quot;, nsamples = 100 ), pp_check( model, type = &quot;loo_pit_qq&quot;, nsamples = 100 ), pp_check( model, type = &quot;loo_pit_overlay&quot;, nsamples = 100 ), pp_check( model, type = &quot;stat&quot;, stat = &quot;median&quot;, nsamples = 100 ), pp_check( model, type = &quot;stat&quot;, stat = &quot;mean&quot;, nsamples = 100 ), labels = c(&quot;Density overlay&quot;, &quot;LOO-PIT QQ&quot;, &quot;LOO-PIT Uniform&quot;, &quot;Predicted medians&quot;, &quot;Predicted means&quot;), ncol = 2, label_size = 8, hjust = 0, vjust = 0, label_x = 0, label_y = 0.93 ) } "],
["data-processing.html", "2 Data processing 2.1 Read waves 2-6 2.2 Read wave 1 2.3 Data cleaning 2.4 Response rates and missing values 2.5 Data quality and exclusions 2.6 Build scales", " 2 Data processing In this section I’ll process the raw data so that I can use them for analysis in the next section. Note that the data were slightly preprocessed: I only selected variables that we use for processing and analysis here. Other than that, the data were untouched. The data are on the OSF. You can download them if you set the code chunk below to eval=TRUE. Downloading only works when the OSF project is public. If it isn’t during peer review, you’ll need to paste the data files from the OSF to the data/ folder manually. # # create directory # dir.create(&quot;data/&quot;, FALSE, TRUE) # # # download models # osf_retrieve_node(&quot;https://osf.io/yn7sx/&quot;) %&gt;% # osf_ls_nodes() %&gt;% # filter(name == &quot;data&quot;) %&gt;% # osf_ls_files( # ., # n_max = Inf # ) %&gt;% # osf_download( # ., # path = here(&quot;data&quot;), # progress = TRUE # ) 2.1 Read waves 2-6 We’ll start with loading the data for waves 2 to 6. We start here instead of wave 1 because participant identification isn’t super straightforward. A participant doesn’t get a single unique identifier that’s stable across all waves. Instead, participants start with an ID in wave 1 (called transaction_idOld in the wave 2 to 6 data) and get a new unique ID for wave 2 and so on. I believe originally the researchers wanted to go with a single ID, but changed their mind. Look at the data table below (2.1), where I made up two participants to recreate the data structure. We see that the first participant has an transaction ID (transaction_idOld) for the first wave. The same participant then has that same old transaction ID for wave two, plus a new transaction ID for wave 2 (transaction_id). Here’s where it gets a bit complicated: That transaction ID for wave 2 is repeated on wave 3, but with a different name (transaction_idW2). Next to that new variable, is the unique ID for that wave (transaction_idW3). After that, each new wave has the ID of the previous wave plus a new ID for the current wave. Table 2.1: Example of how ID variables look like id transaction_old transaction_id transaction_idW2 transaction_idW3 transaction_idW4 transaction_idW5 transaction_idW6 week 1 978344791 NA NA NA NA NA NA 1 1 978344791 987910814 NA NA NA NA NA 2 1 NA NA 987910814 994717737 NA NA NA 3 1 NA NA NA 994717737 998317051 NA NA 4 1 NA NA NA NA 998317051 1005222579 NA 5 1 NA NA NA NA NA 1005222579 1018946937 6 2 978344792 NA NA NA NA NA NA 1 2 978344792 987910815 NA NA NA NA NA 2 2 NA NA 987910815 NA NA NA NA 3 2 NA NA NA NA NA NA NA 4 2 NA NA NA NA NA NA NA 5 2 NA NA NA NA NA NA NA 6 Unfortunately, the id column from the example isn’t included in the raw data, so we’ll have to recreate participant IDs that are constant across waves. I solved this problem with a loop, which is definitely not the most elegant way to go about this, but I think it gets the job done. First, lets load the data. waves_2_to_6 &lt;- read_csv( here(&quot;data&quot;, &quot;waves_2_to_6.csv&quot;), guess_max = 2e4 ) Next, the logic behind assigning the constant IDs. We’ll start at the ID of wave 2, find the ID of wave 3 that’s on the same line as the ID of wave 2 and store the ID for wave 3. We repeat this procedure for all waves and in the end assign an ID to those rows that have the IDs we extracted on any of the ID variables. The steps, concretely: We store all IDs (so that’s the IDs of wave 2) in a vector (excluding NAs). Initiate an ID counter (i.e., the participant number we assign later). We iterate over each wave 2 ID. If participants did participate in a wave, we find the wave 3 ID that is on the same row as the wave 2 that we’re currently looking for. We now look for the wave 3 ID and store the wave 4 ID that’s on the same line. We repeat that until we’re at the last ID and have all IDs for that participant stored in a vector. Then a row gets assigned the participant ID (to the existing, but empty id variable) if any of the wave ID variables have a match in the extracted IDs. On my machine, the below code takes about three minutes. # the unique wave 2 IDs ids &lt;- waves_2_to_6 %&gt;% pull(transaction_id) %&gt;% na.omit # the participant number we assign later id_counter &lt;- 1 # assign the correct variable type to the empty ID variable that&#39;s already in the data where we&#39;ll assign participant numbers at the end of the loop waves_2_to_6$id &lt;- NA_real_ for (an_id in ids) { # transaction ids that belong to that one participant id_to_match &lt;- c() # add the initial id id_to_match &lt;- c(id_to_match, an_id) # assign that id as temporary ID for which we should match (id_to_match only has one entry so far) temp_id &lt;- id_to_match # at this point, participants might have not participated in the next wave, so they might have an empty cell in # transaction_id2. so we&#39;ll embed everything that follows in their separate if statement if (!is_empty(temp_id)) { # find the transcation_id3 that&#39;s on the same line as transaction_id2 and store it temp_id &lt;- waves_2_to_6 %&gt;% filter(transaction_idW2 == an_id) %&gt;% pull(transaction_idW3) id_to_match &lt;- na.omit(c(id_to_match, temp_id)) # so that NA doesn&#39;t become one of the IDs } if (!is_empty(temp_id)){ # then the same for transaction_id4, but this time we compare to the temporary id we extracted above # also, we only select those rows where the next ID isn&#39;t NA (because there&#39;re two matches for the temp_id) temp_id &lt;- waves_2_to_6 %&gt;% filter((transaction_idW3 == temp_id) &amp; !is.na(transaction_idW4)) %&gt;% pull(transaction_idW4) id_to_match &lt;- c(id_to_match, temp_id) } if (!is_empty(temp_id)){ # then the same as above for transaction_id5 temp_id &lt;- waves_2_to_6 %&gt;% filter((transaction_idW4 == temp_id) &amp; !is.na(transaction_idW5)) %&gt;% pull(transaction_idW5) id_to_match &lt;- c(id_to_match, temp_id) } if (!is_empty(temp_id)){ # and last for transaction_id6 temp_id &lt;- waves_2_to_6 %&gt;% filter((transaction_idW5 == temp_id) &amp; !is.na(transaction_idW6)) %&gt;% pull(transaction_idW6) id_to_match &lt;- c(id_to_match, temp_id) } # then we assign a participant number, such that a participant gets the number for each row where any of their transaction_ids are part of the temporary ids waves_2_to_6 &lt;- waves_2_to_6 %&gt;% mutate( id = case_when( transaction_id %in% id_to_match ~ id_counter, transaction_idW2 %in% id_to_match ~ id_counter, transaction_idW3 %in% id_to_match ~ id_counter, transaction_idW4 %in% id_to_match ~ id_counter, transaction_idW5 %in% id_to_match ~ id_counter, transaction_idW6 %in% id_to_match ~ id_counter, TRUE ~ id ) ) # increase the participant number id_counter &lt;- id_counter + 1 } Before we we assign correct variable types, name factor levels etc. we’ll load wave 1. This way, we can merge the two files first before doing all of the data cleaning, variable selection, and variable renaming. 2.2 Read wave 1 Let’s load the file for wave 1. transcaction_id is the unique identifier for each participant. However, that variables is called transaction_idOld in waves 2 to 6, which is why we name it the same here (see above). Also, dWeekMerged is the wave identifier that’s used in waves 2 to 6, so we’ll include that manually here. wave1 &lt;- read_csv( here(&quot;data&quot;, &quot;wave1.csv&quot;), guess_max = 2e4 ) %&gt;% rename(transaction_idOld = transaction_id) %&gt;% mutate(dWeekMerged = 1) There are many variables we don’t care about, but before we make the variable selection, I’ll first merge the two files. Here’s another complication: If we look at the surveys and how variables are named there, it looks like there are different labels for the same variables in wave 1 and waves 2 to 6. For example, in wave 1, variables providing the estimated time with a medium had the appendix ai and those asking about self-estimated increases or decreases in frequency had the appendix aii. For waves 2 to 6, the surveys say that this is reversed, such that estimated time with a medium has the appendix aii and self-estimated increase or decrease has the appendix ai. The same goes for variable names: For example, the audiobooks section in wave 1 begins with C7c, but with C6c in waves 2 to 6. In the actual data, however, variable names are constant (see the codebook). For example, audiobooks are C7c in both data sets despite what the survey files say. The variable labels are the same across all waves (I manually checked), which makes merging easier. My merging strategy is as follows: I assign the id we created above to the wave1 data file by merging by transaction_idOld which is available in both data sets. However, that means that those who didn’t participate in wave 2 won’t have an id. So we manually fill those empty cells up - although we’ll probably exclude those who only participant in wave 1 later anyways. I then add the rows of waves_2_to_6 to waves1. I use the bind_rows command, which maintains all variables for which there’s no match and sets them to NA - exactly what we want, because full demographics are only in wave 1 and newer questions only in later waves. Note that from now on I leave the raw wave data untouched and make all changes in a working file. # add the id variable to wave1 by merging by transaction_idOld that&#39;s in both data sets working_file &lt;- left_join( wave1, waves_2_to_6 %&gt;% select(transaction_idOld, id), by = &quot;transaction_idOld&quot; ) # assign an id to those in wave 1 who have an NA in the id column because they didn&#39;t participate in later waves # we can do this easily with coalesce, for which we create a vector that continues from the current max ID until each participant with missing ID has one working_file &lt;- working_file %&gt;% mutate( id = coalesce( id, max(working_file$id, na.rm = T)+1:nrow(working_file) ) ) # then add the rows of waves 2 to 6 to wave 1 working_file &lt;- bind_rows( working_file, waves_2_to_6 ) 2.3 Data cleaning Now that each participant has a constant identifier and all waves are merged, we can select those variables we actually need. For our purposes, we’ll retain: demographic information variables indicating what media people used in the past week time estimates of those uses self-estimated importance of the medium self-estimated frequency the estimated effects on well-being in wave 6 Note that there are quite a lot of filtering variables. We can’t collapse these to one variable because these questions were multiple choice. working_file &lt;- working_file %&gt;% select( # meta information id, wave = dWeekMerged, # demographics gender = A4, age = A5, # filter questions: downloaded downloaded_music = B1r1, downloaded_music_videos = B1r2, downloaded_video_games = B1r3, downloaded_software = B1r4, downloaded_films = B1r5, downloaded_tv = B1r6, downloaded_sports = B1r7, downloaded_video_clips = B1r8, downloaded_ebooks = B1r9, downloaded_magazines = B1r10, downloaded_audiobooks = B1r11, downloaded_images = B1r12, downloaded_none = B1r13, # filter questions: streamed streamed_music = B2r1, streamed_music_videos = B2r2, streamed_video_games = B2r3, streamed_software = B2r4, streamed_films = B2r5, streamed_tv = B2r6, streamed_sports = B2r7, streamed_video_clips = B2r8, streamed_ebooks = B2r9, streamed_magazines = B2r10, streamed_audiobooks = B2r11, streamed_images = B2r12, streamed_none = B2r13, # filter questions: shared shared_music = B3r1, shared_music_videos = B3r2, shared_video_games = B3r3, shared_software = B3r4, shared_films = B3r5, shared_tv = B3r6, shared_sports = B3r7, shared_video_clips = B3r8, shared_ebooks = B3r9, shared_magazines = B3r10, shared_audiobooks = B3r11, shared_images = B3r12, shared_none = B3r13, # filter questions: bought bought_music = B4r1, bought_video_games = B4r2, bought_software = B4r3, bought_films = B4r4, bought_tv = B4r5, bought_books = B4r6, bought_magazines = B4r7, bought_audiobooks = B4r8, bought_none = B4r9, # music music_identity_ = C1x1r1:C1x1r7, music_hours = C1x1aiHoursc1, music_minutes = C1x1aiMinutesc2, music_estimate = C1x1aii, # films films_identity_ = C2x1r1:C2x1r7, films_hours = C2x1aiHoursc1, films_minutes = C2x1aiMinutesc2, films_estimate = C2x1aii, # tv tv_identity_ = C3x1r1:C3x1r7, tv_hours = C3x1aiHoursc1, tv_minutes = C3x1aiMinutesc2, tv_estimate = C3x1aii, # video games games_identity_ = C5x1r1:C5x1r7, games_hours = C5x1aiHoursc1, games_minutes = C5x1aiMinutesc2, games_estimate = C5x1aii, # e-publishing e_publishing_identity_ = C7x1r1:C7x1r7, # (e-)books books_hours = C7ax1aiHoursc1, books_minutes = C7ax1aiMinutesc2, books_estimate = C7ax1aii, # magazines magazines_hours = C7bx1aiHoursc1, magazines_minutes = C7bx1aiMinutesc2, magazines_estimate = C7bx1aii, # audiobooks audiobooks_hours = C7cx1aiHoursc1, audiobooks_minutes = C7cx1aiMinutesc2, audiobooks_estimate = C7cx1aii, # well-being life_satisfaction_ = QD2r1:QD2r2, well_being_ = QD2r3:QD2r4 ) Alright, now to transforming all variables to the correct type and assigning informative factor level labels. Note that id now is numeric which can be misleading, which is why I add pp_ (for participant) before the ID number. working_file &lt;- working_file %&gt;% # turn non-numeric variables into factors mutate( across( c( id, gender ), as.factor ) ) %&gt;% # purely cosmetic: arrange by id arrange(id) %&gt;% # give proper labels to demographics mutate( gender = fct_recode( gender, &quot;Male&quot; = &quot;1&quot;, &quot;Female&quot; = &quot;2&quot;, &quot;Other&quot; = &quot;3&quot; ), # add &quot;pp_&quot; prefix to id variable id = as.factor( paste0(&quot;pp_&quot;, id) ) ) For the first wave, participants only responded to questions about how much they used a medium if they indicated that they had used it in the three months before wave 1. Those variables (e.g. bought_books) are only present in wave 1, but NA in the other waves. Therefore, we create new variables that show whether a person was asked to indicate their use of a medium, so if they answered yes to any of the filter variables at the beginning of the wave 1 survey. At this point, those filter variables are still numeric, so we’ll add them up. If they’re above 0, participants were asked about that medium. If they’re 0, participants hadn’t used any of the media in the three months before wave 1 and weren’t asked questions about them. Note that I keep those filter variables as numeric for processing later. After we’re done with the filter variables, we can also delete the individual ones. Note that I first check whether any of those filter variables have missing values, but it seems the survey had forced responses here, so we don’t have missings. # check whether any of the filter variables (at wave 1, when they were asked) have missing values working_file %&gt;% filter(wave == 1) %&gt;% summarise( across( c( starts_with(&quot;downloaded&quot;), starts_with(&quot;streamed&quot;), starts_with(&quot;shared&quot;), starts_with(&quot;bought&quot;) ), ~ unique(is.na(.x)) ) ) %&gt;% pivot_longer( everything(), values_to = &quot;missing&quot; ) %&gt;% summarise( &quot;Number of missings: &quot; = sum(missing) ) ## # A tibble: 1 x 1 ## `Number of missings: ` ## &lt;int&gt; ## 1 0 While we’re at it: All constant wave 1 variables now have NA in the subsequent wave. I’ll set those NAs to the wave 1 value because those are stable demographics that apply to each wave. Note that three demographic questions were asked at each wave, employment status, living siutation, and the consequences of COVID-19. # get filter variables (only present at wave 1) filters &lt;- working_file %&gt;% filter(wave == 1) %&gt;% # the filter per category mutate( filter_music = rowSums( select( ., starts_with(&quot;downloaded_music&quot;), starts_with(&quot;streamed_music&quot;), starts_with(&quot;shared_music&quot;), bought_music ) ), filter_films = rowSums( select( ., downloaded_films, streamed_films, shared_films, bought_films ) ), filter_tv = rowSums( select( ., downloaded_tv, streamed_tv, shared_tv, bought_tv ) ), filter_video_games = rowSums( select( ., downloaded_video_games, streamed_video_games, shared_video_games, bought_video_games ) ), filter_ebooks = rowSums( select( ., downloaded_ebooks, streamed_ebooks, shared_ebooks, bought_books ) ), filter_magazines = rowSums( select( ., downloaded_magazines, streamed_magazines, shared_magazines, bought_magazines ) ), filter_audiobooks = rowSums( select( ., downloaded_audiobooks, streamed_audiobooks, shared_audiobooks, bought_audiobooks ) ) ) %&gt;% # recode depending on whether the sum is zero or not mutate( across( starts_with(&quot;filter&quot;), ~ if_else(.x &gt; 0, 1, 0) ) ) %&gt;% # select variables that are constant across all waves select( id, gender, contains(&quot;identity&quot;), starts_with(&quot;filter&quot;) ) # add those filters and constant variables so that they become a constant for each pp, deleting old filter variables working_file &lt;- left_join( working_file %&gt;% select( -(gender), -contains(&quot;identity&quot;) ), filters, by = &quot;id&quot; ) %&gt;% select( -starts_with(&quot;downloaded&quot;), -starts_with(&quot;streamed&quot;), -starts_with(&quot;shared&quot;), -starts_with(&quot;bought&quot;), ) %&gt;% # some reordering for purely cosmetic purposes select( id:age, starts_with(&quot;filter&quot;), everything() ) # remove the temp filters file rm(filters) 2.4 Response rates and missing values In this section, I check response rates, response patterns, and missing values. The data set is quite complicated because of the many filter variables. The survey had forced responses, so there aren’t any missings if someone finished the survey. However, because of the many filters, there’ll still be a large amount of missing values that we need to inspect or recode. I think the following information is most relevant to understand response and missingness patterns: How many participants have completed each wave. How many responses we have per medium per wave. 2.4.1 Participants per wave First, let’s see how many people completed each wave, what percentage of people have completed that exact number of wave, how many participants that have exactly this number of waves, and what percentage of participants have completed at least this wave (Table 2.2). Table 2.2: Response rates Waves Participants (only that number of waves) Frequency Participants per wave Frequency per wave 1 1071 27.7 3863 100.0 2 423 11.0 2792 72.3 3 237 6.1 2369 61.3 4 185 4.8 2132 55.2 5 873 22.6 1947 50.4 6 1074 27.8 1074 27.8 2.4.2 Responses per wave and medium Okay, next we inspect how many responses we have per medium per wave. The data set gets complicated here. This is where the filtering requires quite some wrangling: Someone who hasn’t listened to music in the three months before wave 1 will have missing values on all items about music - but only at wave 1. However, at each subsequent wave, participants were asked one of the estimate questions. If they said that they had used a medium less, about the same, or more compared to the previous week, they were then also prompted to provide their use estimates. For example, someone might’ve had a 0 on the filter questions for audio books because they hadn’t listened to audio books the three months before wave 1. For wave 1, then, they didn’t provide the minutes and hours they spent on audio books. In wave 2, they were then asked how their audio book use had changed since the last survey. If they answered anything but the sixth answer option (i.e., they still hadn’t listened to audio books), they were asked to report how many minutes and hours they had used audio books. Here’s why that can be problematic: The participant below (2.3) hadn’t listened to audio books in the first three months and reports that at wave 1, then says at wave 2 that their audio book use hadn’t changed (i.e., selected 3 on the audiobooks_estimate question). But the participant was still asked about their minutes and hours - which is why they filled in bogus numbers. Minutes and hours were forced response as far as I can tell. I wouldn’t take those estimates seriously, because the participant was forced to respond to minutes and hours. We see that in the following waves, they selected the option that they hadn’t listened to audiobooks. Please note: We could not share the full estimate questions. Before uploading the raw data, I did some preprocessing such that only the answer options 3 (nothing changed) and 6 (didn’t use a medium) remained. All other non-missing values are set to 9. Missing values remain as NA. Table 2.3: Example of a participant with no change in use id wave filter_audiobooks audiobooks_estimate audiobooks_minutes audiobooks_hours pp_7 1 0 NA NA NA pp_7 2 0 3 1 1 pp_7 3 0 6 NA NA pp_7 4 0 6 NA NA pp_7 5 0 6 NA NA Before we turn to those cases where we can tell a participant didn’t want to provide a use estimate, we need to decide what to do with the filter questions in the first wave. For our research question, we’re interested in how variations in amount of use relate to well-being, not what that relation is among users. Therefore, if someone says that they didn’t use a medium in the three months before the first wave, they are saying that they spent zero time engaging with that medium. The filter questions didn’t ask whether a user has a device they can use to engage with those content categories or whether they had any of the media. So the filter question didn’t ask whether participants were able to engage with a category. It asked whether people used a medium. Therefore, it fits our research question to treat those values as zero. Below, I’ll set all time variables at the first wave to -99 that were skipped in the survey because participants said they didn’t use the medium in the filter questions. I choose -99 to be able to distingiush “natural” zeros (so zeros participants actually filled in) from our imputed zeros. I’ll turn those -99 to zeros later when we inspect data quality. There’s probably a sleek way to write a function that pulls variable names and matches those with the conditional commands in the code, but that’s above my skill level. working_file &lt;- working_file %&gt;% mutate( # music across( c(music_hours, music_minutes), ~ if_else((wave == 1 &amp; filter_music == 0), -99, .x) ), # films across( c(films_hours, films_minutes), ~ if_else((wave == 1 &amp; filter_films == 0), -99, .x) ), # tv across( c(tv_hours, tv_minutes), ~ if_else((wave == 1 &amp; filter_tv == 0), -99, .x) ), # video games across( c(games_hours, games_minutes), ~ if_else((wave == 1 &amp; filter_video_games == 0), -99, .x) ), # ebooks across( c(books_hours, books_minutes), ~ if_else((wave == 1 &amp; filter_ebooks == 0), -99, .x) ), # magazines across( c(magazines_hours, magazines_minutes), ~ if_else((wave == 1 &amp; filter_magazines == 0), -99, .x) ), # audiobooks across( c(audiobooks_hours, audiobooks_minutes), ~ if_else((wave == 1 &amp; filter_audiobooks == 0), -99, .x) ) ) Also, when we look at the codebook, we see that hours and minutes were coded such that 0 = 1, 2 = 1, etc. This means someone who has 24 hours actually has 23 hours. Someone who has 60 minutes actually has 59 minutes. Therefore, I subtract one from each hour and minute variable to get the real estimate. working_file &lt;- working_file %&gt;% mutate( across( c( contains(&quot;hours&quot;), contains(&quot;minutes&quot;) ), ~ if_else(.x != -99, .x - 1, .x) # we maintain the artificial zero ) ) Now, when participants said they didn’t use a medium for any wave, in the next wave they’re still presented the estimate question. When they answered anything but that they didn’t use the medium, they were asked to provide minutes and hours estimates (see the example participant above). In those hours and minutes survey questions, they were shown what they said in the previous wave. Crucially, they saw their estimate from the previous wave after they had given their estimate. So when I used 0 minutes in the previous week but forget what I said in the previous wave, it’s not unrealistic that I select “a lot less” on the estimate question. In my mind, estimating use in relation to previous time points and giving an absolute estimate of minutes and hours are two separate psychological retrieval processes. Therefore, I don’t have a problem with someone who used 0 minutes of audio books in a wave saying that they used audio books a lot less in the next wave and report to have used them for half an hour. It doesn’t make sense from an objective stand point because 30 minutes is more than 0 minutes, but the estimate question is about participants’ perceived frequency in relation to the past. For that reason, I won’t directly change the 30 minutes to 0, but leave them as is. In other words, I won’t set values to NA by comparing the absolute minutes and hours estimate to the relative frequency estimate. I’ll only make changes in clear cases like the one presented above, where someone clearly didn’t use a medium. I’ll do exclusions in the next section when I look at data quality. For now, let’s deal with those few cases that are as clear-cut as the one presented above. First some house keeping. If participants indicated on one of the estimate questions that they didn’t use that medium in the previous week (only applicable in waves 2 to 6), they’ll receive a 0 on their time estimates. So we’ll first set time estimates to -999 if participants say that they didn’t use a medium, following the same logic I outlined above. I use -999 instead of -99 like above to be able to distinguish between imputed zeros in the first wave and imputed zeros in later waves. working_file &lt;- working_file %&gt;% mutate( # music across( c(music_hours, music_minutes), ~ if_else((wave != 1 &amp; music_estimate == 6), -999, .x) ), # films across( c(films_hours, films_minutes), ~ if_else((wave != 1 &amp; films_estimate == 6), -999, .x) ), # tv across( c(tv_hours, tv_minutes), ~ if_else((wave != 1 &amp; tv_estimate == 6), -999, .x) ), # video games across( c(games_hours, games_minutes), ~ if_else((wave != 1 &amp; games_estimate == 6), -999, .x) ), # ebooks across( c(books_hours, books_minutes), ~ if_else((wave != 1 &amp; books_estimate == 6), -999, .x) ), # magazines across( c(magazines_hours, magazines_minutes), ~ if_else((wave != 1 &amp; magazines_estimate == 6), -999, .x) ), # audiobooks across( c(audiobooks_hours, audiobooks_minutes), ~ if_else((wave != 1 &amp; audiobooks_estimate == 6), -999, .x) ) ) Alright, now let’s check, per medium, who only has 6s and 3s on the estimate questions (aka didn’t use and no change to previous week). Those minutes and hours we’ll set to 0 as well. This applies only to those who didn’t use a medium in the first wave. If you used a medium in the first wave and said that your time remained the same, you shouldn’t get a zero. Setting instances of time with a medium within a participant but across waves to 0 requires some serious data wrangling (or my coding game isn’t strong enough…). To be able to assess who only gave 3 or 6 as an estimate for a medium for waves 2 through 6, we first transform the data to long format. In Table 2.4, I display how the data look like after transformation. Table 2.4: Data in long format id wave medium estimate minutes hours pp_1 1 music 9 10 1 pp_1 1 films 9 0 4 pp_1 1 tv 9 0 6 pp_1 1 games NA -99 -99 pp_1 1 books 9 0 2 pp_1 1 magazines 9 0 2 pp_1 1 audiobooks NA -99 -99 pp_1 2 music 1 12 9 pp_1 2 films 1 12 12 pp_1 2 tv 1 14 16 pp_1 2 games 1 7 6 pp_1 2 books 1 10 13 pp_1 2 magazines 1 8 14 pp_1 2 audiobooks 1 7 5 pp_2 1 music 9 0 4 pp_2 1 films NA -99 -99 pp_2 1 tv NA -99 -99 pp_2 1 games NA -99 -99 pp_2 1 books NA -99 -99 pp_2 1 magazines NA -99 -99 Next, I need to select only those media which participants didn’t say they used at the first wave. Below, I select those, add a marker for that id by medium combination, and then add that marker to the long data frame. # select id by medium combinations that didn&#39;t give an estimate in the fist wave (aka the only NA entries) markers &lt;- media_long %&gt;% filter(is.na(estimate)) %&gt;% select(id, medium) %&gt;% mutate(selected = TRUE) # add those markers to the long data frame media_long &lt;- left_join( media_long, markers, by = c(&quot;id&quot;, &quot;medium&quot;) ) Now we know on which rows to operate. We then check whether a medium that wasn’t used in the first wave only got a 3 or a 6 on the estimate in waves 2 to 6 and flag the person by medium combination that indeed doesn’t have a change. Afterwards, we transform those no_change indicators to the wide format. Below shows how these data look like: If it’s NA the person provided an estimate at the first wave. If it’s FALSE the person didn’t provide an estimate at wave 1 (so it was 0 minutes and hours), but their estimate increased or decreased over the next waves. If it’s TRUE the person didn’t provide an estimate at wave 1 and they kept not using or their use didn’t change. no_changes &lt;- media_long %&gt;% filter(selected == TRUE) %&gt;% # everyone who had an NA for an estimate in the first wave filter(wave &gt; 1) %&gt;% # we don&#39;t count the first wave group_by(id, medium) %&gt;% mutate(no_change = if_else(estimate %in% c(3,6), 0, 1)) %&gt;% # if it&#39;s 3 or 6, we assign zero summarise( # so that the sum is zero no_change = sum(no_change) ) %&gt;% mutate(no_change = if_else(no_change == 0, TRUE, FALSE)) %&gt;% # then anything that isn&#39;t zero has at least one 1,2, or 4 in their estimate ungroup() %&gt;% # then turn to wide format pivot_wider( ., names_from = &quot;medium&quot;, values_from = &quot;no_change&quot; ) %&gt;% rename_with( ., .cols = -id, ~ paste0(., &quot;_no_change&quot;) ) Table 2.5 shows how these markers look like. Table 2.5: Markers for whether someone had no change from wave 1 through wave 6 or not, per medium id audiobooks_no_change games_no_change tv_no_change books_no_change magazines_no_change music_no_change films_no_change pp_1 FALSE FALSE NA NA NA NA NA pp_10 TRUE NA FALSE NA NA NA NA pp_100 TRUE NA FALSE FALSE NA NA NA pp_1000 TRUE TRUE NA NA NA NA NA pp_1001 TRUE TRUE NA FALSE TRUE TRUE NA pp_1002 FALSE NA FALSE NA NA NA NA pp_1003 TRUE NA NA NA NA NA NA pp_1004 TRUE NA TRUE TRUE NA NA NA pp_1005 FALSE NA NA NA NA NA NA pp_1006 TRUE FALSE NA NA TRUE NA NA Now we can add those markers to the working_file. working_file &lt;- left_join( working_file, no_changes, by = c(&quot;id&quot;) ) Last, we transform the minutes and hours for each medium in each wave to 0, depending on whether that medium has one of the above markers telling us that the person didn’t use the medium at wave 1 and use didn’t change in subsequent waves (i.e., “not changed” or “haven’t used” on estimate for all subsequent waves). Like above, we use -9999 as an indicator for zero, so we know that -9999 estimates are imputed zeros based on the person not changing their use after having said they don’t use a medium in the first wave. -999 is just someone saying they didn’t use a medium and -99 is not having used a medium in the first wave. working_file &lt;- working_file %&gt;% mutate( # music across( c(music_hours, music_minutes), ~ if_else((wave != 1 &amp; music_no_change == TRUE), -9999, .x, missing = .x) # need to set missing explicitly because the no_change variables contain NA if someone didn&#39;t have a missing in the first wave ), # films across( c(films_hours, films_minutes), ~ if_else((wave != 1 &amp; films_no_change == TRUE &amp; .x != - 999), -9999, .x, missing = .x) # don&#39;t override the -99 ), # tv across( c(tv_hours, tv_minutes), ~ if_else((wave != 1 &amp; tv_no_change == TRUE &amp; .x != - 999), -9999, .x, missing = .x) ), # video games across( c(games_hours, games_minutes), ~ if_else((wave != 1 &amp; games_no_change == TRUE &amp; .x != - 999), -9999, .x, missing = .x) ), # ebooks across( c(books_hours, books_minutes), ~ if_else((wave != 1 &amp; books_no_change == TRUE &amp; .x != - 999), -9999, .x, missing = .x) ), # magazines across( c(magazines_hours, magazines_minutes), ~ if_else((wave != 1 &amp; magazines_no_change == TRUE &amp; .x != - 999), -9999, .x, missing = .x) ), # audiobooks across( c(audiobooks_hours, audiobooks_minutes), ~ if_else((wave != 1 &amp; audiobooks_no_change == TRUE &amp; .x != - 999), -9999, .x, missing = .x) ) ) %&gt;% # no need anymore for the variables we added select( -ends_with(&quot;no_change&quot;) ) Let’s do a sanity check: all minutes and hours items should now have entries because they were forced response (or because we set them to zero). That’s indeed the case, so all looking good. working_file %&gt;% summarise( across( c(contains(&quot;minutes&quot;), contains(&quot;hours&quot;)), ~ sum(is.na(.x)) ) ) %&gt;% gather() ## # A tibble: 14 x 2 ## key value ## &lt;chr&gt; &lt;int&gt; ## 1 music_minutes 0 ## 2 films_minutes 0 ## 3 tv_minutes 0 ## 4 games_minutes 0 ## 5 books_minutes 0 ## 6 magazines_minutes 0 ## 7 audiobooks_minutes 0 ## 8 music_hours 0 ## 9 films_hours 0 ## 10 tv_hours 0 ## 11 games_hours 0 ## 12 books_hours 0 ## 13 magazines_hours 0 ## 14 audiobooks_hours 0 In contrast, the estimates will still contain NAs if people didn’t use a medium in the first wave because the survey had them skip those items. After all this wrangling we’re finally able to look at how many responses we have per medium per wave. Actually, the answer is straightforward now: everyone who finished a wave either provided minutes and hours estimates for all media, or they didn’t which means we set them to 0. In other words, the complete responses per wave are also the complete responses per medium. 2.5 Data quality and exclusions In this section, we inspect implausible values, strange response patterns, and potential outliers. 2.5.1 Implausible values Okay, first let’s check that the maximum hour reported is indeed 23 and the maximum minutes 59. Table 2.6 shows that that’s the case. working_file %&gt;% summarise( across( c(contains(&quot;hours&quot;), contains(&quot;minutes&quot;)), ~ max(.x, na.rm = T) ) ) %&gt;% gather() %&gt;% knitr::kable( ., caption = &quot;Maximum values of hours and minutes, per medium&quot; ) Table 2.6: Maximum values of hours and minutes, per medium key value music_hours 23 films_hours 23 tv_hours 23 games_hours 23 books_hours 23 magazines_hours 23 audiobooks_hours 23 music_minutes 59 films_minutes 59 tv_minutes 59 games_minutes 59 books_minutes 59 magazines_minutes 59 audiobooks_minutes 59 Alright, next we did a lot of work on working_file, and media_long isn’t up to date anymore, which is why I turn the working file into the long format once more because it’s easier for some plotting. media_long &lt;- # first turn long by filter variables pivot_longer( working_file %&gt;% select( id, wave, contains(&quot;estimate&quot;), contains(&quot;minutes&quot;), contains(&quot;hours&quot;) ), c(-id, -wave), names_to = c(&quot;medium&quot;, &quot;time&quot;), values_to = &quot;value&quot;, names_sep = &quot;_&quot; ) %&gt;% # now the medium and time are mixed up in the same column, so we spread them pivot_wider( ., id:medium, names_from = &quot;time&quot;, values_from = &quot;value&quot; ) Now let’s see what proportion of minutes and hours we imputed (aka placeholders for zeros). We turned values into -99 if they were in the first wave on a medium a user hadn’t used; to -999 if a user said they hadn’t used a medium in the waves after that; and -9999 if a user hadn’t used a medium in the first wave and reported no changes in all following waves. In Table 2.7, we see we had to impute the most zeros for audiobooks. Table 2.7: Proportion of imputed and natural zero minutes medium Zeros for no change Zeros for no use Zeros for first wave Natural zeros Nonzero Total Proportion no change Proportion no use Proportion first wave Porportion natural Proportion Nonzero audiobooks 1148 7733 3273 1055 968 14177 8.10 54.55 23.09 7.44 6.83 books 1214 3445 2023 4377 3118 14177 8.56 24.30 14.27 30.87 21.99 films 1187 932 1291 6633 4134 14177 8.37 6.57 9.11 46.79 29.16 games 1605 4203 2504 3716 2149 14177 11.32 29.65 17.66 26.21 15.16 magazines 1564 5983 2940 1518 2172 14177 11.03 42.20 20.74 10.71 15.32 music 1584 431 1197 6227 4738 14177 11.17 3.04 8.44 43.92 33.42 tv 1360 353 1449 7481 3534 14177 9.59 2.49 10.22 52.77 24.93 Next, we do the same thing for hours. In Table 2.8, we see a similar pattern. Table 2.8: Proportion of imputed and natural zero hours medium Zeros for no change Zeros for no use Zeros for first wave Natural zeros Nonzero Total Proportion no change Proportion no use Proportion first wave Porportion natural Proportion Nonzero audiobooks 1148 7733 3273 712 1311 14177 8.10 54.55 23.09 5.02 9.25 books 1214 3445 2023 1543 5952 14177 8.56 24.30 14.27 10.88 41.98 films 1187 932 1291 703 10064 14177 8.37 6.57 9.11 4.96 70.99 games 1605 4203 2504 1014 4851 14177 11.32 29.65 17.66 7.15 34.22 magazines 1564 5983 2940 1808 1882 14177 11.03 42.20 20.74 12.75 13.28 music 1584 431 1197 1029 9936 14177 11.17 3.04 8.44 7.26 70.09 tv 1360 353 1449 344 10671 14177 9.59 2.49 10.22 2.43 75.27 Ultimately, these zero imputations are just a matter of how many nonzero entries a medium had to begin with. In other words: The more participants used a medium, the lower the proportion of imputed zeros for any reason. Also, someone putting down one hour and zero minutes will have a zero up here, so these tables aren’t terribly informative. How much total time is zero is much more informative. Right now, hours and minutes are still separate, so we’ll create a time variable that maintains the negative placeholders we inserted above. media_long &lt;- media_long %&gt;% mutate( # if minutes isn&#39;t negative, create time variable to maintain the placeholders time = round(if_else(minutes &gt;= 0, hours + (minutes / 60), minutes), digits = 1) ) In Table 2.9, we see a clearer pattern: The media with the most use (e.g., TV, music, films) have low imputed zeros, whereas those with little use (especially audio books) have a high amount of imputed zeros. That’s in line with the high proportion of imputed values for no use (i.e., selecting not having used in waves 2 to 6) for the little used media. Table 2.9: Proportion of imputed and natural zero times medium Zeros for no change Zeros for no use Zeros for first wave Natural zeros Nonzero Total Proportion no change Proportion no use Proportion first wave Porportion natural Proportion Nonzero audiobooks 1148 7733 3273 290 1733 14177 8.10 54.55 23.09 2.05 12.22 books 1214 3445 2023 295 7200 14177 8.56 24.30 14.27 2.08 50.79 films 1187 932 1291 302 10465 14177 8.37 6.57 9.11 2.13 73.82 games 1605 4203 2504 361 5504 14177 11.32 29.65 17.66 2.55 38.82 magazines 1564 5983 2940 340 3350 14177 11.03 42.20 20.74 2.40 23.63 music 1584 431 1197 137 10828 14177 11.17 3.04 8.44 0.97 76.38 tv 1360 353 1449 61 10954 14177 9.59 2.49 10.22 0.43 77.27 Let’s turn those negative values (i.e., the placeholders for zeros) into actual zeros and check for the overall occurrence of all zeros in relation to nonzero values. working_file &lt;- working_file %&gt;% mutate( across( c(contains(&quot;hours&quot;), contains(&quot;minutes&quot;)), ~ if_else(.x &lt; 0, 0, .x) # if negative, turn into zero ) ) media_long &lt;- media_long %&gt;% mutate( across( c(contains(&quot;hours&quot;), contains(&quot;minutes&quot;)), ~ if_else(.x &lt; 0, 0, .x) # same here ), time = round(hours + (minutes / 60), digits = 1) ) Then we’ll show zeros vs. nonzeros in Table 2.10. The table basically summarizes all tables so far, showing the popularity of the medium and how much we had to impute. Table 2.10: Proportion of 0 hours, per medium medium Above 0h 0h Proportion audiobooks 1733 12444 87.78 books 7200 6977 49.21 films 10465 3712 26.18 games 5504 8673 61.18 magazines 3350 10827 76.37 music 10828 3349 23.62 tv 10954 3223 22.73 Alright, next we’ll visually inspect the distribution of self-reported use times per medium. We’ll be working with the working_file again, for which we need to calculate the time per medium. Like before, I’ll do that manually for all seven media. working_file &lt;- working_file %&gt;% mutate( # music music_time = music_hours + (music_minutes / 60), # films films_time = films_hours + (films_minutes / 60), # tv tv_time = tv_hours + (tv_minutes / 60), # video games games_time = games_hours + (games_minutes / 60), # ebooks books_time = books_hours + (books_minutes / 60), # magazines magazines_time = magazines_hours + (magazines_minutes / 60), # audiobooks audiobooks_time = audiobooks_hours + (audiobooks_minutes / 60) ) In Figure 2.1 we see the distribution of use time per medium. Those figures aren’t super accurate for practical reasons: For some media, there’s so many zeros that there isn’t enough jitter in the cloud which is why they’re all so bunched up together on the left. There’s many entries of more than 18h of average daily use, which is close to impossible if someone sleeps at least six hours. Figure 2.1: Distribution of self-reported time per medium In Table 2.11 we see that very few entries are above 18h, relative to all other values, which is a good sign. # count proportion per medium media_long %&gt;% group_by(medium) %&gt;% count(time &gt;= 18) %&gt;% pivot_wider( names_from = `time &gt;= 18`, values_from = &quot;n&quot; ) %&gt;% rename( &quot;Below 18h&quot; = `FALSE`, &quot;Above 18h&quot; = `TRUE` ) %&gt;% mutate( Proportion = round(`Above 18h` / sum(c(`Above 18h`, `Below 18h`)) * 100, digits = 2) ) %&gt;% knitr::kable( ., caption = &quot;Proportion of hours above 18&quot; ) Table 2.11: Proportion of hours above 18 medium Below 18h Above 18h Proportion audiobooks 14165 12 0.08 books 14120 57 0.40 films 13955 222 1.57 games 14025 152 1.07 magazines 14158 19 0.13 music 14000 177 1.25 tv 13775 402 2.84 2.5.1.1 Participant-level Let’s follow up on those who reported 18h or more use of a medium and check whether there are any participants whose estimates we cannot really trust. We need to distinguish between completely excluding a participant (whose answers we don’t trust for all waves they provided) and wave-level exclusions (when we trust the data of the participant, except for one or two waves). As for implausible values on the participant-level, I’d say the following are indicators of poor quality: More than 30% of time estimates participants provided (excluding zeros imputed by us) across all waves are above 18h. More than one instance of a 23h+ estimate across all waves. More than one instance where the sum of nonzero estimates is above 48h in a wave. Let’s look at the proportion of very high reported use times. Self-reported use is also about how much people feel like they used medium, so I’ll be liberal here. I’d say we can’t trust a participant if they estimated 18+ hours in &gt; 30% of all their time estimates, across all waves. Below, I’ll count per participant how many times they estimated 18+ hours of consumption in relation to all time estimates they provided. I’ll not include zero times in that account because we imputed times of zero. implausible_pp_level_1 &lt;- media_long %&gt;% filter(time &gt; 0) %&gt;% # nonzero group_by(id, medium) %&gt;% summarise( above18 = sum(time &gt;= 18), below18 = sum(time &lt; 18), waves = n() ) %&gt;% ungroup() %&gt;% group_by(id) %&gt;% summarise( above18 = sum(above18), below18 = sum(below18), entries = sum(waves), proportion_above18 = round(above18 / entries, digits = 2) ) %&gt;% ungroup() %&gt;% arrange(desc(proportion_above18)) %&gt;% filter(proportion_above18 &gt; 0.3) # store the participants that were above that threshold exclusions_pp_1 &lt;- implausible_pp_level_1 %&gt;% pull(id) %&gt;% as.character() In Table 2.12 we see that there’s mostly participants that fulfill these exclusions who completed only a wave or two, so there’s most likely a correlation between their motivation to participate and how seriously they took the survey. Note: For all tables on exclusions, I show the first 15 rows. Table 2.12: Proportion of respondents who reported use of 18h in more than 30% of their estimates id above18 below18 entries proportion_above18 pp_103 10 0 10 1.00 pp_3009 1 0 1 1.00 pp_4833 1 0 1 1.00 pp_5153 1 0 1 1.00 pp_5468 1 0 1 1.00 pp_5915 1 0 1 1.00 pp_6008 2 0 2 1.00 pp_6610 1 0 1 1.00 pp_752 5 0 5 1.00 pp_6170 4 1 5 0.80 pp_633 4 1 5 0.80 pp_6471 3 1 4 0.75 pp_128 17 7 24 0.71 pp_4394 2 1 3 0.67 pp_4446 2 1 3 0.67 Overall, there were 98 participants who fall into the first exclusion criterion. Next, participants might feel like they played the whole day, so saying 23 hours of play on average is close to impossible. I’d say that can happen, but if it happens twice across waves, I wouldn’t trust that participant. implausible_pp_level_2 &lt;- media_long %&gt;% group_by(id) %&gt;% summarise( above23 = sum(time &gt;= 23), below23 = sum(time &lt; 23) ) %&gt;% filter(above23 &gt; 1) # store the IDs exclusions_pp_2 &lt;- implausible_pp_level_2 %&gt;% pull(id) %&gt;% as.character() There were 37 participants who fell into the second criterion. In Table 2.13 we see that there’s mostly participants that fulfill these exclusions who completed only a wave or two, so there’s most likely a correlation between their motivation to participate and how seriously they took the survey. Table 2.13: Proportion of respondents who reported more than one instance of 23h use across waves id above23 below23 pp_1116 3 32 pp_1162 5 37 pp_1246 2 26 pp_128 7 35 pp_1420 3 39 pp_156 2 19 pp_1737 2 40 pp_2072 2 12 pp_2111 4 38 pp_2287 2 12 pp_2310 2 12 pp_2436 2 40 pp_252 5 30 pp_2533 3 39 pp_2537 3 32 By the same logic, some weeks might feel very intense, and participants surely didn’t keep track of what they reported for use throughout all media. So it’s possible if we add up all times, there’ll be instances where the sum is above 24h, even around 48h. After all, participants can multitask, but if they use three media at the same time for 16 hours, that’s 48h. I’d say that can happen theoretically, but not over multiple weeks. So if there’s more than one wave where the total is equal to or above 48h, I don’t think the participant read the question correctly. # get total time working_file &lt;- working_file %&gt;% mutate( total_time = rowSums(select(., contains(&quot;time&quot;))) ) # get counts of more than 48h total time implausible_pp_level_3 &lt;- working_file %&gt;% group_by(id) %&gt;% summarise( above48_count = sum(total_time &gt;= 48) ) %&gt;% filter(above48_count &gt; 1) # store the IDs exclusions_pp_3 &lt;- implausible_pp_level_3 %&gt;% pull(id) %&gt;% as.character() In Table 2.14 we see that there’s a bunch of participants who had 48h of total media use more than once (in total 53). Table 2.14: Respondents who reported a total media use time of 48h or more across multiple weeks id above48_count pp_1052 3 pp_1122 5 pp_1162 4 pp_128 6 pp_13 3 pp_1425 4 pp_1460 6 pp_1510 4 pp_1534 3 pp_1653 4 pp_1655 3 pp_1666 2 pp_1667 4 pp_1688 2 pp_1816 2 Last, let’s check how many unique participants we’d need to exclude if we applied all three of those exclusion criteria (taking into account overalp). exclusions_pp &lt;- c(exclusions_pp_1, exclusions_pp_2, exclusions_pp_3) %&gt;% unique() 2.5.1.2 Wave-level As for implausible values on the wave-level, I’ll apply the following criteria: Any wave that has more than two estimates of using a medium for 16h+. Any wave where the sum of use times is above 64h. Any wave where a participant estimated use of 23h or more. Again, it’s probably not uncommon to report a high number if I went on a reading-binge. But I’d say if you sleep eight hours, reporting the rest of the time twice for a wave is suspicious, so there’s probably a typo or someone didn’t take the question seriously. implausible_wave_level_1 &lt;- media_long %&gt;% group_by(id, wave) %&gt;% summarise( two16s = sum(time &gt;= 16) ) %&gt;% filter(two16s &gt; 1) # store the rows that were above that threshold exclusions_wave_1 &lt;- implausible_wave_level_1 %&gt;% select(id, wave) Overall, we have 166 rows of data we need to exclude from 107 participants. However, of those, 72 were already identified as suspicious in the participant-level exclusions. Next, we inspect waves where even excessive multitasking per day exceeds a reasonable threshold. If someone multitasked with three media every waking hour, they’d have 16h x 3 = 48h. Therefore, we exclude waves where the sum of use times is equal or above four times all day multitasking: 16h x 3 = 64. implausible_wave_level_2 &lt;- working_file %&gt;% mutate( total_time = rowSums(select(., contains(&quot;time&quot;))) ) %&gt;% filter(total_time &gt;= 64) %&gt;% select(id, wave, contains(&quot;time&quot;)) # store the rows exclusions_wave_2 &lt;- implausible_wave_level_2 %&gt;% select(id, wave) For this criterion, we have 1026 rows of data we need to exclude from 526 participants. However, of those, 109 were already identified as suspicious in the participant-level exclusions. Last on the wave-level, we want to exclude any row where participants estimated 23h of daily use of any medium. Maybe one can multitask with three media for 16h a day, but an average use of 23h daily for a week is close to impossible. On the participant level, we already had an exclusion criterion where all of people’s rows were excluded if they had more than one estimate of 23h (across all waves). implausible_wave_level_3 &lt;- media_long %&gt;% group_by(id, wave) %&gt;% summarise( max_time = max(time) ) %&gt;% filter(max_time &gt;= 23) # store the rows that were above that threshold exclusions_wave_3 &lt;- implausible_wave_level_3 %&gt;% select(id, wave) For this criterion, we have 184 rows of data we need to exclude from 128 participants. However, of those, 73 were already identified as suspicious in the participant-level exclusions. Before I remove those cases and rows from the data, I’ll go to response patterns. I’ll do the actual exclusions at the end of this section. 2.5.2 Response patterns In surveys, people who didn’t take the study seriously often provide implausible values (see section above), rush, or have response patterns. Out of experience, response patterns are an indicator of poor data quality. I’ll mostly be looking at straightlining, so selecting the same answer option for each item in a scale. Usually, straightlining isn’t uncommon for, say, well-being scales, so I don’t want to be too strict here and exclude valid cases. Also, if participants repeatedly provide the same time estimate across different media, I’d be suspicious of their responses. Anyone who straightlined on more than two of the identity scales (minimum of three media). Anyone who has the same total time in each wave (minimum three media and waves). For the first criterion, we calculate the variance for each identity scale (provided participants provided a response). If someone straightlined at three (of at least three) scales, I wouldn’t trust them to take the survey seriously. Note that magazines and audio books didn’t have identity questions. exclusions_pp_4 &lt;- working_file %&gt;% # create the variance variables per row rowwise() %&gt;% mutate( # music identity variance music_identity_sd = sd( c_across(starts_with(&quot;music_identity&quot;)), na.rm = TRUE ), # films identity variance films_identity_sd = sd( c_across(starts_with(&quot;films_identity&quot;)), na.rm = TRUE ), # tv identity variance tv_identity_sd = sd( c_across(starts_with(&quot;tv_identity&quot;)), na.rm = TRUE ), # games identity variance games_identity_sd = sd( c_across(starts_with(&quot;games_identity&quot;)), na.rm = TRUE ), # epublishing identity variance e_publishing_identity_sd = sd( c_across(starts_with(&quot;e_publishing_identity&quot;)), na.rm = TRUE ) ) %&gt;% unnest(cols = c()) %&gt;% # we&#39;re only looking at the first wave where the identity questions were asked group_by(id) %&gt;% filter(wave == 1) %&gt;% ungroup() %&gt;% # now we check who answered at least three identity scales by summing the filer questions mutate( media_number = rowSums(select(., filter_music:filter_ebooks)), at_least_three = if_else(media_number &gt;= 3, 1, 0) ) %&gt;% filter(at_least_three == 1) %&gt;% # create a variable that counts how many of the variances are zero mutate( multiple_straightlines = rowSums(select(., ends_with(&quot;_sd&quot;)) == 0) ) %&gt;% filter(multiple_straightlines &gt; 2) %&gt;% # and select participants pull(id) %&gt;% as.character() For this criterion, we have 72 participants. Of those, 6 were already identified as suspicious in the participant-level exclusions previously. On to the second criterion: Someone might be very consistent and provide the same use times at each wave (excluding nonzero estimates). However, if a person provides the same use estimates for each medium across all waves (minimum three waves), I’d say they’re just trying to get the survey done and rely on the time that they survey prompted. So below I’ll check who has the same total time (i.e., reporting the same time across all media) in all of their waves. To avoid excluding people for whom this occurred only once, I’ll set a minimum of three media and three waves. # get participants who have at least three waves and media use estimates three_media_and_waves &lt;- working_file %&gt;% mutate( media_number = rowSums(select(., starts_with(&quot;filter&quot;))) # minimum three media ) %&gt;% filter(media_number &gt;= 3) %&gt;% count(id) %&gt;% # count waves filter(n &gt;= 3) %&gt;% pull(id) %&gt;% as.character() # then filter by those participants and check how many times their total times are constant exclusions_pp_5 &lt;- working_file %&gt;% filter(id %in% three_media_and_waves) %&gt;% select(id, wave, total_time) %&gt;% group_by(id) %&gt;% summarise( distinct_times = n_distinct(total_time) ) %&gt;% filter(distinct_times == 1) %&gt;% pull(id) %&gt;% as.character() Only 14 participants fulfilled this criterion. Of those, 1 were already identified as suspicious in the participant-level exclusions previously. Alright, let’s add those participants with response patterns to those with implausible values. exclusions_pp &lt;- c(exclusions_pp, exclusions_pp_4, exclusions_pp_5) %&gt;% unique() 2.5.3 Applying exclusions As a last step, we exclude those participants whom we identified as having low data quality. How many people we exclude will depend on what our starting sample is. Currently, we still have the whole sample, but for the analysis, we’ll restrict valid cases to those who responded to a certain number of waves. Below in Table 2.15 I’ll show, per wave, how many people we’d exclude for each exclusion criterion plus what proportion of the valid sample (aka how many participants have at least that many waves) we have left. Note that some participants fulfill multiple exclusions, so the last columns shows the cumulative exclusions and proportion of the respective sample. For the analysis, mixed-effects models weigh participants with more data more heavily, which means we can use everyone with at least three waves (because we used lagged predictors). Table 2.15: Exclusions depending on how many minimum waves participants must have Participants Wave 1 Wave 2 Wave 3 Wave 4 Wave 5 Wave 6 N 3863.00 2792.00 2369.00 2132.00 1947.00 1074.00 Exclusion 1 3765.00 2764.00 2347.00 2115.00 1931.00 1065.00 Exclusion 1 % 2.54 1.00 0.93 0.80 0.82 0.84 Exclusion 2 3826.00 2761.00 2343.00 2109.00 1927.00 1061.00 Exclusion 2 % 0.96 1.11 1.10 1.08 1.03 1.21 Exclusion 3 3810.00 2739.00 2324.00 2093.00 1914.00 1053.00 Exclusion 3 % 1.37 1.90 1.90 1.83 1.69 1.96 Exclusion 4 3791.00 2739.00 2324.00 2092.00 1911.00 1055.00 Exclusion 4 % 1.86 1.90 1.90 1.88 1.85 1.77 Exclusion 5 3849.00 2778.00 2355.00 2120.00 1935.00 1068.00 Exclusion 5 % 0.36 0.50 0.59 0.56 0.62 0.56 Exclusion all 3630.00 2648.00 2246.00 2027.00 1853.00 1022.00 Exclusion all % 6.03 5.16 5.19 4.92 4.83 4.84 Let’s also combine all wave-level exclusions. # first, I&#39;ll combine all three wave-level exclusions exclusions_wave &lt;- full_join( exclusions_wave_1, exclusions_wave_2 ) %&gt;% full_join( ., exclusions_wave_3 ) %&gt;% ungroup() %&gt;% distinct() Before we apply the exclusions, let’s first create a data frame which we can use later to plot exclusions for the paper. It’ll be similar to the one above, but restricted to those with at least three waves, because those are the ones we ultimately use for the analysis. The code below might duplicate some of the work of previous and later code, but I came back here for creating a plot for the paper, so I didn’t want to break anything. # vectors holding number of participants and number of observations PPs &lt;- c() Observations &lt;- c() # temp data set of people with at least three waves dat &lt;- working_file %&gt;% group_by(id) %&gt;% filter(n() &gt;= 3) %&gt;% ungroup() # the exclusions we iterate over exclusions &lt;- list( exclusions_pp_1, exclusions_pp_2, exclusions_pp_3, exclusions_pp_4, exclusions_pp_5, exclusions_wave_1, exclusions_wave_2, exclusions_wave_3 ) # iterate over each exclusion criterion list/tibble and extract how many are left after excluding those for (i in exclusions) { if(!is_tibble(i)){ PPs &lt;- c(PPs, dat %&gt;% filter(!id %in% i) %&gt;% summarise(PPs = length(unique(id))) %&gt;% pull(PPs)) Observations &lt;- c(Observations, dat %&gt;% filter(!id %in% i) %&gt;% summarise(n = n()) %&gt;% pull(n)) } else{ PPs &lt;- c( PPs, anti_join( dat, i ) %&gt;% summarise(PPs = length(unique(id))) %&gt;% pull(PPs) ) Observations &lt;- c( Observations, anti_join( dat, i ) %&gt;% summarise(n = n()) %&gt;% pull(n) ) } } # our data for the plot exclusion_plot_data &lt;- tibble( &quot;Type&quot; = c(rep(&quot;Participant-level&quot;, 5), rep(&quot;Wave-level&quot;, 3), &quot;Total&quot;, &quot;Total Before&quot;), &quot;Exclusion&quot; = c(1:5, 1:3, &quot;Total&quot;, &quot;Total Before&quot;), &quot;PPs&quot; = c( PPs, dat %&gt;% filter(!id %in% exclusions_pp) %&gt;% anti_join( ., exclusions_wave ) %&gt;% group_by(id) %&gt;% filter(n() &gt;= 3) %&gt;% ungroup() %&gt;% summarise( n = length(unique(id)) ) %&gt;% pull(n), length(unique(dat$id)) ), &quot;Observations&quot; = c( Observations, dat %&gt;% filter(!id %in% exclusions_pp) %&gt;% anti_join( ., exclusions_wave ) %&gt;% group_by(id) %&gt;% filter(n() &gt;= 3) %&gt;% ungroup() %&gt;% summarise( n = n() ) %&gt;% pull(n), nrow(dat) ) ) # clear workspace rm(PPs, Observations, exclusions, dat) Let’s apply participant-level exclusions. # exclusions_pp contains all participant-level exclusions working_file &lt;- working_file %&gt;% filter(!id %in% exclusions_pp) Now that we’ve applied the participant-level exclusions, we also need to take a look at wave-level exclusions. It’s quite possible that having excluded participants with low-quality data already excluded many of their low-quality rows as well. I’ll check how many rows that we intended to exclude on the wave-level are already not in the data set anymore because the entire participant that row belongs to was excluded during participant-level exclusions. anti_join( exclusions_wave, working_file, by = c(&quot;id&quot;, &quot;wave&quot;) ) %&gt;% nrow() ## [1] 385 Let’s take the data set after participant exclusions, exclude low-quality rows (i.e., waves) and count the number of waves again. Table 2.16 shows the number of participants with at least a number of waves (after participant-level exclusions) next to the same number after excluding on the wave-level. The sharpest drop is in the number of people who previously had completed six waves. That’s not surprising because each unique participant in exclusions_wave (553 participants) who had previously completed six waves now drops down to five waves. Probably there’s a correlation between sticking around for this long and motivation, such that motivation drops in later waves and there’s a higher chance to fulfill one of the exclusion criteria. Overall, 5.13% of rows are excluded. Table 2.16: Participants with at least a number of waves before and after wave-level exclusion Waves Participants per wave Participants per wave after exclusions Reduction proportion % 1 3630 3513 3.22 2 2648 2557 3.44 3 2246 2159 3.87 4 2027 1921 5.23 5 1853 1704 8.04 6 1022 883 13.60 During model fitting, we’ll predict the outcome with the lagged value of the predictor. If we merely exclude the rows participants will have gaps in their waves. For example, a participant might have entries for waves 1-4, but wave 3 belongs to low-quality data rows. We’d then be left with rows 1,2, and 4. During model fitting, just lagging the value would mean the outcome at wave 4 is predicted by the predictor at wave 2 - effectively messing up our one-week lag between waves. Therefore, it makes sense to maintain those rows whose data we exclude, but set them to NA. This way, we don’t have “gaps” between waves. In addition, if we want to impute missing values during model fitting (via the built-in brms imputation), we want to be able to know what value to impute, which is why we need the NA signal. Let’s make those rows that have low quality data, then set all wave-level entries to NA on those rows. # add marker to wave-level exclusions exclusions_wave &lt;- exclusions_wave %&gt;% mutate(set_to_na = 1) # add that marker to working file working_file &lt;- left_join( working_file, exclusions_wave, by = c(&quot;id&quot;, &quot;wave&quot;) ) # then set all wave-level entries to NA that have a marker working_file &lt;- working_file %&gt;% mutate( across( c( music_hours:well_being_2, music_time:total_time ), ~ replace(.x, set_to_na == 1, NA) ) ) %&gt;% # remove marker select(-set_to_na) 2.6 Build scales As a last step, we’re creating the mean score scales. Before we do that, we have to reverse code some items. identity items had strongest agreement as 1. I find it more intuitive when larger numbers mean more agreement. The same applies to the well-being item about anxiety, which I will reverse code. working_file &lt;- working_file %&gt;% mutate( across( contains(&quot;identity&quot;), ~ 5 - .x ), well_being_2 = 10 - well_being_2 # starts at 0 ) Let’s start with the identity scales; for each medium (except magazines and audiobooks), participants indicated how much that medium was part of their identity. working_file &lt;- working_file %&gt;% mutate( # music music_identity = rowMeans(select(., starts_with(&quot;music_identity&quot;))), # films films_identity = rowMeans(select(., starts_with(&quot;films_identity&quot;))), # tv tv_identity = rowMeans(select(., starts_with(&quot;tv_identity&quot;))), # games games_identity = rowMeans(select(., starts_with(&quot;games_identity&quot;))), # epublishing e_publishing_identity = rowMeans(select(., starts_with(&quot;e_publishing_identity&quot;))), ) And the well-being scales per wave (aka row). working_file &lt;- working_file %&gt;% mutate( life_satisfaction = rowMeans(select(., starts_with(&quot;life_satisfaction&quot;))), affect = rowMeans(select(., starts_with(&quot;well_being&quot;))), well_being = rowMeans(select(., starts_with(&quot;well_being&quot;), starts_with(&quot;life_satisfaction&quot;))) # both affect and well-being combined ) Before we move on to visualizations and descriptive info, I’ll do some housekeeping. I’ll reorder some variables for cosmetic purposes, only select those we need, and clean the workspace. # select relevant variables working_file &lt;- working_file %&gt;% select( id, gender, wave:filter_audiobooks, starts_with(&quot;music&quot;), starts_with(&quot;films&quot;), starts_with(&quot;tv&quot;), starts_with(&quot;games&quot;), starts_with(&quot;e_publishing&quot;), starts_with(&quot;books&quot;), starts_with(&quot;magazines&quot;), starts_with(&quot;audiobooks&quot;), total_time, starts_with(&quot;life_satisfaction&quot;), starts_with(&quot;well_being&quot;), affect, -ends_with(&quot;hours&quot;), # we got the total time from here on -ends_with(&quot;minutes&quot;), ) # clean workspace rm( markers, no_changes, waves_per_id, an_id, id_counter, id_to_match, ids, temp_id, three_media_and_waves ) And then remove those who don’t have at least three waves. For one model part, we’ll used led values, so two waves won’t be enough because that means a participant is left with only one wave once we lead a predictor. Also, some participants now have missing values (because we applied the wave-level exclusions). Missing values will be removed during model fitting, meaning that if someone has three waves, but two of them are NA, they’ll be left with one wave of data. So I’ll filter the data set to only keep those with at least three waves with responses. # get ids of participants who have at least three valid waves at_least_three &lt;- working_file %&gt;% group_by(id) %&gt;% filter(!is.na(music_time)) %&gt;% filter(n() &gt;= 3) %&gt;% ungroup() %&gt;% pull(id) # then only keep those participants working_file &lt;- working_file %&gt;% filter(id %in% at_least_three) # remove from workspace rm(at_least_three) "],
["descriptives-and-visualizations.html", "3 Descriptives and visualizations 3.1 Overview 3.2 Person-level 3.3 Wave-level 3.4 Correlation matrices 3.5 Plots for Paper", " 3 Descriptives and visualizations 3.1 Overview In this section, I describe and visualize the variables. We got variables on the person-level and on the wave level. Person-level Age and gender (age, gender) What region of the UK participants are from (region) Whether they’ve used a medium in the three months before the first wave (variables starting with filter) To what extent they identify with a medium (variables ending with identity) Wave-level How much they used a medium per wave (variables ending with time) Their well-being per wave (well_being) 3.2 Person-level Let’s have a look at the final sample. Overall, our sample size is N = 2159. Participants, on average, were M = 47 years old, SD = 14.6, see Figure 3.1. The gender distribution is pretty equal (1123 women (52.01%), 1035 men, and 1 non-binary participants). Figure 3.1: Distribution of age Alright, next let’s have a look again (now that we have the final sample) at how many people had used a medium in the three months before wave 1 (Table 3.1). Table 3.1: Frequency of how much a medium was used at wave 1 Medium Used Not Used Proportion audiobooks 274 1885 12.7 ebooks 1032 1127 47.8 films 1339 820 62.0 magazines 498 1661 23.1 music 1420 739 65.8 tv 1310 849 60.7 video_games 624 1535 28.9 Now let’s have a look at how much people identified with each medium. Note that people weren’t asked those identity questions if they indicated that they hadn’t used a medium at wave 1. Table 3.2: Descriptive information for identity scales variable N mean sd median min max range cilow cihigh music_identity 1420 2.19 0.67 2.14 1 4 3 2.16 2.23 tv_identity 1310 2.16 0.63 2.14 1 4 3 2.13 2.20 films_identity 1339 2.26 0.67 2.14 1 4 3 2.22 2.29 games_identity 624 2.48 0.82 2.43 1 4 3 2.42 2.55 e_publishing_identity 1211 2.33 0.69 2.29 1 4 3 2.29 2.37 Figure 3.2 shows the distributions of those identity variables. Apparently gamers identified more with games than for example music listeners identified with music. Figure 3.2: Distribution of identity variables 3.3 Wave-level Let’s inspect the descriptive information for the different media. Table 3.3 shows that people used TV, music, and films the most, but spent little time on magazines and audio books. Table 3.3: Descriptive information for use time (including zero estimates) variable N mean sd median min max range cilow cihigh music_time 10985 2.28 2.57 2.00 0 22.22 22.22 2.24 2.33 tv_time 10985 3.25 3.38 2.50 0 22.00 22.00 3.18 3.31 films_time 10985 2.33 2.62 2.00 0 22.25 22.25 2.28 2.37 games_time 10985 0.98 2.24 0.00 0 22.00 22.00 0.94 1.02 books_time 10985 1.09 1.96 0.17 0 21.00 21.00 1.05 1.12 magazines_time 10985 0.24 0.87 0.00 0 20.00 20.00 0.23 0.26 audiobooks_time 10985 0.16 0.78 0.00 0 20.00 20.00 0.15 0.18 Figure 3.3 shows the distributions of those time variables. Note that most distributions are zero-inflated with a heavy skew. Figure 3.3: Distribution of time variables (with zeros) Let’s also inspect those summary statistics and distributions without zeros. Table 3.4 shows the same pattern was with zeros, but overall higher means. Interestingly, those who listen to audiobooks report to do so for a long time per day. Table 3.4: Descriptive information for use time (excluding zero estimates) variable N mean sd median min max range cilow cihigh music_time 8251 3.04 2.54 2.25 0.02 22.22 22.20 2.99 3.09 tv_time 8537 4.18 3.29 3.00 0.02 22.00 21.98 4.11 4.25 films_time 7956 3.21 2.58 2.33 0.02 22.25 22.23 3.15 3.27 games_time 3873 2.78 3.04 2.00 0.02 22.00 21.98 2.69 2.88 books_time 5561 2.14 2.31 1.50 0.02 21.00 20.98 2.08 2.21 magazines_time 2442 1.09 1.58 0.67 0.02 20.00 19.98 1.03 1.16 audiobooks_time 1101 1.64 1.93 1.00 0.02 20.00 19.98 1.52 1.75 Figure 3.4 shows a less skewed distribution once we remove zeros. Figure 3.4: Distribution of time variables (without zeros) As a next step, let’s see how use developed over time. Figure 3.5 shows that most media stay stable, except maybe an overall spike in wave 2. Figure 3.5: Average use over time per medium Last, let’s see the overall descriptives of the well-being variables. Table 3.5 shows that both life satisfaction and affect were above the mid-point of the scale - even though for affect, it’s a close call. Table 3.5: Well-being descriptives variable N mean sd median min max range cilow cihigh affect 10985 5.938689 2.181849 6 0 10 10 5.897883 5.979495 life_satisfaction 2103 6.410366 2.032778 7 0 10 10 6.323436 6.497296 Let’s plot the distribution of both affect and life satisfaction in Figure 3.6. Figure 3.6: Distribution of well-being across waves and participants Last, let’s look at how well-being develops over time. Figure 3.7 shows that life satisfaction appears stable: note the y-axis is on decimal points (original range: 0 to 10). In contrast, affect has significantly decreased, mostly because anxiety has decreased (not shown on graph). Figure 3.7: Average estimates over time per medium 3.4 Correlation matrices Let’s have a look at the row correlations between the media use variables and well-being. Figure 3.8 shows that a) most media use is correlated, and b) there are negative, but very small correlations between well-being and media use. The significance is negligible here just because the sample is so large. That said, we haven’t done any grouping yet, so the correlation matrix treats all observations as independent, which is clearly not the case. Figure 3.8: Correlation matrix of hours spent with a medium and well-being 3.5 Plots for Paper For the paper, I want to avoid confronting readers with blocks of numbers. Therefore, I’ll try to put as much info as possible into figures rather than tables or in-text reports of numbers. I think the following plots are necessary for the paper: A plot of the response rate per wave, simply as a descriptive measure. A plot showcasing the exclusions. I’ll describe the exclusion criteria in the paper, but don’t want to overwhelm readers with numbers for each. A plot showing the distributions, M, and SD of media use for different categories. Same plot, but for well-being. A plot of the results. First, a plot for the response rate for each wave. We already showed response rates as a table in the processing section, so we can re-use the completion_table object for a plot. Not sure about the colors yet, might go all black for this one. ggplot( data = completion_table %&gt;% rename( Wave = Waves, `Participants per wave (%)` = `Participants per wave` ) %&gt;% mutate( Wave = as.factor(Wave) ), aes( x = Wave, y = `Participants per wave (%)`#, # color = Wave, # fill = Wave ) ) + geom_segment( aes( xend = Wave, y = 0, yend = `Participants per wave (%)` ), size = 1 ) + geom_point( size = 2 ) + geom_text( aes( label = paste0(`Participants per wave (%)`, &quot;(&quot;, `Frequency per wave`, &quot;%)&quot;), y = `Participants per wave (%)` + 160 ) ) + scale_colour_manual(values=cb_palette) + scale_fill_manual(values = cb_palette) + theme( legend.position = &quot;none&quot; ) -&gt; figure1 figure1 ggsave( filename = here(&quot;figures&quot;, &quot;figure1.tiff&quot;), plot = figure1, width = 21 * 0.8, height = 29.7 * 0.4, units = &quot;cm&quot;, dpi = 300 ) Next, I plot the exclusions. There’s two ways to go about this. Either I show the absolute number of participants and observations that we exclude with each criterion in relation to the total sample size. I do that below. Note that getting those exclusions in a nice format requires some wrangling. I already created the exclusion_plot_data object in the processing section. Here, I turn it into the long format first. # to long format for plotting exclusion_plot_data &lt;- exclusion_plot_data %&gt;% filter(!str_detect(Exclusion, &quot;Total&quot;)) %&gt;% # don&#39;t include the total numbers for now rename(Participants = PPs) %&gt;% # nicer name pivot_longer( Participants:Observations, names_to = &quot;Measure&quot;, values_to = &quot;Value&quot; ) %&gt;% mutate( # create new variable that&#39;s stable across exclusions Total = case_when( Measure == &quot;Participants&quot; ~ exclusion_plot_data %&gt;% filter(Type == &quot;Total&quot;) %&gt;% pull(PPs), TRUE ~ exclusion_plot_data %&gt;% filter(Type == &quot;Total&quot;) %&gt;% pull(Observations), ), `Total Before` = case_when( Measure == &quot;Participants&quot; ~ exclusion_plot_data %&gt;% filter(Type == &quot;Total Before&quot;) %&gt;% pull(PPs), TRUE ~ exclusion_plot_data %&gt;% filter(Type == &quot;Total Before&quot;) %&gt;% pull(Observations), ) ) %&gt;% mutate( across( Type:Measure, as.factor ) ) # https://stackoverflow.com/questions/11889625/annotating-text-on-individual-facet-in-ggplot2 # I want to show the total numbers once, not for each facet/criterion combination, which is why I create a data frame that only has a matching value for the positions in the plot that I want label_positions &lt;- tibble( Type = rep(&quot;Wave-level&quot;, 2), Exclusion = c(3, 3), # on the right, where wave-level exclusions are Measure = c(&quot;Participants&quot;, &quot;Observations&quot;) ) %&gt;% mutate( across( everything(), as.factor ) ) # add the total values label_positions &lt;- left_join( label_positions, exclusion_plot_data %&gt;% select(-Value) ) # then plot ggplot( exclusion_plot_data, aes( x = Exclusion, y = Value, color = Type ) ) + geom_segment( aes( x = Exclusion, xend = Exclusion, y = 0, yend = Value ), alpha = 1, size = 1 ) + facet_grid(Measure ~ Type, scales = &quot;free&quot;) + geom_point(alpha = 1, size = 2) + geom_text( aes( label = paste0(&quot;-&quot;, `Total Before` - Value), x = as.numeric(Exclusion) + 0.35, y = Total * 0.1 ) ) + geom_hline( aes( yintercept = Total ), linetype = &quot;dashed&quot; ) + geom_hline( aes( yintercept = `Total Before` ), linetype = &quot;solid&quot; ) + geom_text( data = label_positions, aes( label = `Total`, x = 3.3, y = Total * 1.05 ), color = &quot;black&quot; ) + geom_text( data = label_positions, aes( label = `Total Before`, x = 3.3, y = `Total Before` * 1.05 ), color = &quot;black&quot; ) + xlab(&quot;Exclusion Criterion&quot;) + scale_colour_manual(values=cb_palette) + scale_fill_manual(values = cb_palette) + theme( axis.title.y = element_blank(), legend.position = &quot;none&quot;, panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), strip.background = element_blank() ) -&gt; exclusion_figure1 exclusion_figure1 Alternatively, we could emphasize the contributions of each criterion in relation to the other criteria. Not sure I like this because it doesn’t show the total sample size and the reduction in total sample size. Then again, could simply add those to the figure captions. ggplot( exclusion_plot_data %&gt;% mutate( Value = `Total Before` - Value ), aes( x = Exclusion, y = Value, color = Type ) ) + geom_segment( aes( x = Exclusion, xend = Exclusion, y = 0, yend = Value ), alpha = 1, size = 1 ) + facet_grid(Measure ~ Type, scales = &quot;free&quot;) + geom_point(alpha = 1, size = 2) + geom_text( aes( label = paste0(round(Value/`Total Before`, digits = 4) * 100, &quot;%&quot;), y = Value ), vjust = 1, hjust = -0.2, size = 3 ) + xlab(&quot;Exclusion Criterion&quot;) + scale_colour_manual(values=cb_palette) + scale_fill_manual(values = cb_palette) + theme( axis.title.y = element_blank(), legend.position = &quot;none&quot;, panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), strip.background = element_blank() ) -&gt; exclusion_figure2 exclusion_figure2 Next, I plot the distributions of the use variables. I want to show distributions, but there are a couple of single large values, so violin or density plots will look strange with a long tail. Raincloud plots could solve that to a degree, but they duplicate information. I’ll go with a doptplot, namely beeswarm plots. Like before, because I facet, I’ll turn the data into the long format first. I’m also not sure whether I like vertical or horizontal beeswarms, so I’ll do both. # temporary data file in long format dat &lt;- working_file %&gt;% pivot_longer( contains(&quot;_time&quot;), # only the time variables names_to = &quot;measure&quot;, values_to = &quot;Hours per day&quot; ) %&gt;% mutate( measure = as.factor(str_to_title(str_remove(measure, &quot;_time&quot;))), # prettier factor levels measure = fct_recode( measure, &quot;TV&quot; = &quot;Tv&quot; ), measure = fct_relevel( measure, c( &quot;Music&quot;, &quot;TV&quot;, &quot;Films&quot;, &quot;Games&quot;, &quot;Books&quot;, &quot;Magazines&quot;, &quot;Audiobooks&quot;, &quot;Total&quot; ) ) ) # summary stats for plotting means over time dat_summary &lt;- dat %&gt;% group_by(wave, measure) %&gt;% summarise( mean = mean(`Hours per day`, na.rm = T), sd = sd(`Hours per day`, na.rm = T) ) %&gt;% mutate( across( mean:sd, ~ round(.x, digits = 1) ) ) # let&#39;s try horizontal first (the commented out section adds a vertical line where the mean is) ggplot( dat, aes( x = `Hours per day`, y = 1, color = measure, fill = measure ) ) + geom_quasirandom(groupOnX=FALSE, size = 0.1, alpha = 0.5) + # geom_vline( # data = dat_summary, # aes( # xintercept = mean, # color = measure # ), # linetype = &quot;dashed&quot; # ) + geom_point( data = dat_summary, aes( x = mean, y = 0.55 ), shape = 25, size = 2 ) + facet_grid(measure ~ wave) + geom_text( data = dat_summary, aes( x = 20, y = 1.4, label = paste0(&quot;M = &quot;, mean) ), size = 3, color = &quot;black&quot; ) + geom_text( data = dat_summary, aes( x = 19.6, y = 1.3, label = paste0(&quot;SD = &quot;, sd) ), size = 3, color = &quot;black&quot; ) + theme_cowplot() + scale_colour_manual(values=cb_palette) + scale_fill_manual(values = cb_palette) + theme( axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.line.y = element_blank(), strip.background.x = element_blank(), strip.background.y = element_blank(), legend.position = &quot;none&quot; ) -&gt; figure2.1 figure2.1 I guess the trendline makes it easier to see developments (or lack thereof) over time. ggplot( dat, aes( x = as.factor(wave), y = `Hours per day`, color = measure, fill = measure, group = 1 ) ) + geom_quasirandom(size = 0.1, alpha = 0.2) + geom_line( data = dat_summary, aes( y = mean ), size = 1 ) + facet_wrap(~ measure, ncol = 2) + geom_text( data = dat_summary, aes( x = as.factor(wave), y = -1.2, label = paste0(&quot;M = &quot;, mean) ), size = 2.5, color = &quot;black&quot; ) + geom_text( data = dat_summary, aes( x = as.factor(wave), y = -2.9, label = paste0(&quot;SD = &quot;, sd) ), size = 2.5, color = &quot;black&quot; ) + theme_cowplot() + scale_colour_manual(values=cb_palette) + scale_fill_manual(values = cb_palette) + xlab(&quot;Wave&quot;) + theme( strip.background.x = element_blank(), strip.background.y = element_blank(), legend.position = &quot;none&quot; ) -&gt; figure2.2 figure2.2 Then again, for distributions with a small mean, the trendline blocks everything. Plus, because total time extends the y-axis, there’s lots of white space. I’ll give total time its separate plot to solve that issue. I also won’t have trendlines for the separate media, only for the total (too lazy to write the above into a function, so I’ll copy paste the code from above.). ggplot( dat %&gt;% filter(measure != &quot;Total&quot;), aes( x = as.factor(wave), y = `Hours per day`, color = measure, fill = measure, group = 1 ) ) + geom_quasirandom(size = 0.1, alpha = 0.2) + # geom_line( # data = dat_summary, # aes( # y = mean # ), # size = 1 # ) + facet_wrap(~ measure, ncol = 2) + geom_text( data = dat_summary %&gt;% filter(measure != &quot;Total&quot;), aes( x = as.factor(wave), y = -1.2, label = paste0(&quot;M = &quot;, mean) ), size = 2.5, color = &quot;black&quot; ) + geom_text( data = dat_summary %&gt;% filter(measure != &quot;Total&quot;), aes( x = as.factor(wave), y = -2.9, label = paste0(&quot;SD = &quot;, sd) ), size = 2.5, color = &quot;black&quot; ) + theme_cowplot() + scale_colour_manual(values=cb_palette) + scale_fill_manual(values = cb_palette) + xlab(&quot;Wave&quot;) + theme( strip.background.x = element_blank(), strip.background.y = element_blank(), legend.position = &quot;none&quot; ) -&gt; figure2.3 figure2.3 ggsave( here(&quot;figures&quot;, &quot;figure2.tiff&quot;), plot = figure2.3, width = 21 * 0.8, height = 29.7 * 0.8, units = &quot;cm&quot;, dpi = 300 ) Then a separate plot for total time. ggplot( dat %&gt;% filter(measure == &quot;Total&quot;), aes( x = as.factor(wave), y = `Hours per day`, group = 1 ) ) + geom_quasirandom(size = 0.1, alpha = 0.2, color = &quot;#CC79A7&quot;) + geom_line( data = dat_summary %&gt;% filter(measure == &quot;Total&quot;), aes( y = mean ), size = 0.5, color = &quot;#CC79A7&quot; ) + geom_text( data = dat_summary %&gt;% filter(measure == &quot;Total&quot;), aes( x = as.factor(wave), y = -1.2, label = paste0(&quot;M = &quot;, mean) ), size = 3, color = &quot;black&quot; ) + geom_text( data = dat_summary %&gt;% filter(measure == &quot;Total&quot;), aes( x = as.factor(wave), y = -2.4, label = paste0(&quot;SD = &quot;, sd) ), size = 3, color = &quot;black&quot; ) + theme_cowplot() + xlab(&quot;Wave&quot;) + ylab(&quot;Total hours per day&quot;) + theme( strip.background.x = element_blank(), strip.background.y = element_blank(), legend.position = &quot;none&quot; ) -&gt; figure3 figure3 ggsave( here(&quot;figures&quot;, &quot;figure3.tiff&quot;), plot = figure3, width = 21 * 0.9, height = 29.7 * 0.4, units = &quot;cm&quot;, dpi = 300 ) Then, I need to think of a way to visualize use vs. nonuse over time. Bar graphs could work, but that would mean a lot of bar graphs (one per medium) per wave, which is probably overwhelming. Plus, if I show raw counts, it could be confusing as well, simply because height of the bar != number of participants. If everyone at wave 1 used only one medium, but at wave two everyone used all media, it’ll look like an increase in sample size. So proportions make the most sense, simple and straightforward. # get proportions of users per medium and wave dat &lt;- working_file %&gt;% pivot_longer( contains(&quot;_time&quot;), # only the time variables names_to = &quot;measure&quot;, values_to = &quot;Hours per day&quot; ) %&gt;% mutate( # get use vs. no use in long format used = if_else(`Hours per day` == 0, 0, 1) ) %&gt;% # no need for total time filter(used == 1, measure != &quot;total_time&quot;) %&gt;% # remove &quot;tome appendix mutate(measure = as.factor(str_to_title(str_remove(measure, &quot;_time&quot;)))) %&gt;% # count how often a medium was used count(wave, measure, used) %&gt;% # add total N per wave (of only those that will be included in analysis) left_join( ., working_file %&gt;% count(wave, name = &quot;N&quot;) ) %&gt;% # get proprotion mutate( proportion = round(n / N, digits = 2) * 100, measure = fct_recode(measure, &quot;TV&quot; = &quot;Tv&quot;), measure = fct_relevel( measure, c( &quot;Music&quot;, &quot;TV&quot;, &quot;Films&quot;, &quot;Games&quot;, &quot;Books&quot;, &quot;Magazines&quot;, &quot;Audiobooks&quot; ) ) ) ggplot( dat, aes( x = as.factor(wave), y = proportion, group = measure, color = measure ) ) + geom_point(size = 3) + geom_line(size = 1) + scale_colour_manual(values=cb_palette) + scale_fill_manual(values = cb_palette) + ylab(&quot;% of people who used medium&quot;) + xlab(&quot;Wave&quot;) + geom_dl(aes(label = measure), method = list(dl.trans(x = x + 0.25), &quot;last.points&quot;, cex = 0.6)) + theme( legend.position = &quot;none&quot; ) -&gt; figure4 figure4 ggsave( here(&quot;figures&quot;, &quot;figure4.tiff&quot;), plot = figure4, width = 21 * 0.9, height = 29.7 * 0.4, units = &quot;cm&quot;, dpi = 300 ) Next, I’ll do a beeswarm plot for well-being. # temporary data file in long format dat &lt;- working_file %&gt;% pivot_longer( c(affect, life_satisfaction), # only the aggregated well-being variables names_to = &quot;measure&quot;, values_to = &quot;Value&quot; ) %&gt;% mutate( measure = fct_recode( as.factor(measure), &quot;Affect&quot; = &quot;affect&quot;, &quot;Life satisfaction&quot; = &quot;life_satisfaction&quot; ) ) # summary stats for plotting means over time dat_summary &lt;- dat %&gt;% group_by(wave, measure) %&gt;% summarise( mean = mean(Value, na.rm = T), sd = sd(Value, na.rm = T) ) %&gt;% mutate( across( mean:sd, ~ round(.x, digits = 1) ) ) ggplot( dat, aes( x = as.factor(wave), y = Value, color = measure, fill = measure, group = 1 ) ) + geom_quasirandom(size = 0.1, alpha = 0.2) + geom_line( data = dat_summary, aes( y = mean ), size = 0.5 ) + facet_wrap(~ measure, ncol = 2) + geom_text( data = dat_summary, aes( x = as.factor(wave), y = -0.5, label = paste0(&quot;M = &quot;, mean) ), size = 2.5, color = &quot;black&quot; ) + geom_text( data = dat_summary, aes( x = as.factor(wave), y = -0.9, label = paste0(&quot;SD = &quot;, sd) ), size = 2.5, color = &quot;black&quot; ) + theme_cowplot() + scale_colour_manual(values=cb_palette) + scale_fill_manual(values = cb_palette) + xlab(&quot;Wave&quot;) + theme( axis.title.y = element_blank(), strip.background.x = element_blank(), strip.background.y = element_blank(), legend.position = &quot;none&quot; ) -&gt; figure5 figure5 ggsave( here(&quot;figures&quot;, &quot;figure5.tiff&quot;), plot = figure5, width = 21 * 0.8, height = 29.7 * 0.4, units = &quot;cm&quot;, dpi = 300 ) "],
["analysis.html", "4 Analysis 4.1 Data preparation 4.2 Music 4.3 Films 4.4 TV 4.5 Video games 4.6 (E-)books 4.7 Magazines 4.8 Audiobooks", " 4 Analysis Our overarching research question is how media use in different categories and well-being influence each other over time. There were four well-being items; two were asking about life in general, two about affective states yesterday. I don’t think, just based on face validity, that these four items form one concept, which is why I treated them separately in the data processing. Let’s run a confirmatory factor analysis on the first wave and inspect the fit. The fit is poor-ish and the model suggest that we should correlate the residuals of the life satisfaction items with each other and of the affect items with each other. That confirms my idea about treating those four items as coming from two different constructs. cfa_model &lt;- &quot;well_being_factor =~ life_satisfaction_1 + life_satisfaction_2 + well_being_1 + well_being_2&quot; # get fit cfa_fit &lt;- cfa( cfa_model, data = working_file %&gt;% filter(wave == 1) ) # inspect summary summary( cfa_fit, fit.measures = TRUE, modindices = TRUE ) ## lavaan 0.6-7 ended normally after 25 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of free parameters 8 ## ## Used Total ## Number of observations 2103 2159 ## ## Model Test User Model: ## ## Test statistic 152.823 ## Degrees of freedom 2 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 4689.433 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.968 ## Tucker-Lewis Index (TLI) 0.903 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -16789.925 ## Loglikelihood unrestricted model (H1) -16713.513 ## ## Akaike (AIC) 33595.849 ## Bayesian (BIC) 33641.058 ## Sample-size adjusted Bayesian (BIC) 33615.641 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.189 ## 90 Percent confidence interval - lower 0.165 ## 90 Percent confidence interval - upper 0.215 ## P-value RMSEA &lt;= 0.05 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.038 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## well_being_factor =~ ## life_stsfctn_1 1.000 ## life_stsfctn_2 0.952 0.019 51.334 0.000 ## well_being_1 1.012 0.018 54.730 0.000 ## well_being_2 0.575 0.032 18.148 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .life_stsfctn_1 0.764 0.047 16.108 0.000 ## .life_stsfctn_2 1.413 0.058 24.476 0.000 ## .well_being_1 1.156 0.055 20.862 0.000 ## .well_being_2 6.871 0.216 31.883 0.000 ## well_beng_fctr 3.740 0.143 26.163 0.000 ## ## Modification Indices: ## ## lhs op rhs mi epc sepc.lv sepc.all sepc.nox ## 10 life_satisfaction_1 ~~ life_satisfaction_2 147.866 1.518 1.518 1.461 1.461 ## 11 life_satisfaction_1 ~~ well_being_1 49.432 -1.025 -1.025 -1.090 -1.090 ## 12 life_satisfaction_1 ~~ well_being_2 29.103 -0.381 -0.381 -0.166 -0.166 ## 13 life_satisfaction_2 ~~ well_being_1 29.103 -0.639 -0.639 -0.500 -0.500 ## 14 life_satisfaction_2 ~~ well_being_2 49.432 -0.554 -0.554 -0.178 -0.178 ## 15 well_being_1 ~~ well_being_2 147.867 0.928 0.928 0.329 0.329 4.1 Data preparation We’re interested in reciprocal effects of media use and well-being. Usually, I’d go for Random-Intercept Cross-Lagged Panel Models (RICLPM), but we have such massive zero inflation that the distribution of media use might bias the results. I emailed one of the co-authors of the Random-Intercept Cross-Lagged Panel Models and he said that these models are only well-understood for normally distributed data. Absent any simulation studies that show that these models can retrieve parameters from a non-normal data generating process, I’ll look for an alternative. Instead, I’ll rely on a mixed-models framework. Per well-being outcome (so affect and life satisfaction) and medium, I’ll run two models: The first model predicts well-being from lagged media use. We can treat well-being as normally distributed. The second mode predicts media use from lagged well-being. We treat media use as zero-inflated with a gamma distribution. These models have the advantage that we don’t need to impute missing waves. Instead, the model will weigh those with more data more heavily for the outcome distribution. Because we use lagged predictors in the model predicting use, a participant must have at least three valid waves. When we lag, the model will automatically exclude the first wave (because half of its information is contained in the second wave now). Some participants also have missing values on some waves - which is why we only kept those participants with at least three rows of data. So someone with all six waves but four excluded waves will not be included in the final sample. For both types of models, we’ll separate between- and within-person effects. We’ll not control for the lagged value of the dependent variable, see here. To be able to distinguish between within- and between-person effects, we’ll need to make use of centering. We’re dividing each predictor into a stable, level-2 (person-level) component, and a component that tells us how much each measurement deviates from that stable component (level-1 or within-person effect). See instructions from this excellent blog post. working_file &lt;- working_file %&gt;% group_by(id) %&gt;% mutate( across( c( affect, life_satisfaction, ends_with(&quot;time&quot;) ), list( between = ~ mean(.x, na.rm = TRUE), within = ~ .x - mean(.x, na.rm = TRUE) ) ) ) %&gt;% ungroup() Also, we’re interested in the threshold of going from not using a medium to using a medium. This is due to how the media use variable is distributed: Lots of zeros and continuous if not zero. Because of how we treated zeros so far, we know that zeros are qualitatively different from nonzeros. Zero means not having used at all (possibly a different process), nonzero means how much you used a medium if you used it. When media use is the outcome variable, we’ll model those different processes with a zero-inflation distribution. It’s my understanding that it’s not a good idea to select an outcome distribution based on the histogram of a variable. Richard McElreath calls this “histomancy”. After all, it’s about the distribution of the residuals after model fitting - so a weird looking distribution might still be the result of a normally distributed data generating process. In our case, I think the use variable doesn’t come from a normally distributed data generating process because we know that using vs. not using a medium is a different process. Likewise, we know that if someone used a medium, their use time cannot be zero and will be skewed toward lower values, with fewer and fewer larger values as use increases. That’s a typical case for a Gamma distribution. When media use is the predictor, we need to tell the model that there’s something special about zeros or not zeros. That’s why we’ll include a new indicator variable for whether use is zero or not. See this discussion. In this discussion, they talk about a case where there’s only one observation per case. However, I want to distinguish within- and between-person effects, like I did with the continuous part of use time. I’ll match that strategy with the indicator. First, per medium and wave, I’ll create an index variable that’s 1 when someone used a medium for a wave, and 0 when not. Second, I’ll take the average of that index variable per person. That gives us a between-person proportion. The parameter for that proportion will tell us what happens for well-being if we compare nonusers (0 proportion) to users (100 proportion), so if we go from 0 to 1. Third, we center each participant’s rows with that proportion, just like we did with use time. The parameter for this variable tells us what happens within a person when they go from not using to using, so if we go from their average to their average plus one. For example, suppose someone listened to music in three of the six waves. They’ll have their average time as the between-person effect and their deviation from that average time as the within-person effect. That’s what we did with the centering above. That person will therefore have a constant proportion of having listened to music (yes or no) of 50%. The parameter for this variable will then tell us what happens if we go one up on the proportion scale, which is bound at [0|1]. In other words, if there’s someone else who listened to music in 67% of waves, the model will give us a parameter for a comparison of not using (0) to using (1), based on all the proportion between people. Strictly speaking, the model will tell us what happens if the proportion increases by one, but we can interpret this increase as going from nonuse to use because the proportion is bound at those values. As for the within-part, say the first person listened to music every other wave. Their within-indicator would then take the values of used (1 or 0) minus proportion of use (0.5) = c(-0.5, 0.5, -0.5, 0.5, -0.5, 0.5) for the six waves. The parameter for that indicator would tell us what happens if a user goes up one point above their average proportion of listening to music across all waves. But this proportion is bound at [0|1], so effectively this tells us what happens if the user goes from not listening to music to listening to music (aka 1 up) because the raw scores are always 0 or 1. I’ll create this index variable and center it like I did above. Note that we already have filter variables, but those refer to whether someone used a medium in the three months before the first wave. That’s why I’ll use the used suffix here. working_file &lt;- working_file %&gt;% mutate( across( c( ends_with(&quot;time&quot;), -total_time ), list( used = ~ if_else(.x == 0, 0, 1) ) ) ) %&gt;% # remove the _time part of the variable name rename_with( ~ str_remove(.x, &quot;time_&quot;), ends_with(&quot;used&quot;) ) %&gt;% # center those variables group_by(id) %&gt;% mutate( across( ends_with(&quot;used&quot;), list( between = ~ mean(.x, na.rm = TRUE), within = ~ .x - mean(.x, na.rm = TRUE) ) ) ) We had NAs for those who had poor quality data in a row. However, when introducing the between variables above, we assigned a constant per participant, overwriting the NA. So I’ll reintroduce NA on the between and used variables. I’ll condition on a random variable that’s NA - affect in this case.. Any other variable would also work because all wave-level entries will be NA. working_file &lt;- working_file %&gt;% mutate( across( c( contains(&quot;used&quot;), contains(&quot;between&quot;) ), ~ replace(.x, is.na(affect), NA) ) ) Last, we need to create the lagged and led variables. If we add them to the model as lag(variable)/lead(variable), it will merely shift values one up/down across all participants. But we need to lag/lead for each participant. We can do that when specifying the data, but that’s prone to error with that many models. So I’ll manually create lagged/led variables in our working file where we lag/lead per participant. Note that we don’t need to lag everything here: The data are “naturally” lagged. At each wave, participants reported their average daily use of a medium for the preceding week and their current well-being. So lagging the times variable would mean we’re predicting current well-being with the reports of use from last week, which themselves refer to the week before. Therefore, we don’t need to lag the time variables - they are lagged already. The same holds for variables that show whether someone used a medium or not. They’re also referring to the previous week, so are “naturally” lagged. As for the well-being indicators: Here we don’t want to lag the variable, but lead them. Affect at wave 1 should predict use and time at wave 2, so we need to “move down” use and time one row per participant. Obviously, lagging well-being or leading use is the same, but I find leading more intuitive here because it corresponds to the time line of the data. working_file &lt;- working_file %&gt;% group_by(id) %&gt;% mutate( across( c( ends_with(&quot;_time&quot;) ), lead, .names = &quot;lead_{.col}&quot; ) ) %&gt;% ungroup() Note, I saved all brms model objects and load them below. Each model takes quite some time and the files get huge (a total of 35GB). If you’re reproducing the analysis and don’t want to run the models yourself, you can download the model objects from the OSF. For that, you need to set the code chunk below to eval=TRUE, which creates a model/ directory with all models inside. # create directory dir.create(&quot;models/&quot;, FALSE, TRUE) # download models osf_retrieve_node(&quot;https://osf.io/yn7sx/&quot;) %&gt;% osf_ls_nodes() %&gt;% filter(name == &quot;models&quot;) %&gt;% osf_ls_files( ., n_max = Inf ) %&gt;% osf_download( ., path = here(&quot;models&quot;), progress = TRUE ) 4.2 Music 4.2.1 Affect 4.2.1.1 Music on affect Let’s begin with modeling affect and music over time. In addition to separating within and between effects, we also let the within effects vary. So the fixed effects tell us how much an average person changed on well-being a week later if they went from not using to using a medium and how much well-being changed if a person used a medium an hour more than they usually do. We allow both of those effects to vary across participants. music_affect &lt;- brm( data = working_file, family = gaussian, affect ~ 1 + music_used_between + music_used_within + music_time_between + music_time_within + (1 + music_time_within + music_used_within | id), iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;music_affect&quot;) ) Let’s inspect the traceplots. Overall, they look fine and the chains seem to have mixed well, see (Figure ??). Figure 4.1: Traceplots and posterior distributions for Music-Affect model Figure 4.2: Traceplots and posterior distributions for Music-Affect model Figure 4.3: Traceplots and posterior distributions for Music-Affect model The posterior predictive distribution (Figure 4.4) shows that the model does an okay job in predicting our outcome. It retrieves mean well, but the outcome is not fully normally distributed, which we see in the posterior predictive distribution and hence the median is overestimated by the model. I’d say fitting another distribution (e.g., a skewed normal) might be overfitting - I think a normal data generating process for well-being is adequate. Figure 4.4: Posterior predictive checks for Music-Affect model Let’s also check for potentially influential values. Quite a lot are flagged: This might have to do with the fact that some participants only had three observations. If we leave one out, the posterior will be influenced heavily by the two remaining observation, see the discussion here. Unfortunately, using moment matching to get better LOO estimates doesn’t work for me, even when I save all parameters. Apparently, this could be a bug. And calculating ELPD directly isn’t an option because it would take days. Overall, I’m inclined to trust the model (conditional on us using a normal outcome distribution) because of the model diagnostics. It’s possible that some of the larger values on the time variable (which are quite rare) have a large influence on the posterior if they come from the same person. But we already excluded many implausible values, so this is the sample we’re working with and from which we want to generalize to the population. music_affect_loo &lt;- loo(music_affect) music_affect_loo ## ## Computed from 12000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -18112.0 105.4 ## p_loo 1955.7 34.5 ## looic 36224.0 210.8 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10617 96.6% 434 ## (0.5, 0.7] (ok) 330 3.0% 93 ## (0.7, 1] (bad) 36 0.3% 28 ## (1, Inf) (very bad) 2 0.0% 19 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Let’s inspect the summary. We see that: Music listeners were less happy than those who didn’t listen to music (music_used_between). The model also estimates the effect to be quite large: listeners scored 0.38 points lower on the ten-point scale. The credible interval doesn’t include zero, so conditional on the model, the data are 95% likely to have been generated by a true effect that does not include zero. However, if a person went from not listening to listening, they felt better the next week (music_used_within). That effect is smaller than the between effect: If someone stopped listening they felt 0.12 points worse. The credible interval doesn’t contain zero, but barely. When a person listened to one hour more music than someone else, that person also felt slightly worse (music_time_between). However, the effect is small and the posterior contains zero as well as positive effects, so we can’t be certain. The same goes for a one-hour increase from one’s typical music listening (music_time_within): the effect is positive, but super small and the posterior contains zero as well as negative values. summary(music_affect) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: affect ~ 1 + music_used_between + music_used_within + music_time_between + music_time_within + (1 + music_time_within + music_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.86 0.03 1.80 1.92 1.00 2558 5066 ## sd(music_time_within) 0.06 0.03 0.01 0.11 1.00 1546 1804 ## sd(music_used_within) 0.22 0.11 0.03 0.45 1.00 3101 3835 ## cor(Intercept,music_time_within) -0.22 0.21 -0.68 0.15 1.00 6556 3633 ## cor(Intercept,music_used_within) 0.46 0.26 -0.07 0.92 1.00 7058 6344 ## cor(music_time_within,music_used_within) -0.05 0.46 -0.87 0.79 1.00 4688 6431 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 6.26 0.09 6.07 6.44 1.00 2009 3590 ## music_used_between -0.38 0.13 -0.63 -0.12 1.00 1849 3799 ## music_used_within 0.12 0.06 0.01 0.24 1.00 24236 9993 ## music_time_between -0.02 0.02 -0.06 0.02 1.00 1988 3865 ## music_time_within 0.01 0.01 -0.01 0.03 1.00 19482 10123 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.13 0.01 1.11 1.15 1.00 9868 9496 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Let’s visualize that summary and look at the effects. Figure ?? shows that the used effects have less uncertainty associated with the extreme ends of the distribution, whereas time effects have a lot of uncertainty around smaller and larger values, probably because there aren’t many data points here. Figure 4.5: Conditional effects for Music-Affect model Figure 4.6: Conditional effects for Music-Affect model Figure 4.7: Conditional effects for Music-Affect model Figure 4.8: Conditional effects for Music-Affect model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597590 192.2 6231069 332.8 6231069 332.8 ## Vcells 27695361 211.3 147813396 1127.8 264024548 2014.4 4.2.1.2 Affect on music Let’s do the other lag of the model: The effect of affect in the previous week on music listening. Here, we’ll use a zero-inflated gamma distribution. The zero-inflation is obvious: Not everyone uses each medium at each wave. Like I said above, that’s a clear argument that zero vs. not zero is a different data generating process than time listened. And like above, where I wanted to see how listening vs. not listening is related to affect a week later, I want to see whether changes in affect are related to changes in the probability to listen to music a week later. Besides predicting listening vs. not listening, we also want to see whether changes in affect are related to changes in music listening duration a week later (so the non-zero parts of media use). We know that the non-zero duration is continuous (i.e., hours) and cannot be zero. We can also see from the distribution that the variation increases with larger values, so the variation likely increases with the mean. That’s why I think a Gamma distribution is adequate. Below I run the model. Note again that music time is naturally lagged (i.e., reported for the previous week). So get the lagged effect of affect on music time, we use the led music time. On my machine, the model took about an two hours. affect_music &lt;- brm( bf( # predicting continuous part lead_music_time ~ 1 + affect_between + affect_within + (1 + affect_within | id), # predicting hurdle part hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;affect_music&quot;) ) Let’s inspect the traceplots. Overall, they look fine and the chains seem to have mixed well, see (Figure ??). Figure 4.9: Traceplots and posterior distributions for Affect-Music model Figure 4.10: Traceplots and posterior distributions for Affect-Music model Figure 4.11: Traceplots and posterior distributions for Affect-Music model The posterior predictive distribution (Figure 4.12) shows that the model does an excellent job in predicting our outcome - at least if we follow the distribution. Self-reported time will necessarily bundle around full and half hours (e.g., 0.5h, 1h, 1.5h etc.), which is why the distribution of the data has spikes. The model smooths those spikes, which is a good thing because we want to get at the data generating process. It retrieves the mean well, but underestimates the median, quite possibly because the model expects less zeros, but more very small values - which is what we want from multilevel models: shrinkage. The other model fit diagnostics are okay, but not great. Figure 4.12: Posterior predictive checks for Affect-Music model Let’s also check for potentially influential values. A lot are flagged, like in the previous model: Again, I think that speaks for the flexibility of the model. There are multiple participants with only two observations. If we leave one out, the posterior will be influenced heavily by the one remaining observation Once more, I’m inclined to trust the model because the model diagnostics looked good. affect_music_loo &lt;- loo(affect_music) affect_music_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -11519.8 123.4 ## p_loo 2101.0 53.1 ## looic 23039.6 246.8 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7702 88.5% 761 ## (0.5, 0.7] (ok) 630 7.2% 100 ## (0.7, 1] (bad) 264 3.0% 10 ## (1, Inf) (very bad) 102 1.2% 1 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Summary: For mu we’re on the log scale, so we need to exponentiate which yields exp(0.97) = 2.64 hours on non-zero music time - when a participant has zero affect and no deviation from that affect, so not a very meaningful number (Intercept) For the hurdle, so the odds of having zero rather than not zero, the model estimates considerable shrinkage: The probability of having a zero is plogis(-9.46) = 7.790052210^{-5}, much smaller than the proportion of zeros in the actual data. That’s okay, because most zeros come from very few participants who have all zero, so the model takes that into account (hu_Intercept). When we look at the effect of affect on non-zero hours, we’re still on the log scale, meaning we need to exponentiate which gives us the factor at which y increases with each increase on x: If we compare a participant with another participant with an increase of one on affect, their music time increases (so decreases) by a factor of exp(-0.02) = 0.98 one week later - a small effect, but the posterior doesn’t include zero (affect_between) The same goes for the within effect: As a person goes up one point on affect compared to their typical affect score, their music time increases (i.e., decreases) by a factor of exp(-0.004) = 1 - a completely negligible, small effect whose posterior includes zero (affect_within). As for whether affect influences whether someone went from not listening to music to listening to music: The between effect shows that people with higher affect also have higher odds of not listening to music across all waves: exp(0.48) = 1.6160744 for hu_affect_between. Interestingly, if the average users went went up one point from their typical affect, they had higher odds of not listening to music a week later, exp(0.21) = 1.2336781. summary(affect_music) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_music_time ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.76 0.01 0.73 0.79 1.00 2207 4724 ## sd(affect_within) 0.04 0.02 0.00 0.07 1.00 845 1934 ## sd(hu_Intercept) 8.86 0.53 7.88 9.96 1.00 3052 5772 ## sd(hu_affect_within) 0.31 0.23 0.01 0.86 1.00 2528 5195 ## cor(Intercept,affect_within) -0.35 0.24 -0.88 0.05 1.00 3478 2685 ## cor(hu_Intercept,hu_affect_within) -0.39 0.56 -0.99 0.87 1.00 5938 7531 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.97 0.06 0.86 1.09 1.00 1812 3180 ## hu_Intercept -9.46 0.94 -11.39 -7.70 1.00 1799 3685 ## affect_between -0.02 0.01 -0.04 -0.00 1.00 1901 3045 ## affect_within -0.00 0.01 -0.02 0.01 1.00 17660 10180 ## hu_affect_between 0.48 0.13 0.23 0.74 1.00 1597 3508 ## hu_affect_within 0.21 0.20 -0.08 0.68 1.00 4093 6519 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 5.35 0.11 5.14 5.58 1.00 5354 8356 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects of affect on the amount of music listened a week later. We see the between effect could be meaningful over the entire range of the affect scale, but the within effect is almost flat. Figure 4.13: Conditional effects for Music-Affect model Figure 4.14: Conditional effects for Music-Affect model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597567 192.2 6231069 332.8 6231069 332.8 ## Vcells 27696172 211.4 173958719 1327.2 264024548 2014.4 4.2.2 Life Satisfaction From now on, I’ll be less verbose in describing the models, simply because we’re running 28 in total (7 categories x two directions x 2 well-being measures). I’ll apply the same steps as I did above with affect and music, but won’t describe every parameter unless there’s something unusual that sticks out. Rather, in the end of this section, I’ll create a summary figure. 4.2.2.1 Music on Life Satisfaction Let’s run the model. Again, that took about half an hour on my machine. music_life &lt;- brm( data = working_file, family = gaussian, life_satisfaction ~ 1 + music_used_between + music_used_within + music_time_between + music_time_within + (1 + music_time_within + music_used_within | id), iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;music_life&quot;) ) The traceplots look good (Figure ??). Figure 4.15: Traceplots and posterior distributions for Music-Life Satisfaction model Figure 4.16: Traceplots and posterior distributions for Music-Life Satisfaction model Figure 4.17: Traceplots and posterior distributions for Music-Life Satisfaction model The posterior predictive distribution (Figure 4.18) shows that the model does a good job in predicting our outcome. Like before, it slightly underestimates the median; everything else looks fine. Figure 4.18: Posterior predictive checks for Music-Life Satisfaction model The outliers are in about the same range as in previous models, and the model diagnostics look good. music_life_loo &lt;- loo(music_life) music_life_loo ## ## Computed from 12000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -14530.0 147.9 ## p_loo 2289.4 54.1 ## looic 29059.9 295.8 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10210 92.9% 623 ## (0.5, 0.7] (ok) 623 5.7% 101 ## (0.7, 1] (bad) 137 1.2% 14 ## (1, Inf) (very bad) 15 0.1% 1 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Let’s inspect the summary. We see that: Music listeners had lower satisfaction with life than non-listeners (music_used_between), but the effect is much smaller than for affect and the posterior contains both zero and a lot of negative values However, if a person went from not listening to listening, they reported higher life satisfaction nthe next week (music_used_within), but posterior contains zero. When a person listened to one hour more music than someone else, that person reported slightly higher life satisfaction (music_time_between), but 0 is in CI. The same goes for a one-hour increase from one’s typical music listening (music_time_within): the effect is positive, but super small and the posterior contains zero as well as negative values. summary(music_life) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: life_satisfaction ~ 1 + music_used_between + music_used_within + music_time_between + music_time_within + (1 + music_time_within + music_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.91 0.03 1.85 1.96 1.01 1211 2309 ## sd(music_time_within) 0.11 0.01 0.08 0.14 1.00 2961 5824 ## sd(music_used_within) 0.50 0.08 0.33 0.65 1.00 818 2361 ## cor(Intercept,music_time_within) -0.22 0.09 -0.39 -0.06 1.00 8603 9541 ## cor(Intercept,music_used_within) 0.13 0.09 -0.05 0.31 1.00 8745 7147 ## cor(music_time_within,music_used_within) 0.18 0.31 -0.36 0.83 1.01 478 752 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 6.43 0.09 6.24 6.61 1.01 754 1588 ## music_used_between -0.11 0.13 -0.37 0.15 1.01 536 1281 ## music_used_within 0.04 0.05 -0.05 0.13 1.00 15623 10202 ## music_time_between 0.02 0.02 -0.02 0.07 1.01 819 1615 ## music_time_within 0.01 0.01 -0.01 0.03 1.00 11135 9998 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.80 0.01 0.79 0.81 1.00 8930 9477 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects Figure 4.19: Conditional effects for Music-Affect model Figure 4.20: Conditional effects for Music-Affect model Figure 4.21: Conditional effects for Music-Affect model Figure 4.22: Conditional effects for Music-Affect model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597564 192.2 6231069 332.8 6231069 332.8 ## Vcells 27696858 211.4 139166976 1061.8 264024548 2014.4 4.2.2.2 Life satisfaction on music Below I run the model. On my machine, the model took about three and a half hours. life_music &lt;- brm( bf( # predicting continuous part lead_music_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id), # predicting hurdle part hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;life_music&quot;) ) The chains seem to have mixed well, see (Figure ??). Figure 4.23: Traceplots and posterior distributions for Life Satisfaction-Music model Figure 4.24: Traceplots and posterior distributions for Life Satisfaction-Music model Figure 4.25: Traceplots and posterior distributions for Life Satisfaction-Music model The posterior predictive distribution (Figure 4.26) shows that the model does an excellent job in predicting our outcome. Once more, it shifts zero values to very small values (shrinkage), which biases the median. Figure 4.26: Posterior predictive checks for Life Satisfaction-Music model Once more, there are several potential outliers. Again, because the model diagnostics look good and leaving one out here will estimate parameters for a participant with only two observations, which can lead to influential values, I believe the model is just flexible. life_music_loo &lt;- loo(life_music) life_music_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -11513.5 123.2 ## p_loo 2082.9 52.6 ## looic 23026.9 246.5 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7652 88.0% 701 ## (0.5, 0.7] (ok) 676 7.8% 157 ## (0.7, 1] (bad) 276 3.2% 10 ## (1, Inf) (very bad) 94 1.1% 1 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Summary: Those with higher life satisfaction have a (very small) tendency to listen to more music a week later than those with lower life satisfaction: exp(0.02) = 1.02 (life_satisfaction_between) As a person goes up one point on affect compared to their typical life satisfaction score, their music time increases by a factor of exp(0.002) = 1 - a completely negligible, small effect whose posterior includes zero (life_satisfaction_within). The between effect shows that people with higher life satisfaction also have lower odds of not listening to music across all waves: exp(-0.31) = 0.733447 for hu_life_satisfaction_between - but the posterior goes from negative to positive. If the average users went went up one point from their typical life satisfaction score, they had lower odds of not listening to music a week later, exp(-0.15) = 0.860708, but again the posterior includes a wide range of values, including zero. summary(life_music) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_music_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.76 0.01 0.73 0.79 1.00 2364 4922 ## sd(life_satisfaction_within) 0.04 0.02 0.00 0.08 1.00 1295 3789 ## sd(hu_Intercept) 9.01 0.55 8.00 10.19 1.00 3125 5342 ## sd(hu_life_satisfaction_within) 0.50 0.24 0.06 1.02 1.00 2794 3283 ## cor(Intercept,life_satisfaction_within) -0.03 0.34 -0.78 0.75 1.00 9234 4000 ## cor(hu_Intercept,hu_life_satisfaction_within) 0.11 0.55 -0.88 0.94 1.00 5983 6577 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.71 0.07 0.58 0.84 1.00 1752 3009 ## hu_Intercept -6.36 0.90 -8.17 -4.64 1.00 1794 3694 ## life_satisfaction_between 0.02 0.01 0.00 0.04 1.00 1669 3526 ## life_satisfaction_within 0.00 0.01 -0.01 0.02 1.00 16724 9671 ## hu_life_satisfaction_between -0.05 0.13 -0.31 0.19 1.00 1651 3214 ## hu_life_satisfaction_within -0.15 0.25 -0.68 0.36 1.00 6065 7309 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 5.33 0.11 5.12 5.55 1.00 6693 8054 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects of life satisfaction on the amount of music listened a week later. Figure 4.27: Conditional effects for Life Satisfaction-Music model Figure 4.28: Conditional effects for Life Satisfaction-Music model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597569 192.2 6231069 332.8 6231069 332.8 ## Vcells 27697689 211.4 196873089 1502.1 264024548 2014.4 4.3 Films 4.3.1 Affect 4.3.1.1 Films on affect films_affect &lt;- brm( data = working_file, family = gaussian, affect ~ 1 + films_used_between + films_used_within + films_time_between + films_time_within + (1 + films_time_within + films_used_within | id), iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;films_affect&quot;) ) Traceplots look good, see (Figure ??). Figure 4.29: Traceplots and posterior distributions for Films-Affect model Figure 4.30: Traceplots and posterior distributions for Films-Affect model Figure 4.31: Traceplots and posterior distributions for Films-Affect model The posterior predictive distribution (Figure 4.32) looks okay, like in previous models. Figure 4.32: Posterior predictive checks for Films-Affect model The outliers are in about the same range as in previous models, and the model diagnostics look good. films_affect_loo &lt;- loo(films_affect) films_affect_loo ## ## Computed from 12000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -18109.0 105.7 ## p_loo 2070.9 36.3 ## looic 36218.0 211.4 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10483 95.4% 448 ## (0.5, 0.7] (ok) 447 4.1% 152 ## (0.7, 1] (bad) 51 0.5% 38 ## (1, Inf) (very bad) 4 0.0% 7 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(films_affect) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: affect ~ 1 + films_used_between + films_used_within + films_time_between + films_time_within + (1 + films_time_within + films_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.85 0.03 1.79 1.91 1.00 2468 4159 ## sd(films_time_within) 0.08 0.02 0.02 0.12 1.00 1657 1479 ## sd(films_used_within) 0.55 0.14 0.22 0.79 1.00 768 785 ## cor(Intercept,films_time_within) 0.08 0.16 -0.22 0.39 1.00 7871 4187 ## cor(Intercept,films_used_within) 0.01 0.12 -0.21 0.23 1.00 8904 4186 ## cor(films_time_within,films_used_within) -0.34 0.42 -0.92 0.69 1.00 522 1078 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 6.41 0.09 6.23 6.58 1.00 1658 3026 ## films_used_between -0.58 0.14 -0.85 -0.31 1.00 1523 2729 ## films_used_within 0.07 0.06 -0.04 0.18 1.00 18132 10024 ## films_time_between -0.03 0.02 -0.07 0.02 1.00 1795 3445 ## films_time_within 0.00 0.01 -0.02 0.02 1.00 15647 10134 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.12 0.01 1.11 1.14 1.00 6560 8297 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows conditional effects. Figure 4.33: Conditional effects for Films-Affect model Figure 4.34: Conditional effects for Films-Affect model Figure 4.35: Conditional effects for Films-Affect model Figure 4.36: Conditional effects for Films-Affect model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597609 192.2 6231069 332.8 6231069 332.8 ## Vcells 27698454 211.4 157498472 1201.7 264024548 2014.4 4.3.1.2 Affect on films affect_films &lt;- brm( bf( # predicting continuous part lead_films_time ~ 1 + affect_between + affect_within + (1 + affect_within | id), # predicting hurdle part hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;affect_films&quot;) ) Traceplots look good, see (Figure ??). Figure 4.37: Traceplots and posterior distributions for Affect-Films model Figure 4.38: Traceplots and posterior distributions for Affect-Films model Figure 4.39: Traceplots and posterior distributions for Affect-Films model The posterior predictive distribution (Figure 4.40) looks okay, like in previous models. Figure 4.40: Posterior predictive checks for Affect-Films model The outliers are in about the same range as in previous models, and the model diagnostics look good. affect_films_loo &lt;- loo(affect_films) affect_films_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -12653.3 129.0 ## p_loo 2333.3 51.9 ## looic 25306.6 258.0 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7548 86.8% 546 ## (0.5, 0.7] (ok) 689 7.9% 174 ## (0.7, 1] (bad) 391 4.5% 12 ## (1, Inf) (very bad) 70 0.8% 2 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(affect_films) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_films_time ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.60 0.01 0.57 0.62 1.00 2609 5177 ## sd(affect_within) 0.05 0.02 0.01 0.08 1.00 914 708 ## sd(hu_Intercept) 5.78 0.28 5.26 6.35 1.00 2593 5498 ## sd(hu_affect_within) 0.25 0.14 0.01 0.54 1.00 1062 2592 ## cor(Intercept,affect_within) 0.15 0.17 -0.12 0.53 1.00 2342 1348 ## cor(hu_Intercept,hu_affect_within) 0.06 0.50 -0.88 0.92 1.00 5887 5689 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 1.08 0.05 0.98 1.17 1.00 1812 3613 ## hu_Intercept -6.42 0.56 -7.57 -5.36 1.00 1962 3865 ## affect_between -0.02 0.01 -0.03 -0.00 1.00 1849 3035 ## affect_within -0.01 0.01 -0.02 0.00 1.00 14139 10391 ## hu_affect_between 0.42 0.08 0.26 0.59 1.00 1952 3896 ## hu_affect_within 0.03 0.10 -0.18 0.23 1.00 5926 6769 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 5.61 0.12 5.37 5.85 1.00 3085 6328 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects. Figure 4.41: Conditional effects for Affect-Films model Figure 4.42: Conditional effects for Affect-Films model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597613 192.2 6231069 332.8 6231069 332.8 ## Vcells 27699117 211.4 185126374 1412.5 264024548 2014.4 4.3.2 Life satisfaction 4.3.2.1 Films on life satisfaction films_life &lt;- brm( data = working_file, family = gaussian, life_satisfaction ~ 1 + films_used_between + films_used_within + films_time_between + films_time_within + (1 + films_time_within + films_used_within | id), iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;films_life&quot;) ) The traceplots look good (Figure ??). Figure 4.43: Traceplots and posterior distributions for Films-Life Satisfaction model Figure 4.44: Traceplots and posterior distributions for Films-Life Satisfaction model Figure 4.45: Traceplots and posterior distributions for Films-Life Satisfaction model The posterior predictive distribution (Figure 4.46) shows that the model does a good job in predicting our outcome. Figure 4.46: Posterior predictive checks for Films-Life Satisfaction model The outliers are in about the same range as in previous models, and the model diagnostics look good. films_life_loo &lt;- loo(films_life) films_life_loo ## ## Computed from 12000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -14553.5 146.7 ## p_loo 2240.4 52.1 ## looic 29107.0 293.4 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10339 94.1% 487 ## (0.5, 0.7] (ok) 519 4.7% 114 ## (0.7, 1] (bad) 114 1.0% 14 ## (1, Inf) (very bad) 13 0.1% 5 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(films_life) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: life_satisfaction ~ 1 + films_used_between + films_used_within + films_time_between + films_time_within + (1 + films_time_within + films_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.91 0.03 1.85 1.97 1.00 924 1863 ## sd(films_time_within) 0.08 0.01 0.05 0.10 1.00 2431 5028 ## sd(films_used_within) 0.40 0.09 0.21 0.56 1.01 653 1783 ## cor(Intercept,films_time_within) -0.03 0.11 -0.25 0.18 1.00 11830 8765 ## cor(Intercept,films_used_within) 0.10 0.11 -0.10 0.32 1.00 9109 5304 ## cor(films_time_within,films_used_within) 0.17 0.36 -0.43 0.88 1.01 521 1424 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 6.53 0.09 6.36 6.72 1.00 795 1278 ## films_used_between -0.18 0.14 -0.44 0.09 1.00 686 1316 ## films_used_within 0.02 0.04 -0.06 0.10 1.00 16662 9772 ## films_time_between 0.00 0.02 -0.04 0.05 1.00 871 1905 ## films_time_within 0.00 0.01 -0.01 0.02 1.00 12798 9452 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.80 0.01 0.79 0.82 1.00 7153 8760 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects Figure 4.47: Conditional effects for Films-Life Satisfaction model Figure 4.48: Conditional effects for Films-Life Satisfaction model Figure 4.49: Conditional effects for Films-Life Satisfaction model Figure 4.50: Conditional effects for Films-Life Satisfaction model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597623 192.2 6231069 332.8 6231069 332.8 ## Vcells 27699848 211.4 148101100 1130.0 264024548 2014.4 4.3.2.2 Life satisfaction on films life_films &lt;- brm( bf( # predicting continuous part lead_films_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id), # predicting hurdle part hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;life_films&quot;) ) The chains seem to have mixed well, see (Figure ??). Figure 4.51: Traceplots and posterior distributions for Life Satisfaction-Films model Figure 4.52: Traceplots and posterior distributions for Life Satisfaction-Films model Figure 4.53: Traceplots and posterior distributions for Life Satisfaction-Films model The posterior predictive distribution (Figure 4.54) shows that the model do a good job in predicting our outcome. Figure 4.54: Posterior predictive checks for Life Satisfaction-Films model The outliers are in about the same range as in previous models, and the model diagnostics look good. life_films_loo &lt;- loo(life_films) life_films_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -12636.2 129.4 ## p_loo 2313.2 52.0 ## looic 25272.4 258.7 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7543 86.7% 513 ## (0.5, 0.7] (ok) 687 7.9% 136 ## (0.7, 1] (bad) 400 4.6% 17 ## (1, Inf) (very bad) 68 0.8% 1 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(life_films) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_films_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.60 0.01 0.58 0.62 1.00 3018 5935 ## sd(life_satisfaction_within) 0.07 0.02 0.03 0.10 1.00 1290 1436 ## sd(hu_Intercept) 5.87 0.29 5.33 6.46 1.00 3227 5686 ## sd(hu_life_satisfaction_within) 0.39 0.19 0.04 0.76 1.00 1916 3118 ## cor(Intercept,life_satisfaction_within) -0.17 0.14 -0.46 0.09 1.00 4802 2405 ## cor(hu_Intercept,hu_life_satisfaction_within) 0.05 0.52 -0.87 0.91 1.00 5438 5421 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.92 0.05 0.82 1.03 1.00 1838 3301 ## hu_Intercept -4.26 0.57 -5.40 -3.18 1.00 1927 3638 ## life_satisfaction_between 0.01 0.01 -0.01 0.03 1.00 1783 2987 ## life_satisfaction_within 0.01 0.01 -0.01 0.02 1.00 12701 10479 ## hu_life_satisfaction_between 0.05 0.08 -0.11 0.21 1.00 1947 3371 ## hu_life_satisfaction_within 0.01 0.15 -0.29 0.32 1.00 5537 7355 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 5.61 0.12 5.37 5.85 1.00 4922 7087 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects. Figure 4.55: Conditional effects for Life Satisfaction-Films model Figure 4.56: Conditional effects for Life Satisfaction-Films model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597603 192.2 6231069 332.8 6231069 332.8 ## Vcells 27700519 211.4 174301100 1329.9 264024548 2014.4 4.4 TV 4.4.1 Affect 4.4.1.1 TV on affect tv_affect &lt;- brm( data = working_file, family = gaussian, affect ~ 1 + tv_used_between + tv_used_within + tv_time_between + tv_time_within + (1 + tv_time_within + tv_used_within | id), iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;tv_affect&quot;) ) Traceplots look good, see (Figure ??). Figure 4.57: Traceplots and posterior distributions for TV-affect model Figure 4.58: Traceplots and posterior distributions for TV-affect model Figure 4.59: Traceplots and posterior distributions for TV-affect model The posterior predictive distribution (Figure 4.60) looks okay, like in previous models. Figure 4.60: Posterior predictive checks for TV-affect model The outliers are in about the same range as in previous models, and the model diagnostics look good. tv_affect_loo &lt;- loo(tv_affect) tv_affect_loo ## ## Computed from 12000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -18088.1 105.3 ## p_loo 2022.1 35.4 ## looic 36176.2 210.7 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10549 96.0% 531 ## (0.5, 0.7] (ok) 387 3.5% 108 ## (0.7, 1] (bad) 47 0.4% 27 ## (1, Inf) (very bad) 2 0.0% 4 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(tv_affect) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: affect ~ 1 + tv_used_between + tv_used_within + tv_time_between + tv_time_within + (1 + tv_time_within + tv_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.86 0.03 1.80 1.92 1.00 2338 4271 ## sd(tv_time_within) 0.06 0.02 0.02 0.09 1.00 1606 1396 ## sd(tv_used_within) 0.49 0.18 0.06 0.77 1.01 655 904 ## cor(Intercept,tv_time_within) -0.02 0.16 -0.32 0.28 1.00 9556 4271 ## cor(Intercept,tv_used_within) 0.01 0.16 -0.29 0.33 1.00 6971 2509 ## cor(tv_time_within,tv_used_within) -0.26 0.46 -0.92 0.80 1.00 669 1682 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 6.35 0.10 6.15 6.54 1.00 1670 3232 ## tv_used_between -0.52 0.14 -0.79 -0.25 1.00 1536 3120 ## tv_used_within 0.32 0.06 0.20 0.44 1.00 19453 10357 ## tv_time_between -0.01 0.02 -0.04 0.03 1.00 1638 3115 ## tv_time_within -0.01 0.01 -0.03 0.00 1.00 17512 10735 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.12 0.01 1.11 1.14 1.00 7251 9895 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows conditional effects. Figure 4.61: Conditional effects for TV-affect model Figure 4.62: Conditional effects for TV-affect model Figure 4.63: Conditional effects for TV-affect model Figure 4.64: Conditional effects for TV-affect model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597607 192.2 6231069 332.8 6231069 332.8 ## Vcells 27701195 211.4 139440880 1063.9 264024548 2014.4 4.4.1.2 Affect on TV affect_tv &lt;- brm( bf( # predicting continuous part lead_tv_time ~ 1 + affect_between + affect_within + (1 + affect_within | id), # predicting hurdle part hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;affect_tv&quot;) ) Traceplots look good, see (Figure ??). Figure 4.65: Traceplots and posterior distributions for Affect-TV model Figure 4.66: Traceplots and posterior distributions for Affect-TV model Figure 4.67: Traceplots and posterior distributions for Affect-TV model The posterior predictive distribution (Figure 4.68) looks okay, like in previous models. Figure 4.68: Posterior predictive checks for Affect-TV model The outliers are in about the same range as in previous models, and the model diagnostics look good. affect_tv_loo &lt;- loo(affect_tv) affect_tv_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -13342.2 138.3 ## p_loo 2106.3 55.7 ## looic 26684.4 276.6 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7671 88.2% 517 ## (0.5, 0.7] (ok) 649 7.5% 167 ## (0.7, 1] (bad) 287 3.3% 17 ## (1, Inf) (very bad) 91 1.0% 1 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(affect_tv) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_tv_time ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.63 0.01 0.61 0.66 1.00 2205 4586 ## sd(affect_within) 0.08 0.01 0.06 0.09 1.00 2565 4401 ## sd(hu_Intercept) 12.36 0.94 10.69 14.37 1.00 2990 5055 ## sd(hu_affect_within) 0.35 0.26 0.02 1.02 1.00 2586 4882 ## cor(Intercept,affect_within) -0.03 0.08 -0.18 0.12 1.00 10673 8894 ## cor(hu_Intercept,hu_affect_within) -0.25 0.59 -0.98 0.91 1.00 6226 5652 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 1.27 0.05 1.17 1.37 1.00 1429 2809 ## hu_Intercept -15.87 1.61 -19.30 -12.91 1.00 1992 4123 ## affect_between -0.01 0.01 -0.02 0.01 1.00 1363 2525 ## affect_within -0.01 0.01 -0.02 0.00 1.00 14420 9042 ## hu_affect_between 0.84 0.20 0.47 1.24 1.00 1709 3706 ## hu_affect_within 0.03 0.28 -0.42 0.71 1.00 5071 5499 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 7.12 0.15 6.84 7.42 1.00 6449 8029 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects. Figure 4.69: Conditional effects for Affect-TV model Figure 4.70: Conditional effects for Affect-TV model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597611 192.2 6231069 332.8 6231069 332.8 ## Vcells 27701845 211.4 197249610 1504.9 264024548 2014.4 4.4.2 Life satisfaction 4.4.2.1 TV on life satisfaction tv_life &lt;- brm( data = working_file, family = gaussian, life_satisfaction ~ 1 + tv_used_between + tv_used_within + tv_time_between + tv_time_within + (1 + tv_time_within + tv_used_within | id), iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;tv_life&quot;) ) The traceplots look good (Figure ??). Figure 4.71: Traceplots and posterior distributions for TV-Life Satisfaction model Figure 4.72: Traceplots and posterior distributions for TV-Life Satisfaction model Figure 4.73: Traceplots and posterior distributions for TV-Life Satisfaction model The posterior predictive distribution (Figure 4.74) shows that the model does a good job in predicting our outcome. Figure 4.74: Posterior predictive checks for TV-Life Satisfaction model The outliers are in about the same range as in previous models, and the model diagnostics look good. tv_life_loo &lt;- loo(tv_life) tv_life_loo ## ## Computed from 12000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -14491.4 141.1 ## p_loo 2350.7 53.3 ## looic 28982.7 282.2 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10001 91.0% 580 ## (0.5, 0.7] (ok) 775 7.1% 91 ## (0.7, 1] (bad) 190 1.7% 12 ## (1, Inf) (very bad) 19 0.2% 3 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(tv_life) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: life_satisfaction ~ 1 + tv_used_between + tv_used_within + tv_time_between + tv_time_within + (1 + tv_time_within + tv_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.91 0.03 1.85 1.97 1.00 1259 2194 ## sd(tv_time_within) 0.08 0.01 0.06 0.10 1.00 2516 4556 ## sd(tv_used_within) 0.74 0.07 0.59 0.87 1.00 1685 3079 ## cor(Intercept,tv_time_within) -0.08 0.08 -0.23 0.08 1.00 11636 10011 ## cor(Intercept,tv_used_within) 0.12 0.07 -0.01 0.25 1.00 9586 9190 ## cor(tv_time_within,tv_used_within) -0.30 0.19 -0.59 0.12 1.00 979 1412 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 6.62 0.10 6.43 6.82 1.00 790 1742 ## tv_used_between -0.24 0.14 -0.50 0.03 1.00 734 1664 ## tv_used_within 0.08 0.05 -0.02 0.18 1.00 13043 10030 ## tv_time_between -0.01 0.02 -0.04 0.02 1.00 833 1834 ## tv_time_within -0.01 0.01 -0.03 0.00 1.00 11460 10393 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.79 0.01 0.78 0.81 1.00 9884 9895 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects Figure 4.75: Conditional effects for TV-Life Satisfaction model Figure 4.76: Conditional effects for TV-Life Satisfaction model Figure 4.77: Conditional effects for TV-Life Satisfaction model Figure 4.78: Conditional effects for TV-Life Satisfaction model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597651 192.2 6231069 332.8 6231069 332.8 ## Vcells 27702600 211.4 157799688 1204.0 264024548 2014.4 4.4.2.2 Life satisfaction on TV life_tv &lt;- brm( bf( # predicting continuous part lead_tv_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id), # predicting hurdle part hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;life_tv&quot;) ) The chains seem to have mixed well, see (Figure ??). Figure 4.79: Traceplots and posterior distributions for Life Satisfaction-TV model Figure 4.80: Traceplots and posterior distributions for Life Satisfaction-TV model Figure 4.81: Traceplots and posterior distributions for Life Satisfaction-TV model The posterior predictive distribution (Figure 4.82) shows that the model do a good job in predicting our outcome. Figure 4.82: Posterior predictive checks for Life Satisfaction-TV model The outliers are in about the same range as in previous models, and the model diagnostics look good. life_tv_loo &lt;- loo(life_tv) life_tv_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -13358.9 139.8 ## p_loo 2078.6 56.1 ## looic 26717.8 279.5 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7714 88.7% 833 ## (0.5, 0.7] (ok) 623 7.2% 125 ## (0.7, 1] (bad) 262 3.0% 16 ## (1, Inf) (very bad) 99 1.1% 2 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(life_tv) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_tv_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.64 0.01 0.61 0.66 1.00 2373 4782 ## sd(life_satisfaction_within) 0.09 0.01 0.07 0.12 1.00 2638 4171 ## sd(hu_Intercept) 12.35 0.93 10.69 14.31 1.00 3129 6110 ## sd(hu_life_satisfaction_within) 0.39 0.34 0.02 1.26 1.00 2890 4228 ## cor(Intercept,life_satisfaction_within) -0.08 0.08 -0.24 0.09 1.00 12933 9443 ## cor(hu_Intercept,hu_life_satisfaction_within) -0.12 0.64 -0.98 0.96 1.00 7309 6773 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 1.24 0.05 1.13 1.34 1.00 1801 3195 ## hu_Intercept -13.27 1.55 -16.45 -10.41 1.00 1938 3472 ## life_satisfaction_between -0.00 0.01 -0.02 0.01 1.00 1878 3104 ## life_satisfaction_within 0.01 0.01 0.00 0.03 1.00 16651 9659 ## hu_life_satisfaction_between 0.38 0.19 0.01 0.76 1.00 1618 3056 ## hu_life_satisfaction_within 0.13 0.36 -0.50 1.04 1.00 5016 4089 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 7.07 0.14 6.79 7.36 1.00 6724 9323 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects. Figure 4.83: Conditional effects for Life Satisfaction-TV model Figure 4.84: Conditional effects for Life Satisfaction-TV model 4.5 Video games 4.5.1 Affect 4.5.1.1 Games on affect games_affect &lt;- brm( data = working_file, family = gaussian, affect ~ 1 + games_used_between + games_used_within + games_time_between + games_time_within + (1 + games_time_within + games_used_within | id), iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;games_affect&quot;) ) Traceplots look good, see (Figure ??). Figure 4.85: Traceplots and posterior distributions for Games-Affect model Figure 4.86: Traceplots and posterior distributions for Games-Affect model Figure 4.87: Traceplots and posterior distributions for Games-Affect model The posterior predictive distribution (Figure 4.88) looks okay, like in previous models. Figure 4.88: Posterior predictive checks for Games-Affect model The outliers are in about the same range as in previous models, and the model diagnostics look good. games_affect_loo &lt;- loo(games_affect) games_affect_loo ## ## Computed from 12000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -18108.9 105.5 ## p_loo 1992.1 34.8 ## looic 36217.9 210.9 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10558 96.1% 554 ## (0.5, 0.7] (ok) 378 3.4% 114 ## (0.7, 1] (bad) 49 0.4% 16 ## (1, Inf) (very bad) 0 0.0% &lt;NA&gt; ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(games_affect) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: affect ~ 1 + games_used_between + games_used_within + games_time_between + games_time_within + (1 + games_time_within + games_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.86 0.03 1.80 1.92 1.00 2195 4042 ## sd(games_time_within) 0.08 0.03 0.02 0.13 1.00 1895 2608 ## sd(games_used_within) 0.30 0.12 0.03 0.52 1.00 1818 2315 ## cor(Intercept,games_time_within) 0.19 0.19 -0.20 0.57 1.00 10965 6328 ## cor(Intercept,games_used_within) 0.11 0.23 -0.36 0.60 1.00 9623 4545 ## cor(games_time_within,games_used_within) 0.55 0.33 -0.26 0.96 1.00 2411 3963 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 6.08 0.05 5.98 6.19 1.00 1676 3086 ## games_used_between -0.44 0.13 -0.69 -0.19 1.00 1757 3418 ## games_used_within 0.01 0.05 -0.09 0.12 1.00 22134 8654 ## games_time_between -0.00 0.03 -0.06 0.05 1.00 2177 4108 ## games_time_within -0.01 0.01 -0.03 0.02 1.00 15696 10619 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.13 0.01 1.11 1.15 1.00 8760 9049 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows conditional effects. Figure 4.89: Conditional effects for Games-Affect model Figure 4.90: Conditional effects for Games-Affect model Figure 4.91: Conditional effects for Games-Affect model Figure 4.92: Conditional effects for Games-Affect model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597661 192.2 6231069 332.8 6231069 332.8 ## Vcells 27703984 211.4 148378879 1132.1 264024548 2014.4 4.5.1.2 Affect on video games affect_games &lt;- brm( bf( # predicting continuous part lead_games_time ~ 1 + affect_between + affect_within + (1 + affect_within | id), # predicting hurdle part hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;affect_games&quot;) ) Traceplots look good, see (Figure ??). Figure 4.93: Traceplots and posterior distributions for Affect-Games model Figure 4.94: Traceplots and posterior distributions for Affect-Games model Figure 4.95: Traceplots and posterior distributions for Affect-Games model As the proportion of zeros increases, the posterior predictive distribution (Figure 4.96) looks worse than in previous models, suggesting a smooth term might improve model fit. Figure 4.96: Posterior predictive checks for Affect-Games model There are more potentially influential values than in previous models. affect_games_loo &lt;- loo(affect_games) affect_games_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -6436.2 113.9 ## p_loo 1729.1 46.5 ## looic 12872.5 227.8 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7565 87.0% 803 ## (0.5, 0.7] (ok) 682 7.8% 154 ## (0.7, 1] (bad) 364 4.2% 17 ## (1, Inf) (very bad) 87 1.0% 4 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(affect_games) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_games_time ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.82 0.02 0.78 0.87 1.00 1638 3514 ## sd(affect_within) 0.10 0.02 0.06 0.13 1.00 2274 3040 ## sd(hu_Intercept) 7.39 0.36 6.71 8.14 1.00 2528 4976 ## sd(hu_affect_within) 0.37 0.23 0.02 0.85 1.00 1483 2155 ## cor(Intercept,affect_within) -0.03 0.12 -0.26 0.19 1.00 7302 7705 ## cor(hu_Intercept,hu_affect_within) -0.63 0.43 -0.99 0.63 1.00 2975 4946 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.80 0.09 0.62 0.98 1.01 1060 2620 ## hu_Intercept -0.42 0.63 -1.63 0.85 1.01 963 2042 ## affect_between -0.04 0.02 -0.07 -0.01 1.00 1043 2736 ## affect_within -0.01 0.01 -0.03 0.01 1.00 8115 8815 ## hu_affect_between 0.48 0.11 0.27 0.69 1.01 957 2069 ## hu_affect_within -0.04 0.09 -0.22 0.11 1.00 3045 6968 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 4.83 0.15 4.53 5.13 1.00 4742 6948 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects. We see that there’s less variation around game time at high levels of happiness and a smooth term will probably increase model fit. That said, I’d like to keep the model structure the same across media so that effects are comparable. Figure 4.97: Conditional effects for Affect-Games model Figure 4.98: Conditional effects for Affect-Games model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597644 192.2 6231069 332.8 6231069 332.8 ## Vcells 27704645 211.4 174619568 1332.3 264024548 2014.4 4.5.2 Life satisfaction 4.5.2.1 Games on life satisfaction The correlation between random effects has quite few samples, which is why I had to increase the interations. games_life &lt;- brm( data = working_file, family = gaussian, life_satisfaction ~ 1 + games_used_between + games_used_within + games_time_between + games_time_within + (1 + games_time_within + games_used_within | id), iter = 8000, warmup = 3000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;games_life&quot;) ) The traceplots look good (Figure ??). Figure 4.99: Traceplots and posterior distributions for Games-Life Satisfaction model Figure 4.100: Traceplots and posterior distributions for Games-Life Satisfaction model Figure 4.101: Traceplots and posterior distributions for Games-Life Satisfaction model The posterior predictive distribution (Figure 4.102) shows that the model does a good job in predicting our outcome. Figure 4.102: Posterior predictive checks for Games-Life Satisfaction model The outliers are in about the same range as in previous models, and the model diagnostics look good. games_life_loo &lt;- loo(games_life) games_life_loo ## ## Computed from 20000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -14565.9 143.4 ## p_loo 2144.5 51.4 ## looic 29131.9 286.9 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10500 95.6% 736 ## (0.5, 0.7] (ok) 404 3.7% 132 ## (0.7, 1] (bad) 73 0.7% 19 ## (1, Inf) (very bad) 8 0.1% 3 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(games_life) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: life_satisfaction ~ 1 + games_used_between + games_used_within + games_time_between + games_time_within + (1 + games_time_within + games_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 8000; warmup = 3000; thin = 1; ## total post-warmup samples = 20000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.91 0.03 1.85 1.97 1.00 1728 3684 ## sd(games_time_within) 0.02 0.01 0.00 0.05 1.00 1681 5445 ## sd(games_used_within) 0.49 0.06 0.38 0.60 1.00 3174 8897 ## cor(Intercept,games_time_within) -0.22 0.40 -0.89 0.69 1.00 19642 12094 ## cor(Intercept,games_used_within) 0.26 0.09 0.08 0.43 1.00 10286 11790 ## cor(games_time_within,games_used_within) 0.17 0.46 -0.78 0.89 1.01 313 517 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 6.45 0.05 6.34 6.56 1.01 813 1730 ## games_used_between -0.18 0.13 -0.43 0.07 1.00 1064 2301 ## games_used_within -0.05 0.04 -0.13 0.03 1.00 23383 17438 ## games_time_between 0.02 0.03 -0.04 0.07 1.00 1294 2646 ## games_time_within -0.01 0.01 -0.02 0.01 1.00 26625 16601 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.81 0.01 0.80 0.82 1.00 17578 15429 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects Figure 4.103: Conditional effects for Games-Life Satisfaction model Figure 4.104: Conditional effects for Games-Life Satisfaction model Figure 4.105: Conditional effects for Games-Life Satisfaction model Figure 4.106: Conditional effects for Games-Life Satisfaction model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597651 192.2 6231069 332.8 6231069 332.8 ## Vcells 27705371 211.4 204854804 1563.0 264024548 2014.4 4.5.2.2 Life satisfaction on video games life_games &lt;- brm( bf( # predicting continuous part lead_games_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id), # predicting hurdle part hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;life_games&quot;) ) The chains seem to have mixed well, see (Figure ??). Figure 4.107: Traceplots and posterior distributions for Life Satisfaction-Games model Figure 4.108: Traceplots and posterior distributions for Life Satisfaction-Games model Figure 4.109: Traceplots and posterior distributions for Life Satisfaction-Games model The posterior predictive distribution (Figure 4.110) look worse than earlier models, again suggesting a smooth term might improve model fit. Figure 4.110: Posterior predictive checks for Life Satisfaction-Games model There are more potentially influential values than in previous models. life_games_loo &lt;- loo(life_games) life_games_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -6444.4 114.7 ## p_loo 1711.5 47.0 ## looic 12888.9 229.4 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7645 87.9% 773 ## (0.5, 0.7] (ok) 635 7.3% 153 ## (0.7, 1] (bad) 337 3.9% 20 ## (1, Inf) (very bad) 81 0.9% 2 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(life_games) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_games_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.83 0.02 0.79 0.87 1.00 1914 4056 ## sd(life_satisfaction_within) 0.11 0.02 0.07 0.15 1.00 3140 4693 ## sd(hu_Intercept) 7.38 0.37 6.71 8.14 1.00 2956 5758 ## sd(hu_life_satisfaction_within) 0.26 0.18 0.01 0.66 1.00 2015 3886 ## cor(Intercept,life_satisfaction_within) -0.07 0.13 -0.32 0.19 1.00 8424 8566 ## cor(hu_Intercept,hu_life_satisfaction_within) 0.09 0.59 -0.93 0.97 1.00 6667 6234 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.60 0.10 0.40 0.80 1.00 1160 2193 ## hu_Intercept 1.56 0.66 0.28 2.87 1.00 1407 2638 ## life_satisfaction_between 0.00 0.02 -0.03 0.03 1.00 1184 2259 ## life_satisfaction_within 0.01 0.01 -0.02 0.04 1.00 8793 9142 ## hu_life_satisfaction_between 0.13 0.10 -0.06 0.33 1.00 1323 2507 ## hu_life_satisfaction_within 0.02 0.09 -0.16 0.20 1.00 8294 6754 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 4.79 0.15 4.50 5.09 1.00 6117 8149 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects: looks similar to the affect model. Figure 4.111: Conditional effects for Life Satisfaction-Games model Figure 4.112: Conditional effects for Life Satisfaction-Games model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597652 192.2 6231069 332.8 6231069 332.8 ## Vcells 27706077 211.4 196724612 1500.9 264024548 2014.4 4.6 (E-)books 4.6.1 Affect 4.6.1.1 Books on affect I had to increase the number of iterations. books_affect &lt;- brm( data = working_file, family = gaussian, affect ~ 1 + books_used_between + books_used_within + books_time_between + books_time_within + (1 + books_time_within + books_used_within | id), iter = 7000, warmup = 3000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;books_affect&quot;) ) Traceplots look good, see (Figure ??). Figure 4.113: Traceplots and posterior distributions for Books-Affect model Figure 4.114: Traceplots and posterior distributions for Books-Affect model Figure 4.115: Traceplots and posterior distributions for Books-Affect model The posterior predictive distribution (Figure 4.116) looks okay, like in previous models. Figure 4.116: Posterior predictive checks for Books-Affect model The outliers are in about the same range as in previous models, and the model diagnostics look good. books_affect_loo &lt;- loo(books_affect) books_affect_loo ## ## Computed from 16000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -18100.9 105.7 ## p_loo 2039.9 35.6 ## looic 36201.8 211.4 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10554 96.1% 614 ## (0.5, 0.7] (ok) 399 3.6% 166 ## (0.7, 1] (bad) 30 0.3% 33 ## (1, Inf) (very bad) 2 0.0% 9 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(books_affect) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: affect ~ 1 + books_used_between + books_used_within + books_time_between + books_time_within + (1 + books_time_within + books_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 7000; warmup = 3000; thin = 1; ## total post-warmup samples = 16000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.87 0.03 1.81 1.93 1.00 2277 3775 ## sd(books_time_within) 0.02 0.02 0.00 0.06 1.00 5067 7200 ## sd(books_used_within) 0.59 0.08 0.41 0.74 1.00 3603 5386 ## cor(Intercept,books_time_within) -0.15 0.41 -0.86 0.75 1.00 19382 9497 ## cor(Intercept,books_used_within) 0.10 0.09 -0.07 0.27 1.00 16745 11190 ## cor(books_time_within,books_used_within) -0.03 0.51 -0.89 0.87 1.02 243 1099 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 5.95 0.06 5.82 6.08 1.00 1500 2698 ## books_used_between 0.06 0.12 -0.18 0.30 1.00 1271 2280 ## books_used_within 0.07 0.05 -0.02 0.17 1.00 19776 12900 ## books_time_between -0.05 0.03 -0.11 0.01 1.00 1608 3147 ## books_time_within -0.01 0.01 -0.04 0.01 1.00 23090 12615 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.12 0.01 1.11 1.14 1.00 12209 12010 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows conditional effects. Figure 4.117: Conditional effects for Books-Affect model Figure 4.118: Conditional effects for Books-Affect model Figure 4.119: Conditional effects for Books-Affect model Figure 4.120: Conditional effects for Books-Affect model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597665 192.2 6231069 332.8 6231069 332.8 ## Vcells 27706797 211.4 190531916 1453.7 264024548 2014.4 4.6.1.2 Affect on books affect_books &lt;- brm( bf( # predicting continuous part lead_books_time ~ 1 + affect_between + affect_within + (1 + affect_within | id), # predicting hurdle part hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;affect_books&quot;) ) Traceplots look good, see (Figure ??). Figure 4.121: Traceplots and posterior distributions for Affect-Books model Figure 4.122: Traceplots and posterior distributions for Affect-Books model Figure 4.123: Traceplots and posterior distributions for Affect-Books model The posterior predictive distribution (Figure 4.124) looks like the two previous affect models, probably because the proportion of zeros increases strongly. Figure 4.124: Posterior predictive checks for Affect-Books model There are a similar number of potentially influential values as in the two previous affect models. affect_books_loo &lt;- loo(affect_books) affect_books_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -7635.6 125.7 ## p_loo 2024.0 55.1 ## looic 15271.3 251.3 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7598 87.4% 1032 ## (0.5, 0.7] (ok) 628 7.2% 170 ## (0.7, 1] (bad) 382 4.4% 11 ## (1, Inf) (very bad) 90 1.0% 1 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(affect_books) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_books_time ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.76 0.02 0.72 0.79 1.00 2051 4200 ## sd(affect_within) 0.02 0.01 0.00 0.05 1.00 1658 2435 ## sd(hu_Intercept) 6.67 0.31 6.08 7.32 1.00 2871 5882 ## sd(hu_affect_within) 0.29 0.17 0.02 0.66 1.00 1700 2910 ## cor(Intercept,affect_within) -0.21 0.43 -0.93 0.78 1.00 8211 5811 ## cor(hu_Intercept,hu_affect_within) -0.38 0.50 -0.97 0.79 1.00 5381 5196 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.53 0.07 0.39 0.67 1.01 1239 2735 ## hu_Intercept -0.30 0.55 -1.38 0.76 1.00 1309 2714 ## affect_between -0.02 0.01 -0.04 0.00 1.01 1267 2670 ## affect_within 0.01 0.01 -0.00 0.03 1.00 12692 9852 ## hu_affect_between 0.03 0.09 -0.14 0.20 1.00 1291 2680 ## hu_affect_within 0.09 0.05 -0.01 0.18 1.00 13720 8906 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 4.69 0.11 4.47 4.91 1.00 7153 8079 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects. Figure 4.125: Conditional effects for Affect-Books model Figure 4.126: Conditional effects for Affect-Books model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597696 192.2 6231069 332.8 6231069 332.8 ## Vcells 27707505 211.4 184587160 1408.3 264024548 2014.4 4.6.2 Life satisfaction 4.6.2.1 Books on life satisfaction books_life &lt;- brm( data = working_file, family = gaussian, life_satisfaction ~ 1 + books_used_between + books_used_within + books_time_between + books_time_within + (1 + books_time_within + books_used_within | id), iter = 7000, warmup = 3000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;books_life&quot;) ) The traceplots look good (Figure ??). Figure 4.127: Traceplots and posterior distributions for Books-Life Satisfaction model Figure 4.128: Traceplots and posterior distributions for Books-Life Satisfaction model Figure 4.129: Traceplots and posterior distributions for Books-Life Satisfaction model The posterior predictive distribution (Figure 4.130) shows that the model does a good job in predicting our outcome. Figure 4.130: Posterior predictive checks for Books-Life Satisfaction model The outliers are in about the same range as in previous models, and the model diagnostics look good. books_life_loo &lt;- loo(books_life) books_life_loo ## ## Computed from 16000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -14543.5 145.4 ## p_loo 2218.4 51.9 ## looic 29087.0 290.9 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10377 94.5% 680 ## (0.5, 0.7] (ok) 494 4.5% 166 ## (0.7, 1] (bad) 101 0.9% 13 ## (1, Inf) (very bad) 13 0.1% 2 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(books_life) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: life_satisfaction ~ 1 + books_used_between + books_used_within + books_time_between + books_time_within + (1 + books_time_within + books_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 7000; warmup = 3000; thin = 1; ## total post-warmup samples = 16000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.91 0.03 1.85 1.97 1.00 1083 2354 ## sd(books_time_within) 0.01 0.01 0.00 0.04 1.00 3790 6864 ## sd(books_used_within) 0.57 0.05 0.48 0.67 1.00 2990 7917 ## cor(Intercept,books_time_within) -0.19 0.42 -0.88 0.72 1.00 13557 9347 ## cor(Intercept,books_used_within) -0.12 0.07 -0.25 0.01 1.00 13423 11938 ## cor(books_time_within,books_used_within) 0.04 0.47 -0.82 0.89 1.04 118 358 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 6.44 0.07 6.31 6.57 1.01 560 1236 ## books_used_between -0.01 0.12 -0.24 0.25 1.01 612 1396 ## books_used_within 0.06 0.04 -0.02 0.14 1.00 13260 11309 ## books_time_between -0.03 0.03 -0.09 0.03 1.00 788 1582 ## books_time_within 0.01 0.01 -0.01 0.03 1.00 18096 11991 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.80 0.01 0.79 0.82 1.00 12610 11889 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects Figure 4.131: Conditional effects for Books-Life Satisfaction model Figure 4.132: Conditional effects for Books-Life Satisfaction model Figure 4.133: Conditional effects for Books-Life Satisfaction model Figure 4.134: Conditional effects for Books-Life Satisfaction model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597679 192.2 6231069 332.8 6231069 332.8 ## Vcells 27708191 211.4 178880876 1364.8 264024548 2014.4 4.6.2.2 Life satisfaction on books life_books &lt;- brm( bf( # predicting continuous part lead_books_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id), # predicting hurdle part hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;life_books&quot;) ) The chains seem to have mixed well, see (Figure ??). Figure 4.135: Traceplots and posterior distributions for Life Satisfaction-Books model Figure 4.136: Traceplots and posterior distributions for Life Satisfaction-Books model Figure 4.137: Traceplots and posterior distributions for Life Satisfaction-Books model The posterior predictive distribution (Figure 4.138) looks similar to previous models, probably because the massive zero inflation. Figure 4.138: Posterior predictive checks for Life Satisfaction-Books model The outliers are in about the same range as in the more recent models. life_books_loo &lt;- loo(life_books) life_books_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -7632.0 124.9 ## p_loo 2011.8 54.0 ## looic 15264.1 249.8 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7601 87.4% 403 ## (0.5, 0.7] (ok) 627 7.2% 200 ## (0.7, 1] (bad) 380 4.4% 14 ## (1, Inf) (very bad) 90 1.0% 2 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(life_books) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_books_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.76 0.02 0.73 0.79 1.00 2216 3704 ## sd(life_satisfaction_within) 0.03 0.02 0.00 0.09 1.00 1203 1793 ## sd(hu_Intercept) 6.63 0.30 6.07 7.25 1.00 3357 6186 ## sd(hu_life_satisfaction_within) 0.31 0.20 0.02 0.77 1.00 2177 4112 ## cor(Intercept,life_satisfaction_within) 0.05 0.44 -0.85 0.91 1.00 9588 5808 ## cor(hu_Intercept,hu_life_satisfaction_within) -0.31 0.54 -0.98 0.86 1.00 6643 7206 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.51 0.08 0.36 0.66 1.00 1112 2553 ## hu_Intercept -0.47 0.58 -1.60 0.65 1.00 1341 2913 ## life_satisfaction_between -0.01 0.01 -0.04 0.01 1.01 1148 2610 ## life_satisfaction_within 0.01 0.01 -0.01 0.03 1.00 14238 9376 ## hu_life_satisfaction_between 0.06 0.09 -0.12 0.23 1.01 1292 2599 ## hu_life_satisfaction_within 0.04 0.06 -0.08 0.16 1.00 14476 9065 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 4.69 0.12 4.46 4.92 1.00 6637 7916 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects. Figure 4.139: Conditional effects for Life Satisfaction-Books model Figure 4.140: Conditional effects for Life Satisfaction-Books model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597686 192.2 6231069 332.8 6231069 332.8 ## Vcells 27708907 211.5 173397056 1323.0 264024548 2014.4 4.7 Magazines 4.7.1 Affect 4.7.1.1 Magazines on affect I had to increase the number of iterations again. magazines_affect &lt;- brm( data = working_file, family = gaussian, affect ~ 1 + magazines_used_between + magazines_used_within + magazines_time_between + magazines_time_within + (1 + magazines_time_within + magazines_used_within | id), iter = 7000, warmup = 3000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;magazines_affect&quot;) ) Traceplots look good, see (Figure ??). Figure 4.141: Traceplots and posterior distributions for Magazines-Affect model Figure 4.142: Traceplots and posterior distributions for Magazines-Affect model Figure 4.143: Traceplots and posterior distributions for Magazines-Affect model The posterior predictive distribution (Figure 4.144) looks okay, like in previous models. Figure 4.144: Posterior predictive checks for Magazines-Affect model The outliers are in about the same range as in previous models, and the model diagnostics look good. magazines_affect_loo &lt;- loo(magazines_affect) magazines_affect_loo ## ## Computed from 16000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -18119.3 105.3 ## p_loo 1930.1 33.8 ## looic 36238.6 210.5 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10652 97.0% 593 ## (0.5, 0.7] (ok) 310 2.8% 172 ## (0.7, 1] (bad) 22 0.2% 42 ## (1, Inf) (very bad) 1 0.0% 41 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(magazines_affect) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: affect ~ 1 + magazines_used_between + magazines_used_within + magazines_time_between + magazines_time_within + (1 + magazines_time_within + magazines_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 7000; warmup = 3000; thin = 1; ## total post-warmup samples = 16000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.87 0.03 1.81 1.93 1.00 3196 5959 ## sd(magazines_time_within) 0.03 0.02 0.00 0.09 1.00 6015 8989 ## sd(magazines_used_within) 0.26 0.15 0.01 0.52 1.00 2038 5568 ## cor(Intercept,magazines_time_within) 0.14 0.43 -0.74 0.88 1.00 25152 11231 ## cor(Intercept,magazines_used_within) 0.12 0.28 -0.50 0.74 1.00 14407 6731 ## cor(magazines_time_within,magazines_used_within) 0.09 0.50 -0.85 0.91 1.00 2953 6285 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 5.94 0.05 5.84 6.04 1.00 2393 4596 ## magazines_used_between 0.05 0.16 -0.26 0.35 1.00 2532 4981 ## magazines_used_within -0.09 0.05 -0.20 0.02 1.00 30880 12774 ## magazines_time_between -0.13 0.09 -0.30 0.04 1.00 2787 5640 ## magazines_time_within 0.00 0.02 -0.04 0.04 1.00 26087 13136 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.13 0.01 1.12 1.15 1.00 13152 12940 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows conditional effects. Figure 4.145: Conditional effects for Magazines-Affect model Figure 4.146: Conditional effects for Magazines-Affect model Figure 4.147: Conditional effects for Magazines-Affect model Figure 4.148: Conditional effects for Magazines-Affect model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597717 192.2 6231069 332.8 6231069 332.8 ## Vcells 27709692 211.5 203593175 1553.3 264024548 2014.4 4.7.1.2 Affect on magazines affect_magazines &lt;- brm( bf( # predicting continuous part lead_magazines_time ~ 1 + affect_between + affect_within + (1 + affect_within | id), # predicting hurdle part hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;affect_magazines&quot;) ) Traceplots look good, see (Figure ??). Figure 4.149: Traceplots and posterior distributions for Affect-Magazines model Figure 4.150: Traceplots and posterior distributions for Affect-Magazines model Figure 4.151: Traceplots and posterior distributions for Affect-Magazines model The posterior predictive distribution (Figure 4.152) reflects the massive zero inflation especially with LOO-PIT QQ. Model fit is definitely worse than in previous models, but I’m reluctant to add a smooth/quadratic term to make sure I can compare model coefficients across media. Figure 4.152: Posterior predictive checks for Affect-Magazines model There are more potentially influential values than in earlier models, but similar to recent models. affect_magazines_loo &lt;- loo(affect_magazines) affect_magazines_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -3102.2 96.4 ## p_loo 1262.8 45.9 ## looic 6204.4 192.8 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7658 88.0% 1038 ## (0.5, 0.7] (ok) 734 8.4% 243 ## (0.7, 1] (bad) 234 2.7% 16 ## (1, Inf) (very bad) 72 0.8% 1 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(affect_magazines) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_magazines_time ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.91 0.03 0.85 0.97 1.00 2535 4847 ## sd(affect_within) 0.02 0.01 0.00 0.05 1.00 5509 5781 ## sd(hu_Intercept) 6.18 0.33 5.58 6.84 1.00 2490 4698 ## sd(hu_affect_within) 0.40 0.16 0.06 0.72 1.00 1323 1335 ## cor(Intercept,affect_within) -0.10 0.54 -0.96 0.92 1.00 11294 7118 ## cor(hu_Intercept,hu_affect_within) -0.18 0.45 -0.88 0.76 1.00 4260 3260 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept -0.17 0.12 -0.41 0.07 1.00 1856 3607 ## hu_Intercept 4.48 0.58 3.39 5.64 1.00 1839 3554 ## affect_between -0.02 0.02 -0.06 0.02 1.00 1872 3819 ## affect_within -0.00 0.02 -0.03 0.03 1.00 12871 10249 ## hu_affect_between 0.09 0.09 -0.08 0.26 1.00 1716 3328 ## hu_affect_within 0.01 0.16 -0.34 0.30 1.00 4544 6421 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 3.00 0.11 2.78 3.23 1.00 7976 8906 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects. Figure 4.153: Conditional effects for Affect-Magazines model Figure 4.154: Conditional effects for Affect-Magazines model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597694 192.2 6231069 332.8 6231069 332.8 ## Vcells 27710327 211.5 195578644 1492.2 264024548 2014.4 4.7.2 Life satisfaction 4.7.2.1 Magazines on life satisfaction magazines_life &lt;- brm( data = working_file, family = gaussian, life_satisfaction ~ 1 + magazines_used_between + magazines_used_within + magazines_time_between + magazines_time_within + (1 + magazines_time_within + magazines_used_within | id), iter = 7000, warmup = 3000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;magazines_life&quot;) ) The traceplots look good (Figure ??). Figure 4.155: Traceplots and posterior distributions for Magazines-Life Satisfaction model Figure 4.156: Traceplots and posterior distributions for Magazines-Life Satisfaction model Figure 4.157: Traceplots and posterior distributions for Magazines-Life Satisfaction model The posterior predictive distribution (Figure 4.158) shows that the model does a good job in predicting our outcome. Figure 4.158: Posterior predictive checks for Magazines-Life Satisfaction model The outliers are in about the same range as in previous models, and the model diagnostics look good. magazines_life_loo &lt;- loo(magazines_life) magazines_life_loo ## ## Computed from 16000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -14595.4 146.5 ## p_loo 2004.0 47.5 ## looic 29190.8 293.0 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10612 96.6% 530 ## (0.5, 0.7] (ok) 317 2.9% 93 ## (0.7, 1] (bad) 48 0.4% 17 ## (1, Inf) (very bad) 8 0.1% 2 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(magazines_life) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: life_satisfaction ~ 1 + magazines_used_between + magazines_used_within + magazines_time_between + magazines_time_within + (1 + magazines_time_within + magazines_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 7000; warmup = 3000; thin = 1; ## total post-warmup samples = 16000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.90 0.03 1.85 1.96 1.00 1863 3954 ## sd(magazines_time_within) 0.02 0.02 0.00 0.07 1.00 6375 9043 ## sd(magazines_used_within) 0.15 0.10 0.01 0.35 1.00 1687 5158 ## cor(Intercept,magazines_time_within) 0.16 0.44 -0.75 0.89 1.00 24099 11489 ## cor(Intercept,magazines_used_within) 0.05 0.32 -0.67 0.75 1.00 14167 6508 ## cor(magazines_time_within,magazines_used_within) 0.02 0.50 -0.87 0.89 1.00 3963 7545 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 6.36 0.05 6.27 6.46 1.00 927 1729 ## magazines_used_between 0.01 0.15 -0.28 0.32 1.01 1070 2314 ## magazines_used_within -0.01 0.04 -0.09 0.06 1.00 31653 13180 ## magazines_time_between 0.14 0.09 -0.03 0.32 1.00 1527 3032 ## magazines_time_within -0.00 0.01 -0.03 0.03 1.00 24387 12511 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.82 0.01 0.81 0.83 1.00 16100 12142 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects Figure 4.159: Conditional effects for Magazines-Life Satisfaction model Figure 4.160: Conditional effects for Magazines-Life Satisfaction model Figure 4.161: Conditional effects for Magazines-Life Satisfaction model Figure 4.162: Conditional effects for Magazines-Life Satisfaction model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597707 192.2 6231069 332.8 6231069 332.8 ## Vcells 27711099 211.5 189430295 1445.3 264024548 2014.4 4.7.2.2 Life satisfaction on magazines life_magazines &lt;- brm( bf( # predicting continuous part lead_magazines_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id), # predicting hurdle part hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;life_magazines&quot;) ) The chains seem to have mixed well, see (Figure ??). Figure 4.163: Traceplots and posterior distributions for Life Satisfaction-Magazines model Figure 4.164: Traceplots and posterior distributions for Life Satisfaction-Magazines model Figure 4.165: Traceplots and posterior distributions for Life Satisfaction-Magazines model The posterior predictive distribution (Figure 4.166) is almost identical to the affect model. The massive zero inflation creates problems for the model. Figure 4.166: Posterior predictive checks for Life Satisfaction-Magazines model There are more potentially influential values than in earlier models. life_magazines_loo &lt;- loo(life_magazines) life_magazines_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -3100.1 95.9 ## p_loo 1249.2 45.0 ## looic 6200.1 191.7 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7785 89.5% 786 ## (0.5, 0.7] (ok) 596 6.9% 176 ## (0.7, 1] (bad) 240 2.8% 20 ## (1, Inf) (very bad) 77 0.9% 2 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(life_magazines) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_magazines_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.90 0.03 0.84 0.96 1.00 2141 4691 ## sd(life_satisfaction_within) 0.06 0.04 0.00 0.14 1.00 1469 3379 ## sd(hu_Intercept) 6.08 0.31 5.51 6.73 1.00 2408 5107 ## sd(hu_life_satisfaction_within) 0.36 0.21 0.02 0.79 1.00 1554 2648 ## cor(Intercept,life_satisfaction_within) -0.02 0.42 -0.86 0.85 1.00 7606 4536 ## cor(hu_Intercept,hu_life_satisfaction_within) 0.27 0.51 -0.84 0.96 1.00 5198 5597 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept -0.68 0.14 -0.95 -0.41 1.00 1745 2929 ## hu_Intercept 5.71 0.61 4.53 6.95 1.00 2106 4345 ## life_satisfaction_between 0.06 0.02 0.02 0.10 1.00 1761 3200 ## life_satisfaction_within 0.01 0.02 -0.03 0.06 1.00 10225 9627 ## hu_life_satisfaction_between -0.12 0.08 -0.29 0.04 1.00 1915 3818 ## hu_life_satisfaction_within 0.08 0.18 -0.26 0.48 1.00 4963 5944 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 3.02 0.12 2.80 3.25 1.00 7339 8694 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects where we again see the effect of the massive zero inflation: there’s almost no room on the y-axis and little variation around time. Figure 4.167: Conditional effects for Life Satisfaction-Magazines model Figure 4.168: Conditional effects for Life Satisfaction-Magazines model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597738 192.2 6231069 332.8 6231069 332.8 ## Vcells 27711872 211.5 183527539 1400.3 264024548 2014.4 4.8 Audiobooks 4.8.1 Affect 4.8.1.1 Audiobooks on affect audiobooks_affect &lt;- brm( data = working_file, family = gaussian, affect ~ 1 + audiobooks_used_between + audiobooks_used_within + audiobooks_time_between + audiobooks_time_within + (1 + audiobooks_time_within + audiobooks_used_within | id), iter = 7000, warmup = 3000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;audiobooks_affect&quot;) ) Traceplots look good, see (Figure ??). Figure 4.169: Traceplots and posterior distributions for Audiobooks-Affect model Figure 4.170: Traceplots and posterior distributions for Audiobooks-Affect model Figure 4.171: Traceplots and posterior distributions for Audiobooks-Affect model The posterior predictive distribution (Figure 4.172) looks okay, like in previous models. Figure 4.172: Posterior predictive checks for Audiobooks-Affect model The outliers are in about the same range as in previous models, and the model diagnostics look good. audiobooks_affect_loo &lt;- loo(audiobooks_affect) audiobooks_affect_loo ## ## Computed from 16000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -18111.9 105.6 ## p_loo 1943.3 34.0 ## looic 36223.8 211.3 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10617 96.6% 596 ## (0.5, 0.7] (ok) 337 3.1% 134 ## (0.7, 1] (bad) 31 0.3% 10 ## (1, Inf) (very bad) 0 0.0% &lt;NA&gt; ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(audiobooks_affect) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: affect ~ 1 + audiobooks_used_between + audiobooks_used_within + audiobooks_time_between + audiobooks_time_within + (1 + audiobooks_time_within + audiobooks_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 7000; warmup = 3000; thin = 1; ## total post-warmup samples = 16000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.86 0.03 1.80 1.92 1.00 2764 5234 ## sd(audiobooks_time_within) 0.04 0.03 0.00 0.12 1.00 7055 7642 ## sd(audiobooks_used_within) 0.50 0.16 0.11 0.77 1.00 1932 1603 ## cor(Intercept,audiobooks_time_within) -0.18 0.45 -0.90 0.74 1.00 23390 11178 ## cor(Intercept,audiobooks_used_within) 0.10 0.20 -0.27 0.49 1.00 11896 5089 ## cor(audiobooks_time_within,audiobooks_used_within) -0.10 0.50 -0.91 0.85 1.01 1254 3605 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 5.98 0.05 5.89 6.07 1.00 1675 3771 ## audiobooks_used_between -0.39 0.24 -0.86 0.09 1.00 1963 3615 ## audiobooks_used_within -0.14 0.08 -0.30 0.02 1.00 20473 13050 ## audiobooks_time_between -0.09 0.10 -0.28 0.10 1.00 2236 4846 ## audiobooks_time_within 0.01 0.03 -0.04 0.07 1.00 17227 12197 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.13 0.01 1.12 1.15 1.00 14117 11394 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows conditional effects. Figure 4.173: Conditional effects for Audiobooks-Affect model Figure 4.174: Conditional effects for Audiobooks-Affect model Figure 4.175: Conditional effects for Audiobooks-Affect model Figure 4.176: Conditional effects for Audiobooks-Affect model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597715 192.2 6231069 332.8 6231069 332.8 ## Vcells 27712573 211.5 213503861 1629.0 264024548 2014.4 4.8.1.2 Affect on audiobooks affect_audiobooks &lt;- brm( bf( # predicting continuous part lead_audiobooks_time ~ 1 + affect_between + affect_within + (1 + affect_within | id), # predicting hurdle part hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;affect_audiobooks&quot;) ) Traceplots look good, see (Figure ??). Figure 4.177: Traceplots and posterior distributions for Affect-Audiobooks model Figure 4.178: Traceplots and posterior distributions for Affect-Audiobooks model Figure 4.179: Traceplots and posterior distributions for Affect-Audiobooks model The posterior predictive distribution (Figure 4.180) are similar to recent models with massive zero inflation. Figure 4.180: Posterior predictive checks for Affect-Audiobooks model There are more potentially influential values than in earlier models. affect_audiobooks_loo &lt;- loo(affect_audiobooks) affect_audiobooks_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -1974.7 76.5 ## p_loo 724.5 37.1 ## looic 3949.5 152.9 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7816 89.9% 1415 ## (0.5, 0.7] (ok) 673 7.7% 163 ## (0.7, 1] (bad) 148 1.7% 18 ## (1, Inf) (very bad) 61 0.7% 3 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(affect_audiobooks) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_audiobooks_time ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## hu ~ 1 + affect_between + affect_within + (1 + affect_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.93 0.05 0.84 1.02 1.00 2381 4767 ## sd(affect_within) 0.05 0.03 0.00 0.13 1.00 2856 4443 ## sd(hu_Intercept) 6.25 0.42 5.49 7.13 1.00 2026 4400 ## sd(hu_affect_within) 0.23 0.17 0.01 0.63 1.00 2275 4840 ## cor(Intercept,affect_within) -0.34 0.49 -0.97 0.83 1.00 8265 6872 ## cor(hu_Intercept,hu_affect_within) -0.20 0.59 -0.98 0.92 1.00 4196 6420 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.69 0.21 0.29 1.10 1.00 1906 3367 ## hu_Intercept 6.36 0.75 4.95 7.89 1.00 2570 5020 ## affect_between -0.10 0.03 -0.16 -0.03 1.00 1929 3515 ## affect_within -0.02 0.03 -0.07 0.03 1.00 9563 8809 ## hu_affect_between 0.35 0.11 0.14 0.57 1.00 2240 4669 ## hu_affect_within -0.13 0.24 -0.70 0.28 1.00 3946 4560 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 3.31 0.21 2.91 3.72 1.00 5364 8173 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects where we again see the zero inflation because there’s little non-zero average time to report. Figure 4.181: Conditional effects for Affect-Audiobooks model Figure 4.182: Conditional effects for Affect-Audiobooks model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597725 192.2 6231069 332.8 6231069 332.8 ## Vcells 27713265 211.5 170803089 1303.2 264024548 2014.4 4.8.2 Life satisfaction 4.8.2.1 Audiobooks on life satisfaction audiobooks_life &lt;- brm( data = working_file, family = gaussian, life_satisfaction ~ 1 + audiobooks_used_between + audiobooks_used_within + audiobooks_time_between + audiobooks_time_within + (1 + audiobooks_time_within + audiobooks_used_within | id), iter = 7000, warmup = 3000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;audiobooks_life&quot;) ) The traceplots look good (Figure ??). Figure 4.183: Traceplots and posterior distributions for Audiobooks-Life Satisfaction model Figure 4.184: Traceplots and posterior distributions for Audiobooks-Life Satisfaction model Figure 4.185: Traceplots and posterior distributions for Audiobooks-Life Satisfaction model The posterior predictive distribution (Figure 4.186) shows that the model does a good job in predicting our outcome. Figure 4.186: Posterior predictive checks for Audiobooks-Life Satisfaction model The outliers are in about the same range as in previous models, and the model diagnostics look good. audiobooks_life_loo &lt;- loo(audiobooks_life) audiobooks_life_loo ## ## Computed from 16000 by 10985 log-likelihood matrix ## ## Estimate SE ## elpd_loo -14563.4 146.4 ## p_loo 2076.0 49.7 ## looic 29126.7 292.7 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 10494 95.5% 774 ## (0.5, 0.7] (ok) 405 3.7% 130 ## (0.7, 1] (bad) 75 0.7% 12 ## (1, Inf) (very bad) 11 0.1% 4 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(audiobooks_life) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: life_satisfaction ~ 1 + audiobooks_used_between + audiobooks_used_within + audiobooks_time_between + audiobooks_time_within + (1 + audiobooks_time_within + audiobooks_used_within | id) ## Data: working_file (Number of observations: 10985) ## Samples: 4 chains, each with iter = 7000; warmup = 3000; thin = 1; ## total post-warmup samples = 16000 ## ## Group-Level Effects: ## ~id (Number of levels: 2159) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.91 0.03 1.85 1.96 1.00 1504 3385 ## sd(audiobooks_time_within) 0.16 0.04 0.08 0.24 1.00 3754 7416 ## sd(audiobooks_used_within) 0.33 0.13 0.05 0.55 1.00 1612 2250 ## cor(Intercept,audiobooks_time_within) -0.06 0.22 -0.47 0.40 1.00 9935 9879 ## cor(Intercept,audiobooks_used_within) -0.09 0.23 -0.56 0.36 1.00 9656 5194 ## cor(audiobooks_time_within,audiobooks_used_within) 0.40 0.37 -0.43 0.94 1.00 1955 4210 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 6.39 0.05 6.30 6.48 1.01 815 1490 ## audiobooks_used_between 0.22 0.24 -0.24 0.69 1.01 820 1941 ## audiobooks_used_within -0.12 0.06 -0.24 0.00 1.00 14105 12652 ## audiobooks_time_between -0.08 0.10 -0.27 0.11 1.00 1154 2792 ## audiobooks_time_within 0.09 0.03 0.02 0.15 1.00 9065 11633 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.81 0.01 0.80 0.83 1.00 15476 12483 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects Figure 4.187: Conditional effects for Audiobooks-Life Satisfaction model Figure 4.188: Conditional effects for Audiobooks-Life Satisfaction model Figure 4.189: Conditional effects for Audiobooks-Life Satisfaction model Figure 4.190: Conditional effects for Audiobooks-Life Satisfaction model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597759 192.2 6231069 332.8 6231069 332.8 ## Vcells 27714080 211.5 200453986 1529.4 264024548 2014.4 4.8.2.2 Life satisfaction on audiobooks life_audiobooks &lt;- brm( bf( # predicting continuous part lead_audiobooks_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id), # predicting hurdle part hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ), data = working_file, family = hurdle_gamma(), , iter = 5000, warmup = 2000, chains = 4, cores = 4, seed = 42, control = list(adapt_delta = 0.95), file = here(&quot;models&quot;, &quot;life_audiobooks&quot;) ) The chains seem to have mixed well, see (Figure ??). Figure 4.191: Traceplots and posterior distributions for Life Satisfaction-Audiobooks model Figure 4.192: Traceplots and posterior distributions for Life Satisfaction-Audiobooks model Figure 4.193: Traceplots and posterior distributions for Life Satisfaction-Audiobooks model The posterior predictive distribution (Figure 4.194) is similar to the affect model: there’s just very little non-zero time to explain for the model. Figure 4.194: Posterior predictive checks for Life Satisfaction-Audiobooks model There are more potentially influential values than in earlier models. life_audiobooks_loo &lt;- loo(life_audiobooks) life_audiobooks_loo ## ## Computed from 12000 by 8698 log-likelihood matrix ## ## Estimate SE ## elpd_loo -1976.3 76.8 ## p_loo 752.1 38.6 ## looic 3952.6 153.6 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 7550 86.8% 201 ## (0.5, 0.7] (ok) 890 10.2% 225 ## (0.7, 1] (bad) 191 2.2% 15 ## (1, Inf) (very bad) 67 0.8% 2 ## See help(&#39;pareto-k-diagnostic&#39;) for details. Below the summary. summary(life_audiobooks) ## Family: hurdle_gamma ## Links: mu = log; shape = identity; hu = logit ## Formula: lead_audiobooks_time ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## hu ~ 1 + life_satisfaction_between + life_satisfaction_within + (1 + life_satisfaction_within | id) ## Data: working_file (Number of observations: 8698) ## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1; ## total post-warmup samples = 12000 ## ## Group-Level Effects: ## ~id (Number of levels: 2157) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.94 0.05 0.85 1.04 1.00 2219 4037 ## sd(life_satisfaction_within) 0.10 0.09 0.00 0.31 1.01 575 777 ## sd(hu_Intercept) 6.43 0.43 5.64 7.33 1.00 1970 4389 ## sd(hu_life_satisfaction_within) 0.70 0.30 0.11 1.30 1.00 1861 1620 ## cor(Intercept,life_satisfaction_within) 0.03 0.43 -0.85 0.87 1.00 7258 5674 ## cor(hu_Intercept,hu_life_satisfaction_within) -0.57 0.41 -0.99 0.53 1.00 2779 4482 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.44 0.22 0.00 0.86 1.00 1454 2778 ## hu_Intercept 9.17 0.91 7.48 11.07 1.00 2031 4155 ## life_satisfaction_between -0.04 0.03 -0.11 0.02 1.00 1384 2656 ## life_satisfaction_within -0.01 0.03 -0.08 0.06 1.00 6431 6701 ## hu_life_satisfaction_between -0.09 0.11 -0.31 0.12 1.00 1958 3828 ## hu_life_satisfaction_within -0.67 0.47 -1.58 0.17 1.00 2648 6084 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 3.35 0.24 2.92 3.87 1.00 1802 2466 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Figure ?? shows the conditional effects: again, we see that the model struggles because there’s so little non-zero stuff to explain. Figure 4.195: Conditional effects for Life Satisfaction-Audiobooks model Figure 4.196: Conditional effects for Life Satisfaction-Audiobooks model ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3597766 192.2 6231069 332.8 6231069 332.8 ## Vcells 27714815 211.5 194109422 1481.0 264024548 2014.4 "],
["synthesis.html", "5 Synthesis 5.1 Create a summary graph 5.2 Interpreting the results 5.3 Take-aways", " 5 Synthesis 5.1 Create a summary graph In the Analysis section, I ran 28 models, each with four parameters. That makes it hard to get an overview of general trends and differences. Here, I try to visually present those findings and produce a figure that gives a nice overview. First, I’ll extract all model parameters from the models. Each one is quite large, so loading them all at once will make my RAM explode. Instead, I’ll iterate over each model: Load the model Extract the estimates Wrangle and relabel them Remove model from workspace again The below took about five minutes on my laptop. # get all model names well_being_indicators &lt;- c(&quot;affect&quot;, &quot;life&quot;) media &lt;- c( &quot;music&quot;, &quot;films&quot;, &quot;tv&quot;, &quot;games&quot;, &quot;books&quot;, &quot;magazines&quot;, &quot;audiobooks&quot; ) models1 &lt;- paste(rep(well_being_indicators, each = length(media)), media, sep = &quot;_&quot;) models2 &lt;- paste(rep(media, each = length(well_being_indicators)), well_being_indicators, sep = &quot;_&quot;) models &lt;- c(models1, models2) get_model_estimates &lt;- function( models ){ # set up the data set estimates &lt;- tibble( Predictor = character(), Outcome = character(), `Use vs. Time` = character(), `Between vs. Within` = character(), Estimate = double(), `Lower CI` = double(), `Upper CI` = double() ) for (model_name in models) { # super lame progress bar print( paste0( &quot;Currently working on: &quot;, model_name, &quot;. Progress: &quot;, which(models==model_name), &quot;/&quot;, length(models) ) ) # load model m &lt;- read_rds(here(&quot;models&quot;, paste0(model_name, &quot;.rds&quot;))) # get predictor in this model predictor &lt;- str_remove(model_name, &quot;_.*&quot;) # only take what&#39;s before the underscore # first we get the fixed effects dat &lt;- # get fixed effects fixef(m) %&gt;% # turn into a tibble and keep rownames because they are the parameter names as_tibble(., rownames = &quot;Effect&quot;) %&gt;% # outcome will be the second part of the model name after the underscore mutate( Outcome = model_name, Outcome = str_remove(Outcome, &quot;.*_&quot;) ) %&gt;% # no need for intercept parameters filter(!str_detect(Effect, &quot;Intercept&quot;)) # if statement to see how to rename model estimates if (predictor %in% c(&quot;affect&quot;, &quot;life&quot;)){ dat &lt;- dat %&gt;% # we need to rename the parameters so that their patterns fit with a model that has a media predictor mutate( # life_satisfaction adds an extra underscore which breaks the rest of the code below, so I&#39;ll just replace it here (if it&#39;s affect, it won&#39;t matter) Effect = str_replace(Effect, &quot;life_satisfaction&quot;, &quot;life&quot;), Effect = case_when( # if it has hu(rdle) in it, we remove that and replace it with &quot;use&quot; str_detect(Effect, &quot;hu&quot;) ~ str_replace( str_remove(Effect, &quot;hu_&quot;), &quot;_&quot;, &quot;_use_&quot; ), # if it doesn&#39;t have hu(rdle), we know the parameter is about time TRUE ~ str_replace(Effect, &quot;_&quot;, &quot;_time_&quot;) ) ) } # next, let&#39;s finish the wrangling dat &lt;- dat %&gt;% # turn the Effect parameters into three separate variables separate( Effect, into = c(&quot;Predictor&quot;, &quot;Use vs. Time&quot;, &quot;Between vs. Within&quot;), sep = &quot;_&quot; ) %&gt;% # renaming and selecting (only keep variables we&#39;ll need for plotting) select( Predictor, Outcome, `Use vs. Time`, `Between vs. Within`, Estimate, `Lower CI` = Q2.5, `Upper CI` = Q97.5 ) # then add those rows to the tibble we&#39;ll return estimates &lt;- bind_rows( estimates, dat ) # clear workspace rm(m) gc() } # some wrangling on final data set estimates &lt;- estimates %&gt;% mutate( # turn life into Life Satisfaction across( Predictor:Outcome, ~ str_replace(.x, &quot;life&quot;, &quot;Life Satisfaction&quot;) ), # factor levels to upper case across( Predictor:`Between vs. Within`, str_to_title ), # use factor still has &quot;Used&quot; instead of &quot;Use&quot; as a level `Use vs. Time` = str_replace(`Use vs. Time`, &quot;Used&quot;, &quot;Use&quot;), # turn into factors across( Predictor:`Between vs. Within`, as.factor ) ) # and return return(estimates) } # apply function get_model_estimates(models) -&gt; estimates ## [1] &quot;Currently working on: affect_music. Progress: 1/28&quot; ## [1] &quot;Currently working on: affect_films. Progress: 2/28&quot; ## [1] &quot;Currently working on: affect_tv. Progress: 3/28&quot; ## [1] &quot;Currently working on: affect_games. Progress: 4/28&quot; ## [1] &quot;Currently working on: affect_books. Progress: 5/28&quot; ## [1] &quot;Currently working on: affect_magazines. Progress: 6/28&quot; ## [1] &quot;Currently working on: affect_audiobooks. Progress: 7/28&quot; ## [1] &quot;Currently working on: life_music. Progress: 8/28&quot; ## [1] &quot;Currently working on: life_films. Progress: 9/28&quot; ## [1] &quot;Currently working on: life_tv. Progress: 10/28&quot; ## [1] &quot;Currently working on: life_games. Progress: 11/28&quot; ## [1] &quot;Currently working on: life_books. Progress: 12/28&quot; ## [1] &quot;Currently working on: life_magazines. Progress: 13/28&quot; ## [1] &quot;Currently working on: life_audiobooks. Progress: 14/28&quot; ## [1] &quot;Currently working on: music_affect. Progress: 15/28&quot; ## [1] &quot;Currently working on: music_life. Progress: 16/28&quot; ## [1] &quot;Currently working on: films_affect. Progress: 17/28&quot; ## [1] &quot;Currently working on: films_life. Progress: 18/28&quot; ## [1] &quot;Currently working on: tv_affect. Progress: 19/28&quot; ## [1] &quot;Currently working on: tv_life. Progress: 20/28&quot; ## [1] &quot;Currently working on: games_affect. Progress: 21/28&quot; ## [1] &quot;Currently working on: games_life. Progress: 22/28&quot; ## [1] &quot;Currently working on: books_affect. Progress: 23/28&quot; ## [1] &quot;Currently working on: books_life. Progress: 24/28&quot; ## [1] &quot;Currently working on: magazines_affect. Progress: 25/28&quot; ## [1] &quot;Currently working on: magazines_life. Progress: 26/28&quot; ## [1] &quot;Currently working on: audiobooks_affect. Progress: 27/28&quot; ## [1] &quot;Currently working on: audiobooks_life. Progress: 28/28&quot; Alright, now let’s see in which way the plot makes the most sense. First, I need to do some wrangling on the estimates data frame. Then I facet by the direction of the effect and time and use. Not sure I like this: Four columns might be a bit much. estimates &lt;- estimates %&gt;% mutate( # factor variable that shows the direction of effect Direction = if_else(Predictor %in% str_to_title(media), &quot;Media on Well-Being&quot;, &quot;Well-Being on Media&quot;), # factor variable that shows which measure to facet from Measure = as.factor(if_else(Predictor == &quot;Life Satisfaction&quot; | Outcome == &quot;Life Satisfaction&quot;, &quot;Life Satisfaction&quot;, &quot;Affect&quot;)), # for which predictor/outcome the effect is visualized Effect = as.factor(if_else(Predictor %in% str_to_title(media), Predictor, Outcome)), # the effect on the hurdle gave us odds ratios of zero, so I reverse those to tell use odds of having used medium across( Estimate:`Upper CI`, ~ if_else(Direction == &quot;Well-Being on Media&quot;, exp(-.x), .x) ), # the line for null effect (0 for gaussian, 1 for hurdle gamme) Line = if_else(Direction == &quot;Media on Well-Being&quot;, 0, 1), # rename levels Effect = fct_recode( Effect, &quot;TV&quot; = &quot;Tv&quot;, &quot;Life satisfaction&quot; = &quot;Life Satisfaction&quot; ), Measure = fct_recode( Measure, &quot;Life satisfaction&quot; = &quot;Life Satisfaction&quot; ), # reorder factor levels Effect = fct_relevel( Effect, c( &quot;Audiobooks&quot;, &quot;Magazines&quot;, &quot;Books&quot;, &quot;Games&quot;, &quot;Films&quot;, &quot;TV&quot;, &quot;Music&quot; ) ) ) ggplot( estimates %&gt;% arrange(Measure), aes( x = Estimate, y = Effect, color = Measure ) ) + geom_vline( aes( xintercept = Line ) ) + geom_pointrange( aes( xmin = `Lower CI`, xmax = `Upper CI` ), position = position_dodge2(.6, reverse = TRUE) ) + facet_grid( `Between vs. Within` ~ Direction + `Use vs. Time`, scales = &quot;free_x&quot; ) + scale_colour_manual(values=cb_palette) + scale_fill_manual(values = cb_palette) + theme( axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.line.y = element_blank(), strip.background.x = element_blank(), strip.background.y = element_blank() ) -&gt; figure6.1 figure6.1 This looks better, in my opinion. Shapes and colors can be tough, but I think it’s easier to read than having four columns. Then again, it’s quite a lot to take in, so maybe it’s best to split one of the facets into two plots. ggplot( estimates %&gt;% mutate( # ggplot weirdly shows the first level of the legend second on the graph, so I reverse level order and then reverse the legend order below with the guides command `Use vs. Time` = fct_relevel( `Use vs. Time`, &quot;Time&quot;, &quot;Use&quot; ), Measure = fct_relevel( Measure, &quot;Life satisfaction&quot;, &quot;Affect&quot; ) ), aes( x = Estimate, y = Effect, color = `Use vs. Time`, shape = Measure, ) ) + geom_vline( aes( xintercept = Line ) ) + geom_pointrange( aes( xmin = `Lower CI`, xmax = `Upper CI` ), position = position_dodge2(1), size = 0.5 ) + geom_hline( aes( yintercept = if_else(as.numeric(Effect) == 1, 0, as.numeric(Effect) - 0.5) ), color = &quot;lightgrey&quot;, linetype = &quot;dashed&quot;, alpha = 0.45 ) + facet_grid( `Between vs. Within` ~ Direction, scales = &quot;free_x&quot; ) + scale_colour_manual(values=c(&quot;#000000&quot;, &quot;#E69F00&quot;)) + scale_fill_manual(values = c(&quot;#000000&quot;, &quot;#E69F00&quot;)) + scale_shape_manual(values=c(15, 16)) + guides( color = guide_legend(reverse = TRUE), shape = guide_legend(reverse = TRUE) ) + theme( axis.title.y = element_blank(), axis.title.x = element_blank(), axis.ticks.y = element_blank(), # axis.line.y = element_blank(), strip.background.x = element_blank(), strip.background.y = element_blank(), legend.position = &quot;bottom&quot;, ) -&gt; figure6.2 figure6.2 I’ll create one plot for use and one plot for time effects. I’ll start with a plot for use vs. nonuse. ggplot( estimates %&gt;% mutate( `Use vs. Time` = fct_relevel( `Use vs. Time`, &quot;Time&quot;, &quot;Use&quot; ), Measure = fct_relevel( Measure, &quot;Life satisfaction&quot;, &quot;Affect&quot; ) ) %&gt;% # only use filter(`Use vs. Time` == &quot;Use&quot;), aes( x = Estimate, y = Effect, color = Measure ) ) + geom_vline( aes( xintercept = Line ) ) + geom_pointrange( aes( xmin = `Lower CI`, xmax = `Upper CI` ), position = position_dodge2(1), size = 0.5 ) + geom_hline( aes( yintercept = if_else(as.numeric(Effect) == 1, 0, as.numeric(Effect) - 0.5) ), color = &quot;lightgrey&quot;, linetype = &quot;dashed&quot;, alpha = 0.45 ) + facet_grid( `Between vs. Within` ~ Direction, scales = &quot;free_x&quot; ) + scale_colour_manual(values=c(&quot;#000000&quot;, &quot;#E69F00&quot;)) + scale_fill_manual(values = c(&quot;#000000&quot;, &quot;#E69F00&quot;)) + scale_shape_manual(values=c(15, 16)) + guides( color = guide_legend(reverse = TRUE), shape = guide_legend(reverse = TRUE) ) + theme( axis.title.y = element_blank(), axis.title.x = element_blank(), axis.ticks.y = element_blank(), # axis.line.y = element_blank(), strip.background.x = element_blank(), strip.background.y = element_blank(), legend.position = &quot;bottom&quot;, ) -&gt; figure6.3 figure6.3 ggsave( filename = here(&quot;figures&quot;, &quot;figure6.tiff&quot;), plot = figure6.3, width = 21 * 0.9, height = 29.7 * 0.7, units = &quot;cm&quot;, dpi = 300 ) Then a plot for time effects. ggplot( estimates %&gt;% mutate( `Use vs. Time` = fct_relevel( `Use vs. Time`, &quot;Time&quot;, &quot;Use&quot; ), Measure = fct_relevel( Measure, &quot;Life satisfaction&quot;, &quot;Affect&quot; ) ) %&gt;% # show only filter(`Use vs. Time` == &quot;Time&quot;), aes( x = Estimate, y = Effect, color = Measure ) ) + geom_vline( aes( xintercept = Line ) ) + geom_pointrange( aes( xmin = `Lower CI`, xmax = `Upper CI` ), position = position_dodge2(1), size = 0.5 ) + geom_hline( aes( yintercept = if_else(as.numeric(Effect) == 1, 0, as.numeric(Effect) - 0.5) ), color = &quot;lightgrey&quot;, linetype = &quot;dashed&quot;, alpha = 0.45 ) + facet_grid( `Between vs. Within` ~ Direction, scales = &quot;free_x&quot; ) + scale_colour_manual(values=c(&quot;#000000&quot;, &quot;#E69F00&quot;)) + scale_fill_manual(values = c(&quot;#000000&quot;, &quot;#E69F00&quot;)) + scale_shape_manual(values=c(15, 16)) + guides( color = guide_legend(reverse = TRUE), shape = guide_legend(reverse = TRUE) ) + theme( axis.title.y = element_blank(), axis.title.x = element_blank(), axis.ticks.y = element_blank(), # axis.line.y = element_blank(), strip.background.x = element_blank(), strip.background.y = element_blank(), legend.position = &quot;bottom&quot;, ) -&gt; figure7 figure7 ggsave( filename = here(&quot;figures&quot;, &quot;figure7.tiff&quot;), plot = figure7, width = 21 * 0.9, height = 29.7 * 0.7, units = &quot;cm&quot;, dpi = 300 ) 5.2 Interpreting the results Points represent the mean of the posterior distribution of the parameter. Lines represent 95% Credible Intervals of the same posterior distribution. For both of the last two figures, the columns display reciprocal effects: On the left-hand side, coefficients are of the Gaussian models, meaning they represent an effect on the 0 to 10 well-being scale. On the right, coefficients are of the hurdle gamma model, meaning they represent odds of using a medium at all (hurdle part) and time spent using a medium (gamma part). The top part shows between-person effects. The bottom part shows within-person effects. If we take music as an example: In the top left of the second to last figure, we see the between-person effects of listening to music vs. not listening to music on affect and life satisfaction. Across the entire sample and all waves, the model estimated that someone who listens to music, compared to someone who does not listen to music, reports feeling somewhat worse on affect, but not on life satisfaction. That correlation is mirrored on the top right that shows effects of affect and life satisfaction, across all waves, on whether someone listens to music vs. not. Mirroring the left-hand columns, someone who feels one point better than someone else on the 0 to 10 affect measure has lower odds of listening to music compared to someone else. The bottom left shows within-effects of listening to music: Someone who goes from not listening to music to listening to music does feel somewhat better a week later. Conversely (on the bottom right), if a person feels one point better on affect than they typically do, they do not have higher odds of listening to music a week later (golden circle). In the last figure, we see the effects of time spent listening to music. The top left corner shows that one hour more music listening than someone else is only weakly related to well-being; conversely, scoring one point higher on well-being than someone else is only weakly related to the odds of spending more time listening to music. At the within-person level (bottom left), when a person listens to one hour more than they typically do, they felt slightly better, but the posterior included zero as well as negative effects. Likewise, if someone scored on point higher on the affect scale than they typically do, they do not have higher odds of listening to more music (bottom right). 5.3 Take-aways The effects we observe are on the between-level (top left): Those who use a medium also feel worse, generally. But: This only applies to use and not time: Once people use a medium, they’re not worse off than someone who spends less time with a medium. Any differences happen on the less stable affect, not on life satisfaction. These differences don’t seem to differ much per medium. On the within-level, there isn’t much going on: Most effects are super small and include zero as a plausible effect size. "]
]
